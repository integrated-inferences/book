<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>7&nbsp; Process Tracing with Causal Models – Integrated Inferences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./08-PT-application.html" rel="next">
<link href="./06-theory-as-causal-models.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="style.css">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07-process-tracing-with-models.html">II Model-based Causal Inference</a></li><li class="breadcrumb-item"><a href="./07-process-tracing-with-models.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Process Tracing with Causal Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Integrated Inferences</a> 
        <div class="sidebar-tools-main">
    <a href="./Integrated-Inferences.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Start</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Front matter</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quick guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">I Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-causal-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-illustrating-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Illustrating Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-causal-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Causal Queries</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-being-Bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Answers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-theory-as-causal-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Theories as Causal Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">II Model-based Causal Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-process-tracing-with-models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Process Tracing with Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-PT-application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Process Tracing Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-mixing-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Integrated Inferences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-mixed-application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Integrated Inferences Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-fusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Mixing Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">III Design choices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-clue-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Clue Selection as a Decision Problem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-case-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Case Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-wide-or-deep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Going Wide, Going Deep</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">IV Models in Question</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-justifying-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Justifying Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-evaluating-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Evaluating Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Final Words</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">End matter</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-errata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Errata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p><img src=".\figures/cover_smaller.jpg" class="img-fluid"></p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#the-intuition" id="toc-the-intuition" class="nav-link active" data-scroll-target="#the-intuition"><span class="header-section-number">7.1</span> The Intuition</a></li>
  <li>
<a href="#a-formalization-of-the-general-approach" id="toc-a-formalization-of-the-general-approach" class="nav-link" data-scroll-target="#a-formalization-of-the-general-approach"><span class="header-section-number">7.2</span> A Formalization of the General Approach</a>
  <ul class="collapse">
<li><a href="#the-model" id="toc-the-model" class="nav-link" data-scroll-target="#the-model"><span class="header-section-number">7.2.1</span> The Model</a></li>
  <li><a href="#priors" id="toc-priors" class="nav-link" data-scroll-target="#priors"><span class="header-section-number">7.2.2</span> Priors</a></li>
  <li><a href="#possible-data-types" id="toc-possible-data-types" class="nav-link" data-scroll-target="#possible-data-types"><span class="header-section-number">7.2.3</span> Possible Data Types</a></li>
  <li><a href="#sec-updatingtypes" id="toc-sec-updatingtypes" class="nav-link" data-scroll-target="#sec-updatingtypes"><span class="header-section-number">7.2.4</span> Updating on Types Given the Data</a></li>
  <li><a href="#updating-on-queries" id="toc-updating-on-queries" class="nav-link" data-scroll-target="#updating-on-queries"><span class="header-section-number">7.2.5</span> Updating on Queries</a></li>
  </ul>
</li>
  <li><a href="#mapping-from-models-to-classic-qualitative-tests" id="toc-mapping-from-models-to-classic-qualitative-tests" class="nav-link" data-scroll-target="#mapping-from-models-to-classic-qualitative-tests"><span class="header-section-number">7.3</span> Mapping from Models to Classic Qualitative Tests</a></li>
  <li><a href="#assessing-probative-value-from-a-graph" id="toc-assessing-probative-value-from-a-graph" class="nav-link" data-scroll-target="#assessing-probative-value-from-a-graph"><span class="header-section-number">7.4</span> Assessing Probative Value from a Graph</a></li>
  <li>
<a href="#principles-of-learning" id="toc-principles-of-learning" class="nav-link" data-scroll-target="#principles-of-learning"><span class="header-section-number">7.5</span> Principles of Learning</a>
  <ul class="collapse">
<li><a href="#sec-DAGalone" id="toc-sec-DAGalone" class="nav-link" data-scroll-target="#sec-DAGalone"><span class="header-section-number">7.5.1</span> A DAG Alone Does Not Guarantee Probative Value for a Single Case</a></li>
  <li><a href="#learning-requires-uncertainty" id="toc-learning-requires-uncertainty" class="nav-link" data-scroll-target="#learning-requires-uncertainty"><span class="header-section-number">7.5.2</span> Learning Requires Uncertainty</a></li>
  <li><a href="#population-level-uncertainty-and-case-level-causal-inference" id="toc-population-level-uncertainty-and-case-level-causal-inference" class="nav-link" data-scroll-target="#population-level-uncertainty-and-case-level-causal-inference"><span class="header-section-number">7.5.3</span> Population-Level Uncertainty and Case-Level Causal Inference</a></li>
  </ul>
</li>
  <li>
<a href="#chapter-appendix-process-tracing-with-causalqueries" id="toc-chapter-appendix-process-tracing-with-causalqueries" class="nav-link" data-scroll-target="#chapter-appendix-process-tracing-with-causalqueries"><span class="header-section-number">7.6</span> Chapter Appendix: Process Tracing with <code>CausalQueries</code></a>
  <ul class="collapse">
<li><a href="#example-1-simple-model" id="toc-example-1-simple-model" class="nav-link" data-scroll-target="#example-1-simple-model"><span class="header-section-number">7.6.1</span> Example 1: Simple Model</a></li>
  <li><a href="#example-2-many-clues" id="toc-example-2-many-clues" class="nav-link" data-scroll-target="#example-2-many-clues"><span class="header-section-number">7.6.2</span> Example 2: Many Clues</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07-process-tracing-with-models.html">II Model-based Causal Inference</a></li><li class="breadcrumb-item"><a href="./07-process-tracing-with-models.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Process Tracing with Causal Models</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-HJC7" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Process Tracing with Causal Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-default callout-note callout-titled" title="Chapter summary">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>We show how process tracing can be implemented within a causal-model framework. The chapter outlines a model-based procedure for drawing case-level inferences from within-case evidence. We also show how a key result from the causal-models literature provides a condition for when the observation of a node in a causal model (a “clue”) may be (or certainly will not be) informative and we extract a set of implications for process-tracing strategies.</p>
</div>
</div>
<p>We now show how we can use causal models to address the kinds of problems of causal inference that social scientists frequently grapple with. We begin by demonstrating how we can use causal models to conduct confirmatory process tracing.</p>
<p>Going forward, we conceptualize process tracing somewhat more broadly than some previous treatments. Scholars have sometimes defined the method in terms of the parts of a causal system from which evidence is drawn or in terms of the kinds of questions being asked. For instance, <span class="citation" data-cites="george2005case">George and Bennett (<a href="20-references.html#ref-george2005case" role="doc-biblioref">2005</a>)</span> (p.&nbsp;6) define process tracing, in part, as involving the use of evidence on “the sequence and values of the intervening variables” in a causal chain, while <span class="citation" data-cites="BennettCheckel2015PT">Bennett and Checkel (<a href="20-references.html#ref-BennettCheckel2015PT" role="doc-biblioref">2015</a>)</span> (p.&nbsp;7) specify the method as one undertaken “for the purposes of either developing or testing hypotheses about causal mechanisms that might causally explain” a case. </p>
<p>We take a slightly more ecumenical approach to thinking about the nature of the evidence that may be deployed or the inferential purposes being pursued in process tracing. We consider process tracing to be an approach that seeks to draw causal inferences <em>about a single case</em> using data <em>from</em> that case. The data used may be evidence on intervening steps, on features of context, or on any other potentially informative part of a causal system. Moreover, the causal question that one seeks to answer may be of any kind: whether about the cause of an outcome, the mechanism (or pathway) through which an effect unfolds, or any other query of interest to the analyst, as long as it is a question about the case at hand.</p>
<p>We deal in this chapter with confirmatory process tracing in the sense that our focus is on how to draw causal inferences <em>given</em> a set of background beliefs about how the world works, rather than how to inductively derive theoretical insights from the evidence. We note that other parts of the book — in particular, our treatments of population-level and mixed-data inference in <a href="09-mixing-methods.html" class="quarto-xref"><span>Chapter 9</span></a>, of model-justification in <a href="15-justifying-models.html" class="quarto-xref"><span>Chapter 15</span></a>, and of model-evaluation in <a href="16-evaluating-models.html" class="quarto-xref"><span>Chapter 16</span></a>—show how we can learn about theory from the data within a causal-model framework.</p>
<p>Our purpose in this chapter is to show how process tracing, defined in this manner, can be grounded in a causal model and implemented within a causal-model framework. In a nutshell, the procedure we describe here involves <em>the use of observable nodes on a causal graph to assess the value of one or more unobserved nodes on a causal graph</em> that are informative for our causal query.</p>
<p>There are a number of distinctive advantages to grounding process tracing in a a causal model. First, process tracing from a model maximizes analytic transparency: It allows us to be fully explicit about the background beliefs informing our inferences, about the question we are asking, and about how precisely our answers follow from our prior beliefs and the new evidence that we are assessing. Research audiences and other scholars can then engage with and evaluate our inferences in ways uniquely enabled by formalization: They can scrutinize, call into question, and test for sensitivity to the model that we start with, the way we define our query, or the analytic steps we take upon observing the evidence. The approach also readily allows for the updating of inferences as additional case-level observations are brought to the table.</p>
<p>Second, grounding process tracing in a model enforces logical consistency on the set of beliefs entering into the analysis—such as between our priors on a causal question and our beliefs about the probative value of evidence—since all beliefs are derived from the same underlying model.</p>
<p>Third, as we show in this chapter and later in <a href="12-clue-selection.html" class="quarto-xref"><span>Chapter 12</span></a>, embedding process tracing in a causal model offers a tool for making research design choices: It allows us to derive expectations about the kinds of new evidence that are potentially informative for our query, those that are likely to be <em>most</em> informative given what we have already observed, and the optimal sequence in which to search for within-case clues.</p>
<p>Finally, as we elaborate in <a href="09-mixing-methods.html" class="quarto-xref"><span>Chapter 9</span></a>, process tracing with a causal model opens an opportunity to integrate within-case and cross-case strategies of causal inference, allowing our inferences about individual cases to be informed by patterns observed across a larger set of cases.</p>
<section id="the-intuition" class="level2" data-number="7.1"><h2 data-number="7.1" class="anchored" data-anchor-id="the-intuition">
<span class="header-section-number">7.1</span> The Intuition</h2>
<p></p>
<p>When we undertake process tracing, we seek to answer a causal question about a given case. The key insight driving our approach is that the inference about a causal question for a case is a claim about <em>which causal types (collections of nodal types) are both likely</em> ex ante <em>(given prior knowledge) and consistent with the data</em>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>The question of interest can be about any number of case-level causal features, including questions about a case-level causal effect, the pathway through which an effect operates, an actual cause, or causal attribution. We use observations from the case itself to address this query. We do so via a procedure in which we first encode prior knowledge in the form of a causal model, collect data on some nodes in the model from the case at hand, ask which causal possibilities (causal types) permitted by the model are consistent with the data, and then map those causal possibilities onto the specific causal query we seek to answer.</p>
<p>Given a causal model, we form posteriors over queries as follows: </p>
<ol type="1">
<li>
<strong>Specify all possible causal types for a model</strong>. A causal type, recall, is a particular combination of nodal types for all nodes in a unit. That is, a single causal type specifies both a specific set of values of all exogenous variables in a model and the values that all endogenous variables <em>would</em> potentially take on for all possible values of the other endogenous variables. For a simple, binary <span class="math inline">\(X \rightarrow Y\)</span> model, the number of possible causal types will be 8; that is, 2 (the number of possible values <span class="math inline">\(X\)</span>, the root node, can take on) times 4 (the number of possible nodal types for <span class="math inline">\(Y\)</span>, the endogenous node). To illustrate, three of these causal types would be (writing them out here, rather than using our usual <span class="math inline">\(\theta\)</span> notation):</li>
</ol>
<ul>
<li>Type 1: (<span class="math inline">\(X=1\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X=0\)</span>).</li>
<li>Type 2: (<span class="math inline">\(X=0\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X=0\)</span>).</li>
<li>Type 3: (<span class="math inline">\(X=1\)</span>) <em>and</em> (<span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=1\)</span> if <span class="math inline">\(X=0\)</span>).</li>
</ul>
<p>Whatever the model, we generate a complete set of all possible causal types.</p>
<ol start="2" type="1">
<li><p><strong>Specify priors over causal types.</strong> We report how likely we think it is, ex ante, that a given unit is of a particular causal type. It is sometimes useful to conceive of the case at hand as having been randomly drawn from a broader population; thus, our prior beliefs about the case are equivalent to our beliefs about <em>how common</em> different causal types are in that population. In the simplest situation, we might place 0 weight on some causal types (those that are ruled out by background theory, for example) and equal weight on all others. More generally, we assign a lower probability to those causal types that we believe are relatively less common in the population and a higher probability to those causal types that we think are more common. Note that, in this critical step, we are <em>mobilizing our population-level beliefs</em> to allow us to draw <em>case-level</em> inferences.</p></li>
<li><p><strong>Specify the query in terms of causal types.</strong> For instance, for the simple <span class="math inline">\(X \rightarrow Y\)</span> model, the query “<span class="math inline">\(Y\)</span> responds positively to <span class="math inline">\(X\)</span>” can be thought of as a collection of causal types: Q={Type 1, Type 2}, above.</p></li>
<li><p><strong>Once we observe the data, specify the set of causal types that are consistent with those data.</strong> For instance, if we observe <span class="math inline">\(X=1, Y=1\)</span> we might specify the data-consistent set as {Type 1, Type 3}, excluding Type 2, with which these data are inconsistent.</p></li>
<li><p><strong>Update.</strong> Updating is then done by adding up the prior probabilities on all causal types that are consistent with both the data and the query, and dividing this sum by the sum of prior probabilities on all causal types that are consistent with the data (whether or not they are consistent with the query).</p></li>
</ol>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-7-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-7-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-process-tracing-with-models_files/figure-html/fig-HJ-F-7-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-7-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Logic of simple updating on arbitrary queries.
</figcaption></figure>
</div>
</div>
</div>
<p>This process is represented graphically in <a href="#fig-HJ-F-7-1" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>, where we can think of probabilities as proportionate to areas. Our causal model defines the causal-type space. We then proceed by a process of elimination. Only some of the causal types in the model are consistent with prior knowledge. Only some are consistent with the data that we observe. Finally, any query itself maps onto a subset of the possible causal types. The causal types that remain in contention once we have observed the evidence are those at the intersection of consistency with priors and consistency with the data. <span class="math inline">\(A\)</span> represents those types that are <em>also</em> consistent with a given answer to the query (say, <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>).</p>
<p>Thus, our belief about the query before we have seen the data is the probability of all causal types consistent with our priors and with the query (<span class="math inline">\(A + B\)</span>), as a proportion of the probability of all types consistent with our priors. Once we have seen the data, we have reduced the permissible types to <span class="math inline">\(A + C\)</span>. Our posterior belief on the query is, then, the probability of those remaining types that are also consistent with the query, as a share of the probability of <em>all</em> remaining types, or <span class="math inline">\(A/(A+C)\)</span>.</p>
<p>We now turn to a formalization of these ideas.</p>
</section><section id="a-formalization-of-the-general-approach" class="level2" data-number="7.2"><h2 data-number="7.2" class="anchored" data-anchor-id="a-formalization-of-the-general-approach">
<span class="header-section-number">7.2</span> A Formalization of the General Approach</h2>
<p></p>
<p>The general approach to inference draws on the components we outlined in Chapters 2 to 4: causal models, queries, and priors. Coupled with data, these elements provide grounds for causal inferences. We continue to focus on a situation with binary variables, though we describe later how this can be extended. We walk through the procedure for simple models, though note that the approach outlined here can be applied to <em>any</em> causal model with discrete variables and to any queries defined over the model.</p>
<p>The process tracing procedure operates as follows.</p>
<p></p>
<section id="the-model" class="level3" data-number="7.2.1"><h3 data-number="7.2.1" class="anchored" data-anchor-id="the-model">
<span class="header-section-number">7.2.1</span> The Model</h3>
<p>First we need a model.</p>
<p><strong>A DAG</strong> </p>
<p>We begin with a DAG, or graphical causal model. As discussed in Chapter 2, a DAG identifies a set of variables and describes the parent-child relations between them, indicating for each variable which other variables are its direct (possible) causes. These relationship, in turn, tell us which (non-descendant) variables a given variable is <em>not</em> independent of given the other variables in the model.</p>
<p><strong>Nodal Types</strong> </p>
<p>Once we have specified a DAG, we can determine the full set of possible nodal types: The types defining the value that a variable will take on given the values of its parents, which we have denoted with <span class="math inline">\(\theta^j\)</span> values for node <span class="math inline">\(j\)</span>, as in <span class="math inline">\(\theta^X_{0}\)</span> or <span class="math inline">\(\theta^Y_{10}\)</span>. At each node, the range and number of possible nodal types is defined by the number of parents that that node has and the number of values the variables can take on. For instance, assuming all variables to be binary, if <span class="math inline">\(Y\)</span> has parents <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>, then there are <span class="math inline">\(2^{\left(2^2\right)}=16\)</span>) possible causal types for the <span class="math inline">\(Y\)</span> node.</p>
<p><strong>Causal types</strong></p>
<p></p>
<p>From the set of all possible nodal types for a DAG, we get the set of all possible causal types by simply elaborating all possible permutations of nodal types.</p>
</section><section id="priors" class="level3" data-number="7.2.2"><h3 data-number="7.2.2" class="anchored" data-anchor-id="priors">
<span class="header-section-number">7.2.2</span> Priors</h3>
<p></p>
<p>Our background beliefs about a causal domain will usually consist of more than just beliefs about which variables have causal connections; they will also typically contain beliefs about what <em>kinds</em> of effects operate between variables. That is, they will contain beliefs about which types are possible or, more generally, are more or less common in the world. We express these beliefs over causal effects as probability distributions over the nodal types. Generally, beliefs about causal types are implied by beliefs about nodal types. In cases with unobserved confounding, beliefs are defined over the joint distributions of nodal types.</p>
<p>For process tracing, our beliefs over nodal type <span class="math inline">\(\theta^j\)</span>, say, simply capture the subjective probability we have that the type takes on different values. We do not <em>need</em> to defend this belief to use the machinery. We use <span class="math inline">\(\lambda^j_x\)</span> to denote the probability that <span class="math inline">\(\theta^j = \theta^j_x\)</span>. Often however it helps with intuition to think of a given case of interest—the one we are studying and seek to learn about—as being drawn at random from a population and to think about our beliefs for the <em>single</em> case as stemming from our beliefs about the population from which it is drawn. In this sense, <span class="math inline">\(\lambda^j_x\)</span> can be thought of as the <em>share</em> of cases in that population that we believe to be of type <span class="math inline">\(\theta^j_x\)</span>. So, for instance, our prior belief about the probability that inequality has a positive effect on democratization in Mexico in 1999 is our belief about how commonly inequality has a positive effect on democratization in the population of cases that are “like” Mexico in 1999.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Vector <span class="math inline">\(\lambda^j\)</span> is simply a set of numbers for each possible nodal type, with all numbers non negative and summing to <span class="math inline">\(1\)</span>. So, for instance, <span class="math inline">\(\lambda^Y\)</span> for our current example would be a vector with four values, each of which expresses a probability on one of the four nodal types at <span class="math inline">\(Y\)</span>. So we might have <span class="math inline">\(\lambda^Y_{01}=0.1\)</span>, <span class="math inline">\(\lambda^Y_{11}=0.05\)</span>, and so on—with the <span class="math inline">\(\lambda^Y\)</span> values summing to <span class="math inline">\(1\)</span> because these values are defined over the full set of possible nodal types for <span class="math inline">\(Y\)</span>. For the purposes of this chapter, we take <span class="math inline">\(\lambda\)</span> as given—as the set of population-level beliefs we are operating with. In later chapters however, when we move beyond single cases, <span class="math inline">\(\lambda\)</span> becomes quantity of interest, a parameter we want to learn about from the data.</p>
<p>Consider now beliefs over causal types. Let’s start with a situation in which we assume that the nodal types are independent of one another. We can think of this as a situation in which there is no confounding that is not captured in the graph—no variable missing from the model that is a common ancestor of multiple nodes in the model. In this situation, our beliefs over causal types are simply the product of our beliefs over the component nodal types (since the joint probability of independent events is simply the product of their individual probabilities). For instance, one causal type might be “a unit in which <span class="math inline">\(X=1\)</span> and in which <span class="math inline">\(Y=1\)</span> no matter what value <span class="math inline">\(X\)</span> takes.” In this case, the probability that a case is of this causal type is <span class="math inline">\(\Pr(\theta^X = \theta^X_1)\Pr(\theta^Y = \theta^Y_{11}) = \lambda^X_1\lambda^Y_{11}\)</span>.</p>
<p>The simplest way in which we can express beliefs about the differential probabilities of different causal possibilities is by <em>eliminating</em> nodal types that we do not believe to be possible—setting their <span class="math inline">\(\lambda\)</span> values to <span class="math inline">\(0\)</span>. Suppose, for instance, that we are examining the effect of ethnic diversity on civil war in a case. We might not know whether ethnic diversity causes civil war in this case, but we might have sufficient background knowledge to believe that ethnic diversity never has a <em>negative</em> effect on civil war: It never prevents a civil war from happening that would have happened in the absence of ethnic diversity. We would thus want to set the <span class="math inline">\(\lambda\)</span> value for a negative causal effect to <span class="math inline">\(0\)</span>. If we then know nothing about the relative frequencies of the three remaining nodal types for <span class="math inline">\(Y\)</span> – a positive effect, a null effect with civil war never going to happen, and a null effect with civil war never going to happen – we may (following the principle of indifference) assign an equal weight of one-third to each of them.</p>
<p>In a situation of unobserved confounding, our beliefs over causal types are still well defined, though they are no longer the simple product of beliefs over nodal types. In this situation we need to describe a joint distribution over nodal types. In practice we can do this by specifying a probability for one nodal type and a conditional probability for another. Let us imagine for instance, in a simple <span class="math inline">\(X \rightarrow Y\)</span> model, that we believe that some unobserved factor both affects both the likelihood of <span class="math inline">\(X = 1\)</span> and also <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span>: Maybe, for instance, <span class="math inline">\(X\)</span> is more likely to be assigned to 1 where <span class="math inline">\(X\)</span> has a positive effect. This is the same as saying that the probability distributions over <span class="math inline">\(\theta^X\)</span> and <span class="math inline">\(\theta^Y\)</span> are not independent. Now the probability of any combination of <span class="math inline">\(\theta^X\)</span> and <span class="math inline">\(\theta^Y\)</span> can be calculated using the joint probability formula, <span class="math inline">\(\Pr(A, B) = \Pr(A)\Pr(B|A)\)</span>.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Thus, for instance, <span class="math inline">\(\Pr(\theta^Y = \theta^Y_{01}, \theta^X = \theta^X_1) = \Pr(\theta^Y = \theta^Y_{01})\Pr(\theta^X = \theta^X_1 | \theta^Y = \theta^Y_{01})\)</span>. To form priors over causal types in this situation, we need to posit beliefs about a set of more complex, conditional probabilities for <span class="math inline">\(X\)</span>’s type. Specifically, we need to posit, <em>for those cases</em> with a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, what are the chances a case is “assigned” to <span class="math inline">\(X=1\)</span>; <em>for those cases</em> with a negative effect, what are the chances a case is “assigned” to <span class="math inline">\(X = 1\)</span>; and similarly for other nodal types.</p>
<p>In practice, we represent <span class="math inline">\(\Pr(\theta^X_1, \theta^Y_{01}) = \Pr(\theta^X_1)\Pr(\theta^Y_{01}|\theta^X_1)\)</span> using <span class="math inline">\(\lambda^X_1, \lambda^{Y|\theta^X_1}_{01}\)</span>. The notation is awkward but the key thing is that we have a well defined set of beliefs that we need to take into account to assess the probability of different causal types.</p>
</section><section id="possible-data-types" class="level3" data-number="7.2.3"><h3 data-number="7.2.3" class="anchored" data-anchor-id="possible-data-types">
<span class="header-section-number">7.2.3</span> Possible Data Types</h3>
<p>A <em>data type</em> is a particular pattern of data that we could potentially observe for a given case. More specifically, a data type is a set of values, one for each node in a model. For instance, in an <span class="math inline">\(X \rightarrow Y \leftarrow Z\)</span> model, (X=1, Z=0, Y=0) would be one data type; (X=0, Z=0, Y=1) another. We use <code>X1Z0Y0</code>, or <code>X0Z0Y1</code> as shorthand for such data types.</p>
<p>Importantly, absent intervention, each possible causal type <em>maps deterministically into a single data type.</em> One intuitive way to think about why this is the case is that a causal type tells us (a) the values to which all root variables in a model are assigned and (b) how all other endogenous variables respond to their parents. Given these two components, only one set of node values is possible for a given causal type. For example, causal type <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^Z = \theta^Z_0, \theta^Y = \theta^Y_{0100})\)</span> implies data <span class="math inline">\(X=1, Z=0, Y=1\)</span> (the second digit in the subscript for <span class="math inline">\(\theta^Y\)</span> refers to the potential outcome for <span class="math inline">\(Y\)</span> when <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Z = 0\)</span>). Absent intervention, there is no other set of data that can be generated by this causal type.</p>
<p>Equally importantly, however, <em>the mapping from causal types to data types is not one-to-one.</em> More than one causal type can generate the same case-level data pattern. For instance, the causal type <span class="math inline">\(\theta = (\theta^X = \theta^X_1, \theta^Z = \theta^Z_0, \theta^Y = \theta^Y_{1101})\)</span> will <em>also</em> generate the data type, <span class="math inline">\(X=1, Z=0, Y=1\)</span>. Thus, observing this data type leaves us with ambiguity about the causal type by which it was generated. </p>
<p>We can use an <em>ambiguities matrix</em> to summarize the mapping between causal types and data types. There is a row for each causal type and a column for each data type. An entry of 1 in a given cell indicates that the causal type generates the data type. Each row has a single 1 but each column can have many 1s—an indicator of the ambiguity we have about causal types when we observe a data type.</p>
<p>We illustrate with an ambiguities matrix for a simple <span class="math inline">\(X \rightarrow Y\)</span> model in <a href="#tbl-ambigmatrix" class="quarto-xref">Table&nbsp;<span>7.1</span></a>. In the last column, we provide illustrative prior probabilities that could be placed on each causal type. As discussed above, each causal-type probability would be derived from beliefs about the <span class="math inline">\(\lambda^j\)</span> probabilities for the component nodal types. Note how we can read the ambiguities off of the matrix. For instance, if we observe <span class="math inline">\(X=1, Y=0\)</span> in a case, we face an ambiguity about whether the case’s causal type is <span class="math inline">\(\theta^X_1, \theta^Y_{00}\)</span> or <span class="math inline">\(\theta^X_1, \theta^Y_{10}\)</span>: that is, about whether <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(Y\)</span> in this case or <span class="math inline">\(Y\)</span> would be <span class="math inline">\(0\)</span> in this case regardless of <span class="math inline">\(X\)</span>’s value.</p>
<div id="tbl-ambigmatrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ambigmatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.1: An ambiguities matrix, mapping from data types to causal types for a simple <span class="math inline">\(X \rightarrow Y\)</span> model.
</figcaption><div aria-describedby="tbl-ambigmatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 39%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 30%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X0Y0</th>
<th style="text-align: center;">X1Y0</th>
<th style="text-align: center;">X0Y1</th>
<th style="text-align: center;">X1Y1</th>
<th style="text-align: center;">Priors</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^Y_{11}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>As models get more complex, the numbers of causal and data types multiply, though generally the number of causal types increases faster than the number of data types. For a simple mediation model (<span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>), there are <span class="math inline">\(2^3 = 8\)</span> data types—possible combinations of values for <span class="math inline">\(X,M,Y\)</span> – but <span class="math inline">\(2\times 4 \times 4\)</span> causal types.</p>
<p>The ambiguities matrix tells us which causal types are consistent with the data we observe and, in doing so, shapes our inferences. <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a> shows a portion of the ambiguities matrix for the <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, with priors on causal types appended in the final column. In this model if we observe <span class="math inline">\(X=1, M=0, Y=0\)</span>, for instance, we have ambiguities over causal types. These data tell us that <span class="math inline">\(\theta^X = \theta^X_1\)</span>. But they do not tell us whether <span class="math inline">\(M\)</span>’s type is such that <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(M\)</span> (<span class="math inline">\(\theta^M_{10}\)</span>) or <span class="math inline">\(X\)</span> has no effect with <span class="math inline">\(M\)</span> fixed at <span class="math inline">\(0\)</span> (<span class="math inline">\(\theta^M_{00}\)</span>). Similarly, we do not know whether <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span> (<span class="math inline">\(\theta^Y_{01}\)</span>) or no effect with <span class="math inline">\(Y\)</span> fixed at <span class="math inline">\(0\)</span> (<span class="math inline">\(\theta^Y_{00}\)</span>). This leaves four combinations of nodal types—four causal types—that are consistent with the data. These types are picked out by the ambiguities matrix (two of these four can be seen in the second column of the excerpt of the ambiguities matrix displayed in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>.</p>
<div id="tbl-ambigmatrixmed" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ambigmatrixmed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.2: Excerpt from the ambiguities matrix for a simple mediation model. Rows are causal types, columns are data types. Last column shows possible priors over rows.
</figcaption><div aria-describedby="tbl-ambigmatrixmed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X0M0Y0</th>
<th style="text-align: center;">X1M0Y0</th>
<th style="text-align: center;">X0M1Y0</th>
<th style="text-align: center;">X1M1Y0</th>
<th style="text-align: center;">X0M0Y1</th>
<th style="text-align: center;">X1M0Y1</th>
<th style="text-align: center;">prior</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{00}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{10}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{01}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{11}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11}, \theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{00}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{10}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{01}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_0,\theta^M_{11}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11}, \theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section><section id="sec-updatingtypes" class="level3" data-number="7.2.4"><h3 data-number="7.2.4" class="anchored" data-anchor-id="sec-updatingtypes">
<span class="header-section-number">7.2.4</span> Updating on Types Given the Data</h3>
<p>Once we observe actual data in a case, we can then update on the probabilities assigned to each causal type. The logic is simple. When we observe a set of data from a case, we place <span class="math inline">\(0\)</span> probability on all causal types that could not have produced these data; we then scale up the probabilities on all causal types that could have.</p>
<p>As a simple example, return to our <span class="math inline">\(X\rightarrow Y\)</span> model with equal prior weights (1/8) on each of the eight possible causal types, as in Table 7.1. Now suppose that we observe the data <span class="math inline">\(X=1, Y=1\)</span>, that is, data type <span class="math inline">\(X1Y1\)</span>. These data are consistent with some causal types but not others. Only two causal types are consistent with the data: <span class="math inline">\(\theta^X_1, \theta^Y_{01}\)</span> and <span class="math inline">\(\theta^X_1, \theta^Y_{11}\)</span>. We therefore put 0 weight on all other causal types and scale up the remaining probabilities so that they sum to 1 (preserving the ratio between them). The result gives <em>posterior</em> probabilities on the causal types. We display an “updated” ambiguities matrix, with excluded data types and causal types removed, in <a href="#tbl-ambigupdate" class="quarto-xref">Table&nbsp;<span>7.3</span></a>.</p>
<p>Before we see any data on the case at hand, then, we believe (based on our beliefs about the population to which the case belongs) that there is a 1/8 probability that the case is one in which <span class="math inline">\(X\)</span> is assigned to <span class="math inline">\(1\)</span> and has a positive effect on <span class="math inline">\(Y\)</span>; and 1/8 probability that it’s a case in which <span class="math inline">\(X\)</span> gets assigned to <span class="math inline">\(1\)</span> and has no effect on <span class="math inline">\(Y\)</span> (and so <span class="math inline">\(Y\)</span> is <span class="math inline">\(1\)</span> regardless of <span class="math inline">\(X\)</span>). Seeing the <span class="math inline">\(X=1, Y=1\)</span> data, we now believe that there is a 1/2 probability that the case is of the former type, and a 1/2 probability that it is of the latter type. Had our prior beliefs on types been different from each other, the posterior beliefs would have scaled up accordingly.</p>
<div id="tbl-ambigupdate" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ambigupdate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.3: Ambiguities in an <span class="math inline">\(X \rightarrow Y\)</span> model after observing <span class="math inline">\(X=1, Y=1\)</span> in a case.
</figcaption><div aria-describedby="tbl-ambigupdate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X1Y1</th>
<th style="text-align: center;">Priors</th>
<th style="text-align: center;">Posteriors</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">1/2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^Y_{11}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">1/2</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>We now walk through how this works for the more complex <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model, and the ambiguities matrix in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>. If we observe the data <span class="math inline">\(X=1, M=0, Y=0\)</span>, for instance, this exercise would yield the updated ambiguities matrix in <a href="#tbl-ambigmedupdate" class="quarto-xref">Table&nbsp;<span>7.4</span></a>. Here, we have eliminated all rows (causal types) with a <span class="math inline">\(0\)</span> in the relevant data-type column (<span class="math inline">\(X1M0Y0\)</span>) and formed the posteriors by scaling up the priors in the retained rows.</p>
<div id="tbl-ambigmedupdate" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ambigmedupdate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.4: An updated version of the ambiguities matrix in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, after observing <span class="math inline">\(X=1, M=0, Y=0\)</span> in a case.
</figcaption><div aria-describedby="tbl-ambigmedupdate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 60%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 16%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X1M0Y0</th>
<th style="text-align: center;">Priors</th>
<th style="text-align: center;">Posteriors</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.1667</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.1667</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.3333</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.3333</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>A notable feature of the logic of single-case process tracing is that the relative probabilities on the retained causal types never change. If we start out believing that causal type <span class="math inline">\(A\)</span> is twice as likely as causal type <span class="math inline">\(B\)</span>, and both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are retained once we see the data, then <span class="math inline">\(A\)</span> will be twice as likely as <span class="math inline">\(B\)</span> in our posteriors. All updating occurs by <em>eliminating</em> causal types from consideration and zeroing in on those that remain.</p>
<p>A similar logic applies if partial data are observed: that is, if we do not collect data for all nodes in the model. The one difference is that, now, rather than reducing to one column we entertain the possibility of any data <em>type</em> consistent with the <em>observed data</em>. In general, more than one data type will be consistent with partial data. For instance, suppose that we observe <span class="math inline">\(X=1, Y=0\)</span> but do not observe <span class="math inline">\(M\)</span>’s value. These are data that are consistent with both the data type <span class="math inline">\(X1M0Y0\)</span> and the data type <span class="math inline">\(X1M1Y0\)</span> (since the unobserved <span class="math inline">\(M\)</span> could be either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>). We thus retain both of these data-type columns as well as all causal types consistent with <em>either</em> of these data types. This gives the updated ambiguities matrix in <a href="#tbl-amb-partial" class="quarto-xref">Table&nbsp;<span>7.5</span></a>. We note that, with these partial data, we are not able to update as strongly. For instance, for the causal type <span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span>, instead of updating to a posterior probability of 0.1667, we update to a posterior of only 0.0833—because there is a larger set of causal types with which these partial data are consistent.</p>
<div id="tbl-amb-partial" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-amb-partial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.5: An updated version of the ambiguities matrix in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, after observing partial data in case: <span class="math inline">\(X=1, Y=0\)</span>, with <span class="math inline">\(M\)</span> unobserved.
</figcaption><div aria-describedby="tbl-amb-partial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 52%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 11%">
<col style="width: 15%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X1M0Y0</th>
<th style="text-align: center;">X1M1Y0</th>
<th style="text-align: center;">Priors</th>
<th style="text-align: center;">Posteriors</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0833</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{00}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0833</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.1667</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{00}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0833</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.1667</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{10}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0833</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.1667</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.1667</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section><section id="updating-on-queries" class="level3" data-number="7.2.5"><h3 data-number="7.2.5" class="anchored" data-anchor-id="updating-on-queries">
<span class="header-section-number">7.2.5</span> Updating on Queries</h3>
<p></p>
<p>We now have a posterior probability for each causal type for the case at hand. The causal question we are interested in answering, our query, may not be about causal types <em>per se.</em> In general, causal query can be defined as a <em>combination</em> of causal types, as described in <a href="04-causal-questions.html" class="quarto-xref"><span>Chapter 4</span></a>.</p>
<p>For instance, suppose we are working with the model <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>; and that our question is, “Did <span class="math inline">\(X=1\)</span> cause <span class="math inline">\(Y=1\)</span>?”. This question is asking both:</p>
<ol type="1">
<li><p>Does <span class="math inline">\(X=1\)</span> in this case?</p></li>
<li><p>Does <span class="math inline">\(X\)</span> have a positive effect on <span class="math inline">\(Y\)</span> in this case?</p></li>
</ol>
<p>The causal types that qualify are those, and only those, in which the answer to both is “yes.”</p>
<p>Meeting condition (1) requires that <span class="math inline">\(\theta^X=\theta^X_1\)</span>.</p>
<p>Meeting condition (2) requires that <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span> are such that <span class="math inline">\(X\)</span> has an effect on <span class="math inline">\(M\)</span> that yields a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. This could occur via a positive <span class="math inline">\(X \rightarrow M\)</span> effect linked to a positive <span class="math inline">\(M \rightarrow Y\)</span> effect or via a negative <span class="math inline">\(X \rightarrow M\)</span> effect linked to a negative <span class="math inline">\(M \rightarrow Y\)</span> effect.</p>
<p>Thus, the qualifying causal types in this model are:</p>
<ul>
<li><span class="math inline">\(\theta^X_1, \theta^M_{01}, \theta^Y_{01}\)</span></li>
<li><span class="math inline">\(\theta^X_1, \theta^M_{10}, \theta^Y_{10}\)</span></li>
</ul>
<p>Our <em>prior</em> on the query—what we believe before we collect data on the case at hand—is given simply by summing up the prior probabilities on each of the causal types that correspond to the query. Note that we must calculate the prior from the full ambiguities matrix, before excluding types for inconsistency with the data. Returning to the full ambiguities matrix in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, we see that the priors on these two types (given the population parameters assumed there) are 0.08 and 0.02, respectively, giving a prior for the query of 0.1.</p>
<p> The posterior on any query is, likewise, given by summing up the posterior probabilities on each of the causal types that correspond to the query, drawing of course from the updated ambiguities matrix. For instance, if we observe the data <span class="math inline">\(X=1, M=1, Y=1\)</span>, we update to the ambiguities matrix in <a href="#tbl-ambigmedupdate2" class="quarto-xref">Table&nbsp;<span>7.6</span></a>. Our posterior on the query, “Did <span class="math inline">\(X=1\)</span> cause <span class="math inline">\(Y=1\)</span>?” is the sum of the posteriors on the above two causal types. Since <span class="math inline">\(\theta^X_1, \theta^M_{10}, \theta^Y_{10}\)</span> is excluded by the data, this just leaves the posterior on <span class="math inline">\(\theta^X_1, \theta^M_{01}, \theta^Y_{01}\)</span>, 0.4444, which is the posterior belief on our query.</p>
<p>If we observe only the partial data, <span class="math inline">\(X=1, Y=1\)</span>, then we update to the ambiguities matrix in <a href="#tbl-ambigmedupdatepartial2" class="quarto-xref">Table&nbsp;<span>7.7</span></a>. Now both causal types satisfying the query are included, and we sum their posteriors to get the posterior on the query: <span class="math inline">\(0.08 + 0.31 = 0.39\)</span>.</p>
<div id="tbl-ambigmedupdate2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ambigmedupdate2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.6: An updated version of the ambiguities matrix in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, after observing <span class="math inline">\(X=1, M=1, Y=1\)</span> in a case.
</figcaption><div aria-describedby="tbl-ambigmedupdate2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 59%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 17%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X1M1Y1</th>
<th style="text-align: center;">Priors</th>
<th style="text-align: center;">Posteriors</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">0.4444</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.2222</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.2222</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.1111</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="tbl-ambigmedupdatepartial2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ambigmedupdatepartial2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.7: An updated version of the ambiguities matrix in <a href="#tbl-ambigmatrixmed" class="quarto-xref">Table&nbsp;<span>7.2</span></a>, after observing partial data in case: <span class="math inline">\(X=1, Y=0\)</span>, with <span class="math inline">\(M\)</span> unobserved.
</figcaption><div aria-describedby="tbl-ambigmedupdatepartial2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 53%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 15%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">
<strong>Data types</strong> <span class="math inline">\(\rightarrow\)</span>
</th>
<th style="text-align: center;">X1M0Y0</th>
<th style="text-align: center;">X1M1Y0</th>
<th style="text-align: center;">Priors</th>
<th style="text-align: center;">Posteriors</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<strong>Causal types</strong> <span class="math inline">\(\downarrow\)</span>
</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{10}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0769</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{10}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0769</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">0.3077</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{01}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.1538</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{00},\theta^Y_{11}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0769</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{10},\theta^Y_{11}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0769</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{01},\theta^Y_{11}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.1538</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^X_1,\theta^M_{11},\theta^Y_{11}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.0769</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>For more complex models and queries, it can be more difficult to eyeball the corresponding causal types. In practice, therefore, we use the <code>get_query_types</code> function in the <code>CausalQueries</code> package to do this for us.</p>
<p><br></p>
</section></section><section id="mapping-from-models-to-classic-qualitative-tests" class="level2" data-number="7.3"><h2 data-number="7.3" class="anchored" data-anchor-id="mapping-from-models-to-classic-qualitative-tests">
<span class="header-section-number">7.3</span> Mapping from Models to Classic Qualitative Tests</h2>
<p></p>
<p>The approach we have elaborated here appears different from that described in the literature on process-tracing tests—such as <span class="citation" data-cites="collier2011understanding">Collier (<a href="20-references.html#ref-collier2011understanding" role="doc-biblioref">2011</a>)</span>, <span class="citation" data-cites="BennettBayes">Bennett (<a href="20-references.html#ref-BennettBayes" role="doc-biblioref">2008</a>)</span>, or <span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>—in which one seeks specific evidence that is directly informative about causal propositions: “clues” that arise with different probabilities if one proposition or another is true. In fact, however, the approaches are deeply connected. Specifically, we can think of causal models as providing a <em>justification</em> for the probative value that researchers assign to clues in the classic approach. One can use the predictive probabilities for queries from a model as the prior for the query before starting process tracing; and use the predictive probability of data given a query as likelihoods. In doing so the priors and likelihoods are <em>justified</em> by the model (which of course implies that challenges to the model imply challenges to these quantities).</p>
<p>To see this, let’s write down the probability of observing a given clue conditional on a unit’s causal type using the <span class="math inline">\(\phi\)</span> notation from <span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>. Here, <span class="math inline">\(\phi_{jx}\)</span> refers to the probability of observing a clue, <span class="math inline">\(K\)</span>, in a case of type <span class="math inline">\(j\)</span> when <span class="math inline">\(X=x\)</span>. Assuming an <span class="math inline">\(X\rightarrow K \rightarrow Y\)</span> model and a prior distribution over the lower level causal types (the <span class="math inline">\(\lambda\)</span>’s), we can derive, for an <span class="math inline">\(X=1\)</span> case, the probability of seeing the clue if the case is of type <span class="math inline">\(b\)</span> (positive effect) or of type <span class="math inline">\(d\)</span> (no effect, and <span class="math inline">\(Y\)</span> always <span class="math inline">\(1\)</span>):</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\phi_{b1} &amp; = \frac{\lambda_{01}^{K}\lambda_{01}^{Y}}{\lambda_{01}^{K}\lambda_{01}^{Y}+\lambda_{10}^{K}\lambda_{10}^{Y}}\\
\phi_{d1} &amp; = \frac{\lambda_{11}^{Y}(\lambda_{01}^{K}+\lambda_{11}^{K})+\lambda_{11}^{K}\lambda_{01}^{Y}}{\lambda_{11}^{Y} + \lambda_{00}^{K}\lambda_{10}^{Y} + \lambda_{11}^{K}\lambda_{01}^{Y}}
\end{split}
\label{eqn:phisfromlambdas}
\end{equation}\]</span></p>
<p>These quantities allow for easy mapping between our prior beliefs about our causal query—as expressed in the lower level model—and the classic process-tracing tests in <span class="citation" data-cites="Van-Evera:1997">Van Evera (<a href="20-references.html#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span>. <a href="#fig-HJ-F-7-2" class="quarto-xref">Figure&nbsp;<span>7.2</span></a> illustrates this mapping. In each panel, we manipulate a prior for one or more of the lower level causal effects, keeping all other priors flat, relative to ech other, and we see how probative value changes. As the curves for <span class="math inline">\(\phi_b\)</span> and <span class="math inline">\(\phi_d\)</span> diverge, probative value is increasing since there is an increasing difference between the probability of seeing the clue if <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span> and the probability of seeing the clue if <span class="math inline">\(X\)</span> has no effect. </p>
<p>In the left panel, we see that as we place a lower prior probability on <span class="math inline">\(K\)</span>’s being negatively affected by <span class="math inline">\(X\)</span>, (that is as we move left),<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> seeking <span class="math inline">\(K=1\)</span> increasingly takes on the quality of a hoop test for <span class="math inline">\(X\)</span>’s having a positive effect on <span class="math inline">\(Y\)</span>. The clue, that is, increasingly becomes something we must see if <span class="math inline">\(X\)</span> positively affects <span class="math inline">\(Y\)</span>, with the clue remaining moderately probable if there is no effect. Why? The less likely we believe it is that <span class="math inline">\(K=0\)</span> was caused by <span class="math inline">\(X=1\)</span>, the less consistent the observation of <span class="math inline">\(K=0\)</span> is with <span class="math inline">\(X\)</span> having a positive causal effect on <span class="math inline">\(Y\)</span> via <span class="math inline">\(K\)</span> (since, to have such an effect, if <span class="math inline">\(X=1\)</span> and <span class="math inline">\(K=0\)</span>, would precisely have to mean that <span class="math inline">\(X=1\)</span> <em>caused</em> <span class="math inline">\(K=0\)</span>).</p>
<p>In the second graph, we simultaneously change the prior probabilities of zero effects at both stages in the sequence: of <span class="math inline">\(K\)</span> and <span class="math inline">\(Y\)</span> being <span class="math inline">\(1\)</span> regardless of the values of <span class="math inline">\(X\)</span> and <span class="math inline">\(K\)</span>, respectively.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> We see here that, as the probabilities of zero effects jointly diminish (again, moving left), seeking <span class="math inline">\(K=1\)</span> increasingly becomes a smoking-gun test for a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>: the probability of seeing the clue if the case is a <span class="math inline">\(d\)</span> type diminishes. The reason is that, as zero effects at the lower level become less likely, it becomes increasingly unlikely that <span class="math inline">\(K=1\)</span> could have occurred without a positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(K\)</span>, and that <span class="math inline">\(Y=1\)</span> could have occurred (given that we have seen <span class="math inline">\(K=1\)</span>) without a positive effect of <span class="math inline">\(K\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>In sum, when we undertake process tracing with a causal model, the probative value of the evidence derives in a systematic way from our prior beliefs about causal relations in the domain of interest – that is, from a lower-level model together with our beliefs about which causal effects are more or less likely to be operating in that model.</p>
<div class="cell" data-layout-align="center" data-errors="false">
<div class="cell-output-display">
<div id="fig-HJ-F-7-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-7-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-process-tracing-with-models_files/figure-html/fig-HJ-F-7-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="864">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-7-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: The probability of observing <span class="math inline">\(K\)</span> given causal types for different beliefs on lower level causal effects.
</figcaption></figure>
</div>
</div>
</div>
</section><section id="assessing-probative-value-from-a-graph" class="level2" data-number="7.4"><h2 data-number="7.4" class="anchored" data-anchor-id="assessing-probative-value-from-a-graph">
<span class="header-section-number">7.4</span> Assessing Probative Value from a Graph</h2>
<p> </p>
<p>As we have argued, causal queries can be expressed as collections of combinations of nodal types (i.e., as collections of causal types) in a causal model. A nodal type is itself represented as an unobservable node in a model—as a <span class="math inline">\(\theta^j\)</span> pointing into node <span class="math inline">\(j\)</span>. Thus, causal inference in this framework is <em>the use of observable nodes on a causal graph to assess the value of one or more unobserved nodes on a causal graph.</em> Placing our queries on the graph together with the observable nodes has the important advantage of allowing us to graphically identify the possibilities for learning about these queries: that is, to figure out which observable nodes are potentially informative about a given query.</p>
<p>To think through the logic of potential probative value, it is useful to distinguish among three different features of the world, as represented in our causal model: there are the things we want to learn about; the things we have already observed; and the things we could observe. As notation going forward, we let:</p>
<ul>
<li>
<span class="math inline">\(Q\)</span> denote the <em>set</em> of <span class="math inline">\(\theta^j\)</span> nodes that define our <em>query</em>; usually <span class="math inline">\(Q\)</span> cannot be directly observed so that its values must be inferred;</li>
<li>
<span class="math inline">\(W\)</span> denote a <em>set</em> of previously observed nodes in the causal model; and</li>
<li>
<span class="math inline">\(K\)</span> denote a <em>set</em> of additional variables—clues—that we have not yet observed but could observe.</li>
</ul>
<p>Now suppose that we seek to design a research project to investigate a causal question. How should the study be designed? Given that there are some features of the world that we have already observed, which additional clues should we seek to collect to shed new light on our question? In terms of the above notation, what we need to figure out is whether a given <span class="math inline">\(K\)</span> might be informative about—might provide additional leverage on—<span class="math inline">\(Q\)</span> given the prior observation of <span class="math inline">\(W\)</span>.</p>
<p>To ask whether one variable (or set of variables) is informative about another is to ask whether the two (sets of) variables are, on average, related with one another, given whatever we already know. Conversely, if two variables’ distributions are fully <em>independent</em> of one another (conditional on what else we have observed), then knowing the value of one variable can provide no new information about the value of the other.</p>
<p>Thus, asking whether a set of clues, <span class="math inline">\(K\)</span>, is informative about <span class="math inline">\(Q\)</span> given the prior observation of <span class="math inline">\(W\)</span>, is equivalent to asking whether <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> are conditionally independent given <span class="math inline">\(W\)</span>. That is, <span class="math inline">\(K\)</span> can be informative about <span class="math inline">\(Q\)</span> given <span class="math inline">\(W\)</span> only if <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> are <em>not</em> conditionally independent of one another given <span class="math inline">\(W\)</span>. </p>
<p>As our discussion of conditional independence in <a href="02-causal-models.html" class="quarto-xref"><span>Chapter 2</span></a> implies, as long as we have built <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(W\)</span> into our causal model of the phenomenon of interest, we can answer this kind of question by inspecting the structure of the model’s DAG. In particular, what we need to go looking for are relationships of <em><span class="math inline">\(d\)</span>-separation</em>. The following proposition, with only the names of the variable sets altered, is from <span class="citation" data-cites="pearl2009causality">Pearl (<a href="20-references.html#ref-pearl2009causality" role="doc-biblioref">2009</a>)</span> (Proposition 1.2.4):</p>
<p> <strong>Proposition 1:</strong> If sets <span class="math inline">\(Q\)</span> and <span class="math inline">\(K\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(W\)</span> in a DAG, <span class="math inline">\(\mathcal G\)</span>, then <span class="math inline">\(Q\)</span> is independent of <span class="math inline">\(K\)</span> conditional on <span class="math inline">\(W\)</span> in every distribution compatible with <span class="math inline">\(\mathcal G\)</span>. Conversely, if <span class="math inline">\(Q\)</span> and <span class="math inline">\(K\)</span> are <em>not</em> <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(W\)</span> in <span class="math inline">\(\mathcal G\)</span>, then <span class="math inline">\(Q\)</span> and <span class="math inline">\(K\)</span> are dependent conditional on <span class="math inline">\(W\)</span> in at least one distribution compatible with <span class="math inline">\(\mathcal G\)</span>.</p>
<p>We begin with a causal graph and a set of nodes on the graph (<span class="math inline">\(W\)</span>) that we have already observed. Given what we have already observed, <em>a collection of clue nodes, <span class="math inline">\(K\)</span>, will be uninformative about the query nodes, <span class="math inline">\(Q\)</span>, if <span class="math inline">\(K\)</span> is <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(Q\)</span> by <span class="math inline">\(W\)</span> on the graph.</em> (Equivalently, <span class="math inline">\(K\)</span>, will be uninformative about <span class="math inline">\(Q\)</span>, given that we have already observed <span class="math inline">\(W\)</span>, if <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> are conditionally independent given <span class="math inline">\(W\)</span>.) When <span class="math inline">\(W\)</span> <span class="math inline">\(d\)</span>-separates <span class="math inline">\(K\)</span> from <span class="math inline">\(Q\)</span>, this means that what we have already observed already captures all information that the clues might yield about our query. On the other hand, if <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> are <span class="math inline">\(d\)</span>-connected (i.e., not <span class="math inline">\(d\)</span>-separated) by <span class="math inline">\(W\)</span>, then <span class="math inline">\(K\)</span> is <em>possibly</em> informative about <span class="math inline">\(Q\)</span>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Note, moreover, that under quite general conditions (referred to in the literature as the <em>faithfulness</em> of a probability distribution), there are then at least <em>some</em> values of <span class="math inline">\(W\)</span> for which <span class="math inline">\(K\)</span> <em>will</em> be informative about <span class="math inline">\(Q\)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Let us examine Proposition 1 in practice. We begin with the simplest case possible, and then move on to more complex models.</p>
<p>The very simplest probabilistic causal graph, shown in <a href="#fig-HJ-F-7-3" class="quarto-xref">Figure&nbsp;<span>7.3</span></a>, has <span class="math inline">\(X\)</span> influencing <span class="math inline">\(Y\)</span>, with <span class="math inline">\(X\)</span> determined by a coin flip. If we want to know <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span>, this query is defined solely in terms of <span class="math inline">\(Y\)</span>’s nodal type, <span class="math inline">\(\theta^Y\)</span>. To help us conceptualize the more general point about informativeness for queries, we relabel <span class="math inline">\(\theta^Y\)</span> as <span class="math inline">\(Q\)</span> to emphasize the fact that this node represents our query.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-7-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-7-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-process-tracing-with-models_files/figure-html/fig-HJ-F-7-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-7-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: A simple causal model in which the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a given case depends on the case’s nodal type for <span class="math inline">\(Y\)</span> (here marked <span class="math inline">\(Q\)</span> to highlight that this quantity is the query of interest).
</figcaption></figure>
</div>
</div>
</div>
<p>Let us assume that we have observed nothing yet in this case and then ask what clue(s) might be informative about <span class="math inline">\(Q\)</span>, the node of interest. The other two nodes in the graph are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>: These are thus the possible clues that we might go looking for in our effort to learn about <span class="math inline">\(Q\)</span> (i.e., they are the possible members of <span class="math inline">\(K\)</span>).</p>
<p>First, can we learn about <span class="math inline">\(Q\)</span> by observing <span class="math inline">\(X\)</span>? We can answer this question by asking whether <span class="math inline">\(X\)</span> is <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> on the graph given what we have already observed (which is nothing). We can see visually that there is no active path from <span class="math inline">\(X\)</span> to <span class="math inline">\(Q\)</span>: The only path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> is blocked by colliding arrow heads. Thus, <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> are <span class="math inline">\(d\)</span>-separated, meaning that <span class="math inline">\(X\)</span> will not be informative about <span class="math inline">\(Q\)</span>: observing the value that a causal variable takes on in a case—having seen nothing else in the case—tells us nothing whatsoever about that variable’s effect on the outcome. If we want to know whether a case is of a type in which the presence of natural resources would cause civil war, for instance, observing only that the case has natural resources does not help answer the question.</p>
<p>What, then, if we instead were to observe only <span class="math inline">\(Y\)</span>? Is <span class="math inline">\(Y\)</span> <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> given what we have already observed (which, again, is nothing)? It is: the arrow from <span class="math inline">\(Q\)</span> to <span class="math inline">\(Y\)</span> is an active path. Observing only the <em>outcome</em> in a case does tell us something about causal effects. Returning to the natural resources and civil war example, observing only that a country has had a civil war is informative about the case’s causal type (the value of <span class="math inline">\(Q\)</span>). In particular, it rules out the possibility that this is a case in which nothing could cause a civil war: that is, it excludes <span class="math inline">\(\theta^Y_{00}\)</span> (i.e., <span class="math inline">\(c\)</span>-type) as a possible value of <span class="math inline">\(Q\)</span>.</p>
<p>Suppose now, having observed <span class="math inline">\(Y\)</span>, that we were to consider also observing <span class="math inline">\(X\)</span>. Would we learn anything further about <span class="math inline">\(Q\)</span> from doing so? We have already seen that observing <span class="math inline">\(X\)</span> alone yields no information about <span class="math inline">\(Q\)</span> because the two nodes are unconditionally <span class="math inline">\(d\)</span>-separated, the path between them blocked by the colliding arrowheads at <span class="math inline">\(Y\)</span>. However, as we have seen, observing a collider variable (or one of its descendants) <em>unblocks</em> the flow of information, generating relations of conditional dependence across the colliding arrowheads. Here, <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> are <span class="math inline">\(d\)</span>-connected by <span class="math inline">\(Y\)</span>: Thus, if we have <em>already</em> observed <span class="math inline">\(Y\)</span>, then observing <span class="math inline">\(X\)</span> does confer additional information about <span class="math inline">\(Q\)</span>. Knowing only that a country has natural resources tells us nothing about those resources’ effect on civil war in that country. But if we already know that the country has a civil war, then learning that the country has natural resources helps narrow down the case’s possible nodal types for <span class="math inline">\(Y\)</span>. Having already used the observation of <span class="math inline">\(Y=1\)</span> to rule out the possibility of <span class="math inline">\(\theta^Y_{00}\)</span>, observing <span class="math inline">\(X=1\)</span> <em>together with</em> <span class="math inline">\(Y=1\)</span> allows us to additionally rule out the possibility that natural resources <em>prevent</em> civil war, that is, that <span class="math inline">\(Q=\theta^Y_{10}\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>Finally, what if we observe <span class="math inline">\(X\)</span> first and are considering whether to seek information about <span class="math inline">\(Y\)</span>? Would doing so be informative? <span class="math inline">\(X\)</span> does not <span class="math inline">\(d-\)</span>separate <span class="math inline">\(Q\)</span> from <span class="math inline">\(Y\)</span>; thus, observing <span class="math inline">\(Y\)</span> will be informative about <span class="math inline">\(Q\)</span>. In fact, observing <span class="math inline">\(Y\)</span> if we have already seen <span class="math inline">\(X\)</span> is <em>more</em> informative than observing <span class="math inline">\(Y\)</span> alone. The reasoning follows the logic of collision discussed just above. If we observe <span class="math inline">\(Y\)</span> having already seen <span class="math inline">\(X\)</span>, not only do we reap the information about <span class="math inline">\(Q\)</span> provided by <span class="math inline">\(Y\)</span>’s correlation with <span class="math inline">\(Q\)</span>; we simultaneously open up the path between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span>, learning additionally from the conditional dependence between <span class="math inline">\(X\)</span> and <span class="math inline">\(Q\)</span> given <span class="math inline">\(Y\)</span>.</p>
<p>We put Proposition 1 to work in a slightly more complex set of models in <a href="#fig-HJ-F-7-4" class="quarto-xref">Figure&nbsp;<span>7.4</span></a>. Here we investigate the informativeness of a clue that is neither <span class="math inline">\(X\)</span> nor <span class="math inline">\(Y\)</span>. Each graph in <a href="#fig-HJ-F-7-4" class="quarto-xref">Figure&nbsp;<span>7.4</span></a> has four variables: <span class="math inline">\(X\)</span>; <span class="math inline">\(Y\)</span>; a possible clue, <span class="math inline">\(K\)</span>; and a node, <span class="math inline">\(Q\)</span>, representing the query. It is probably most intuitive to think of <span class="math inline">\(Q\)</span> in these graphs simply as <span class="math inline">\(\theta^Y\)</span>; but we leave the notation a bit more general to emphasize that any query can be composed of multiple nodal types.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>We draw all 34 possible graphs with variables <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, <span class="math inline">\(K\)</span>, and <span class="math inline">\(Q\)</span> for causal models in which (a) all variables are connected to at least one other variable, (b) <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> either directly or indirectly, and (c) <span class="math inline">\(Q\)</span> is a direct cause of <span class="math inline">\(Y\)</span> but is not caused by any other variable in the model. The title of each panel reports <span class="math inline">\(K\)</span>’s conditional informativeness using principles of <span class="math inline">\(d\)</span>-separation: It tells us when <span class="math inline">\(K\)</span> is possibly informative about <span class="math inline">\(Q\)</span> depending on whether <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, both, or none are observed.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="cell" data-layout-align="center" data-errors="false">
<div class="cell-output-display">
<div id="fig-HJ-F-7-4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-7-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-process-tracing-with-models_files/figure-html/fig-HJ-F-7-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1056">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-7-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: All connected directed acyclic graphs over <span class="math inline">\(XYKQ\)</span> in which <span class="math inline">\(Q\)</span> is a root node that directly causes <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is a direct or indirect cause of <span class="math inline">\(Y\)</span>. Graph titles indicate conditions under which <span class="math inline">\(K\)</span> can be informative about <span class="math inline">\(Q\)</span> given prior observation of <span class="math inline">\(X\)</span> <span class="math inline">\(Y\)</span> both or neither (0).
</figcaption></figure>
</div>
</div>
</div>
<p>The results show us not just what kinds of variables can be informative about the nodal types operating in a case but also what combinations of observations yield leverage on case-level causal effects. A number of features of the graphs are worth highlighting:</p>
<ul>
<li>
<strong>Clues at Many Stages.</strong> Process tracing has focused a great deal on observations that lie “along the path” between suspected causes and outcomes. What we see in <a href="#fig-HJ-F-7-4" class="quarto-xref">Figure&nbsp;<span>7.4</span></a>, however, is that observations at many different locations in a causal model can be informative about causal effects. We see here that <span class="math inline">\(K\)</span> can be informative when it is pre-treatment (causally prior to <span class="math inline">\(X\)</span>—e.g., panel (3)), post-treatment but pre-outcome (i.e., “between” <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as, e.g., in panel (20)), an auxiliary effect of <span class="math inline">\(X\)</span> that itself has no effect on <span class="math inline">\(Y\)</span> (e.g., in panel (19)), a post-outcome observation (after <span class="math inline">\(Y\)</span>—e.g., in panel (15)), or a joint effect of both the suspected cause and the main outcome of interest (e.g., panel (31)).</li>
</ul>
<p><strong>Mediator Clues</strong>. </p>
<p>While clues that lie in between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> may be informative, how informative they are depends on what else is known. For instance, when a clue serves <em>only</em> as a mediator in our model (i.e., its only linkages are being caused by <span class="math inline">\(X\)</span> and affecting <span class="math inline">\(Y\)</span> and <span class="math inline">\(Q\)</span> points only into <span class="math inline">\(Y\)</span>, as in panels (20) and (21), the clue is only informative about <span class="math inline">\(Q\)</span> if we have also observed the outcome, <span class="math inline">\(Y\)</span>. Of course, this condition may commonly be met—qualitative researchers usually engage in retrospective research and learn the outcome of the cases they are studying early on—but it is nonetheless worth noting why it matters: In this setup, <span class="math inline">\(K\)</span> is unconditionally <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(Q\)</span> by the collision at <span class="math inline">\(Y\)</span>; it is only by observing <span class="math inline">\(Y\)</span> (the collider) that the path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> becomes unblocked. (As we saw above, the very same is true for observing <span class="math inline">\(X\)</span>; it is only when we know <span class="math inline">\(Y\)</span> that <span class="math inline">\(X\)</span> is informative about <span class="math inline">\(Q\)</span>.)</p>
<p>In short, observations along causal paths are more helpful in identifying causal effects to the extent that we have measured the outcome. Importantly, this is not the same as saying that mediator clues are <em>only</em> informative about causal effects where we have observed the outcome. Observing <span class="math inline">\(Y\)</span> is necessary for the mediator to be informative about a <span class="math inline">\(Q\)</span> term that is connected only to <span class="math inline">\(Y\)</span>. Observing a mediator without the outcome, however, could still be informative about the overall effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> by providing leverage on how the mediator responds to <span class="math inline">\(X\)</span>, which is itself informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> via the mediator.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> Moreover, observing the mediator could be informative without the observation of <span class="math inline">\(Y\)</span> if, for instance, <span class="math inline">\(Q\)</span> also points into <span class="math inline">\(K\)</span> itself or into a cause of <span class="math inline">\(K\)</span>. As we discuss below, the clue then is informative as a “symptom” of one or more nodal types, generating learning that does not hinge on observing the outcome.</p>
<p><strong>Symptoms as Clues.</strong> </p>
<p>Some clues may themselves be affected by <span class="math inline">\(Q\)</span>: that is to say, they may be symptoms of the same conditions that determine causal effects in a case. Imagine, for instance, a model of political corruption in which how politicians respond to institutional structures—whether institutions, <span class="math inline">\(X\)</span>, curb their tendency to act corruptly, <span class="math inline">\(Y\)</span>—depends on their underlying motives. Institutions that strengthen governmental transparency and accountability, for instance, might reduce corruption among those politicians who value long-term policy influence but not among those who value only short-run personal enrichment. In this model, politicians’ motives essentially operate as an unobservable nodal type, in the position of <span class="math inline">\(Q\)</span>, determining institutions’ effects on corruption. While we cannot directly observe politicians’ motives, however, there may be <em>consequences</em> of politicians’ motives that are observable: for instance, whether politicians regularly make policy decisions with broad, long-run societal benefits. While such policy decisions would not be part of the causal chain generating institutions’ effect on corruption, observing those policy decisions (or the lack of them) would be informative about that effect because these decisions are a symptom of the same conditions (politicians’ motives) that enable or disable the effect.</p>
<p>We see that <span class="math inline">\(K\)</span> is a child or descendant of <span class="math inline">\(Q\)</span> in several of the graphs in <a href="#fig-HJ-F-7-4" class="quarto-xref">Figure&nbsp;<span>7.4</span></a>: <span class="math inline">\(Q\)</span> directly causes <span class="math inline">\(K\)</span> in panels (7) through (14), (17), (18), (25)-(30), (33), and (34); <span class="math inline">\(Q\)</span> causes <span class="math inline">\(K\)</span> only indirectly through <span class="math inline">\(X\)</span> in panels (22) through (24); <span class="math inline">\(Q\)</span> causes <span class="math inline">\(K\)</span> only indirectly through <span class="math inline">\(Y\)</span> in panels (15), (16), and (31); and <span class="math inline">\(Q\)</span> causes <span class="math inline">\(K\)</span> only indirectly through <span class="math inline">\(X\)</span> and through <span class="math inline">\(Y\)</span> in panel (32). We can then use the principle of <span class="math inline">\(d\)</span>-separation to figure out when the symptom clue is potentially informative, given what we have already observed. It is easy to see that <span class="math inline">\(K\)</span> is potentially informative, no matter what we have already observed, if <span class="math inline">\(K\)</span> is directly affected by <span class="math inline">\(Q\)</span>; there is nothing we could observe that would block the <span class="math inline">\(Q \rightarrow K\)</span> path. Thus, <span class="math inline">\(Q\)</span>’s “symptom” can, in this setup, contain information about type above and beyond that contained in the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values. However, where <span class="math inline">\(Q\)</span> affects <span class="math inline">\(K\)</span> only through some other variable, observing that other variable renders <span class="math inline">\(K\)</span> uninformative by blocking the <span class="math inline">\(Q\)</span>-to-<span class="math inline">\(K\)</span> path. For instance, where <span class="math inline">\(Q\)</span> affects <span class="math inline">\(K\)</span> indirectly through <span class="math inline">\(X\)</span>, once we observe <span class="math inline">\(X\)</span>, we already have all the information about <span class="math inline">\(Q\)</span> that would be contained in <span class="math inline">\(K\)</span>.</p>
<p><strong>Surrogates as Clues.</strong> </p>
<p>Clues may be consequences of the outcome, as in graphs (15) and (16). If <span class="math inline">\(K\)</span> is a consequence <em>only</em> of <em>Y</em>, then it will contain no new information about <span class="math inline">\(Q\)</span> when <span class="math inline">\(Y\)</span> is already known. However, in situations where the outcome has not been observed, <span class="math inline">\(K\)</span> can act as a “surrogate” for the outcome and thus yield leverage on <span class="math inline">\(Q\)</span> (<span class="citation" data-cites="frangakis2002principal">Frangakis and Rubin (<a href="20-references.html#ref-frangakis2002principal" role="doc-biblioref">2002</a>)</span>). A researcher might, for instance, want to understand causal effects on an outcome that is difficult to directly observe: consider, studies that seek to explain ideational change. Ideas themselves, the <span class="math inline">\(Y\)</span> in such studies, are not directly observable. However, their consequences—such as statements by actors or policy decisions—will be observable and can thus serve as informative surrogates for the outcome of interest.</p>
<p>Clues may similarly serve as surrogates of a cause, as in graphs (19) and (22). Here <span class="math inline">\(X\)</span> causes <span class="math inline">\(K\)</span>, but <span class="math inline">\(K\)</span> plays no role in the causal process generating <span class="math inline">\(Y\)</span>. <span class="math inline">\(K\)</span> is of no help if we can directly measure <span class="math inline">\(X\)</span> since the latter <span class="math inline">\(d\)</span>-separates <span class="math inline">\(K\)</span> from <span class="math inline">\(Q\)</span>. But if an explanatory variable cannot be directly measured—consider, again, ideas or preferences as causes—then its consequences, including those that have no relationship to the outcome of interest, can provide leverage on the case-level causal effect.</p>
<p>Clues can also be a consequence of both our suspected cause and the outcome of interest, thus serving as what we might call “double surrogates,” as in panels (31) and (32). Here, <span class="math inline">\(X\)</span> is a direct cause of <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K\)</span> is a joint product of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. A double surrogate can be informative as long as we have not already observed both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Where data on either <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> are missing, there is an open path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>. If we have already observed both, however, then there is nothing left to be learned from <span class="math inline">\(K\)</span>.</p>
<p><strong>Instruments as Clues.</strong> </p>
<p>Clues that are causally prior to an explanatory variable, and have no other effect on the outcome, can sometimes be informative. Consider, for instance, graph (3). Here <span class="math inline">\(K\)</span> is the only cause of <span class="math inline">\(X\)</span>. It can thus serve as a proxy. If we have seen <span class="math inline">\(X\)</span>, then <span class="math inline">\(X\)</span> blocks the path between <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, and so <span class="math inline">\(K\)</span> is unhelpful. <span class="math inline">\(K\)</span> can be informative, though, if we have <em>not</em> observed <span class="math inline">\(X\)</span>. Note that informativeness here still requires that we observe <span class="math inline">\(Y\)</span>. Since <span class="math inline">\(Y\)</span> is a collider for <span class="math inline">\(Q\)</span> and the <span class="math inline">\(K \rightarrow X \rightarrow Y\)</span> chain, we need to observe <span class="math inline">\(Y\)</span> in order to <span class="math inline">\(d\)</span>-connect <span class="math inline">\(K\)</span> to <span class="math inline">\(Q\)</span>.</p>
<p>A rather different setup appears in graph (5), where both <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> cause <span class="math inline">\(X\)</span>. Now the conditions for <span class="math inline">\(K\)</span>’s informativeness are broader. Observing <span class="math inline">\(X\)</span> still makes <span class="math inline">\(K\)</span> uninformative as a proxy for <span class="math inline">\(X\)</span> itself. However, because <span class="math inline">\(X\)</span> is a collider for <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span>, observing <span class="math inline">\(X\)</span> <em>opens up</em> a path from <span class="math inline">\(K\)</span> to <span class="math inline">\(Q\)</span>, rendering a dependency between them. Still, we have to observe at least one of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> for the instrument to be informative here. This is because both of <span class="math inline">\(K\)</span>’s paths to <span class="math inline">\(Q\)</span> run through a collision that we need to unblock by observing the collider. For one path, the collider is <span class="math inline">\(X\)</span>; for the other path, the collider is <span class="math inline">\(Y\)</span>.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> </p>
<p>Other patterns involving instrumentation are also imaginable, though not graphed here. For example, we might have a causal structure that combines instrumentation and surrogacy. Suppose that <span class="math inline">\(X\)</span> is affected by <span class="math inline">\(Q\)</span> and by an unobservable variable <span class="math inline">\(\theta_X\)</span>; and that <span class="math inline">\(\theta_X\)</span> has an observable consequence, <span class="math inline">\(K\)</span>. Then, <span class="math inline">\(K\)</span>, though not a cause of <span class="math inline">\(X\)</span>, is a “surrogate instrument” <span class="citation" data-cites="hernan2006instruments">(<a href="20-references.html#ref-hernan2006instruments" role="doc-biblioref">Hernán and Robins 2006</a>)</span> as it is a descendant of an unobserved instrument, <span class="math inline">\(U\)</span>, and thus allows us to extract inferences similar to those that we could draw from a true instrument. </p>
<p><strong>Confounders as Clues.</strong> </p>
<p>In several of the graphs, <span class="math inline">\(K\)</span> is a confounder in that it is a direct cause of both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (panels (4), (6), (12), and (14)). Let us focus on graph (4), which isolates <span class="math inline">\(K\)</span>’s role as a confounder. Here, <span class="math inline">\(K\)</span> can be informative via two possible paths. First, if <span class="math inline">\(X\)</span> is not observed but <span class="math inline">\(Y\)</span> is, then <span class="math inline">\(K\)</span> is <span class="math inline">\(d\)</span>-connected to <span class="math inline">\(Q\)</span> along the path <span class="math inline">\(K \rightarrow X \rightarrow Y \leftarrow Q\)</span>. <span class="math inline">\(K\)</span> is in this sense serving as a proxy for <span class="math inline">\(X\)</span>, with its path to <span class="math inline">\(Q\)</span> opened up by the observation of the collider, <span class="math inline">\(Y\)</span>. Second, with <span class="math inline">\(Y\)</span> observed, <span class="math inline">\(K\)</span> can provide information on <span class="math inline">\(Q\)</span> via the more direct collision, <span class="math inline">\(K \rightarrow Y \leftarrow Q\)</span>. If <span class="math inline">\(X\)</span> <em>is</em> observed, then the first path is blocked, but the second still remains active. As with any pre-outcome variable, for a confounder clue to provide purchase on <span class="math inline">\(Y\)</span>’s nodal type, <span class="math inline">\(Y\)</span> itself must be observed.</p>
<p>In a sense, then, the role of confounders as clues in case-level inference is the mirror image of the role of confounders as covariates in cross-case correlational inference. In a correlational inferential framework, controlling for a variable in <span class="math inline">\(K\)</span>’s position in graph (5) renders the <span class="math inline">\(X, Y\)</span> correlation (which we assume to be observed) informative about <span class="math inline">\(X\)</span>’s average causal effect. When we use confounders as evidence in within-case inference, it is our observations of other variables that determine how informative the confounder <em>itself</em> will be about <span class="math inline">\(X\)</span>’s causal effect.</p>
<p>It is important to be precise about the kinds of claims that one can make from graphs like those in <a href="#fig-HJ-F-7-4" class="quarto-xref">Figure&nbsp;<span>7.4</span></a>. The graphs in this figure allow us to identify informativeness about an unobserved node <span class="math inline">\(Q\)</span> that is a parent of <span class="math inline">\(Y\)</span>. This setup does not, however, capture all the ways in which clues can be informative about the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> or about other causal queries of interest. For instance, as noted above, even if a clue is uninformative about a <span class="math inline">\(Q\)</span> node pointing into <span class="math inline">\(Y\)</span>, it may still help establish whether <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>: The statement that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> will for some graphs be a statement about a <em>collection</em> of nodes that comprise the query. This is the case, for instance, in any graph of the form <span class="math inline">\(X \rightarrow M  \rightarrow Y\)</span>, where we are interested not just in <span class="math inline">\(Y\)</span>’s response to <span class="math inline">\(M\)</span> (the mediator) but also in <span class="math inline">\(M\)</span>’s response to <span class="math inline">\(X\)</span>. Of interest, thus, are not just a <span class="math inline">\(\theta^Y\)</span> node pointing into <span class="math inline">\(Y\)</span> but also a <span class="math inline">\(\theta^M\)</span> node pointing into <span class="math inline">\(M\)</span>. Observations that provide leverage on either component of our query will thus aid an inference about the overall causal effect. A clue <span class="math inline">\(K\)</span> that is <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(\theta^Y\)</span> may nevertheless be informative about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> if it is <em>not</em> <span class="math inline">\(d\)</span>-separated from <span class="math inline">\(\theta^M\)</span>. This opens up a broader range of variables as potentially informative clues.</p>
<p>Additionally, as our discussion in Chapter 2 makes clear, queries other than the case-level causal effect—such as average causal effects, actual causes, and causal paths—involve particular features of context: particular sets of exogenous nodes as members of our query set, <span class="math inline">\(Q\)</span>. Thus, even for the same causal model, informativeness will be defined differently for each causal question that we seek to address. The broader point is that we can identify what kinds of observations may address our query if we can place that query on a causal graph and then assess the graph for relationships of <span class="math inline">\(d\)</span>-separation and -connection.</p>
<p>Further, we emphasize that a DAG can only tell us when a clue <em>may</em> be informative (perhaps conditional on some prior observation): thus, <span class="math inline">\(d\)</span>-connectedness is necessary but not sufficient for informativeness. This fact follows directly from the rules for drawing a causal graph: The absence of an arrow between two variables implies that they are <em>not</em> directly causally related, while the presence of an arrow does not imply that they always are. Whether variables connected to one another by arrows are in fact causally related can depend on the values of other nodes. Likewise, whether a clue <span class="math inline">\(K\)</span> is in fact informative may depend on particular values of <span class="math inline">\(W\)</span>—the variables that have already been observed.</p>
<p>As a simple example, let <span class="math inline">\(q = k_1w + (1-w)k_2\)</span>, where <span class="math inline">\(W\)</span> is a variable that we have already observed and <span class="math inline">\(K_1\)</span> and <span class="math inline">\(K_2\)</span> are clues that we might choose to observe next. Here, if <span class="math inline">\(w=1\)</span> then learning <span class="math inline">\(K_1\)</span> will be informative about <span class="math inline">\(Q\)</span>, and learning <span class="math inline">\(K_2\)</span> will not; but if <span class="math inline">\(w=0\)</span>, then <span class="math inline">\(K_1\)</span> will be uninformative (and <span class="math inline">\(K_2\)</span> informative).</p>
<p>In general, then, graphical analysis alone can help us exclude unhelpful research designs, given our prior observations and a fairly minimal set of prior beliefs about causal linkages. This is no small feat. But identifying those empirical strategies that will yield the <em>greatest</em> leverage requires engaging more deeply with our causal model, as we show in detail in our discussion of clue-selection in <a href="12-clue-selection.html" class="quarto-xref"><span>Chapter 12</span></a>.</p>
</section><section id="principles-of-learning" class="level2" data-number="7.5"><h2 data-number="7.5" class="anchored" data-anchor-id="principles-of-learning">
<span class="header-section-number">7.5</span> Principles of Learning</h2>
<p></p>
<p>While we can use software (such as <code>CausalQueries</code>) to implement process-tracing inference for us, it is helpful for researchers to be able to reason their way through what is happening “under the hood.” We provide here some core principles and intuitions for thinking through the features of models and queries that influence whether and how much we can learn from within-case observations.</p>
<section id="sec-DAGalone" class="level3" data-number="7.5.1"><h3 data-number="7.5.1" class="anchored" data-anchor-id="sec-DAGalone">
<span class="header-section-number">7.5.1</span> A DAG Alone Does Not Guarantee Probative Value for a Single Case</h3>
<p></p>
<p>A DAG puts qualitative structure on causal relations, but quantitative implications depend on the beliefs over causal types. In general, learning from new data requires that, conditional on known data, the probability of a new data pattern is different depending on whether or not the query is true. With flat priors, this condition may not hold for many queries of interest.</p>
<p>To illustrate, suppose that we are interested in whether <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> and we posit a simple <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model with flat priors over <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span>. Now we would like to conduct process tracing and observe <span class="math inline">\(M\)</span> to tell us about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> in a case with <span class="math inline">\(X=Y=1\)</span>.</p>
<p>Does the observation of <span class="math inline">\(M\)</span> provide leverage on whether <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>?</p>
<p>It does not. We can learn nothing about <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span> from observing <span class="math inline">\(M\)</span> (again: when we have flat priors and we are examining a single case).</p>
<p>To see why, consider that there are two causal types that will satisfy the query, <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Those are the types <span class="math inline">\(\theta^X_1 \theta^M_{01} \theta^Y_{01}\)</span> and <span class="math inline">\(\theta^X_1 \theta^M_{10} \theta^Y_{10}\)</span>: Either linked positive effects or linked negative effects could generate an overall positive effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Moreover, with flat priors over nodal types, these causal types are equally likely. Now think about what we would conclude if we collected process data and observed <span class="math inline">\(M=1\)</span> in the <span class="math inline">\(X=Y=1\)</span> case. This observation would rule out various ways in which <span class="math inline">\(X\)</span> did not cause <span class="math inline">\(Y\)</span> but it also rules out one way in which the query could be satisfied: the causal type with linked negative effects. And what if we observed, instead, <span class="math inline">\(M=0\)</span>? This would have similar implications, this time ruling out the other way in which the query could be satisfied: linked positive effects. Intuitively, we would update the same way no matter what we find, which means we must not be updating at all.</p>
<p>More formally, conditional on observing <span class="math inline">\(X=1, Y=1\)</span> our prior that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[\frac{\lambda^M_{01}\lambda^Y_{01}+ \lambda^M_{10}\lambda^Y_{10}}{(\lambda^M_{01}+\lambda^M_{11})(\lambda^Y_{01}+ \lambda^Y_{11})+ (\lambda^M_{10}+\lambda^M_{00})(\lambda^Y_{10}+ \lambda^Y_{11}) }\]</span></p>
<p>Our posterior on observing <span class="math inline">\(M=1\)</span> is:</p>
<p><span class="math display">\[\frac{\lambda^M_{01}\lambda^Y_{01}}{(\lambda^M_{01}+\lambda^M_{11})(\lambda^Y_{01} + \lambda^Y_{11})}\]</span> it is easy to see these are equal with flat priors (<span class="math inline">\(\lambda^j_{ab}=\lambda^{j*}\)</span> for all <span class="math inline">\(a,b\)</span>). What we can see from the comparison is that when we observe data we rule out half the types consistent with the data (denominator) but also rule out half the types consistent with the query <em>and</em> data (numerator) .</p>
<p>However that informative priors on <em>either</em> <span class="math inline">\(\theta^M\)</span> or <span class="math inline">\(\theta^Y\)</span>, would help here. For instance, if we believed that linked positive effects are more likely than linked negative effects, then observing <span class="math inline">\(M\)</span> would be informative. Seeing <span class="math inline">\(M=1\)</span> would then rule out the way in which the query could be satisfied but rule in the more likely way, thus increasing our confidence that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span>. Seeing <span class="math inline">\(M=0\)</span> would reduce that confidence by ruling out the most likely way in which this effect could occur.</p>
<p>More generally, what we need at the level of priors depends on the query. Suppose that we start with the model, <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>, and formulate the following query: Does <span class="math inline">\(X\)</span> have a positive effect on <span class="math inline">\(Y\)</span> that runs through a chain of positive effects via <span class="math inline">\(M\)</span>? We can learn about this query without any informative priors over nodal types because of the way in which the query itself restricts the type space. Since the query is not satisfied if negative mediating effects are operating, we will update to probability 0 on the query for any observation that violates <span class="math inline">\(X=M=Y\)</span>, and we will update upwards on the query for any observation of <span class="math inline">\(X=M=Y\)</span>.</p>
</section><section id="learning-requires-uncertainty" class="level3" data-number="7.5.2"><h3 data-number="7.5.2" class="anchored" data-anchor-id="learning-requires-uncertainty">
<span class="header-section-number">7.5.2</span> Learning Requires Uncertainty</h3>
<p>While case-level inference from within-case evidence often requires informative priors about nodal types, there is also such a thing as <em>too much</em> information—or, put differently, as insufficient uncertainty about causal relations. Suppose, for instance, that our beliefs are such that <span class="math inline">\(X\)</span> always has a positive effect on <span class="math inline">\(M\)</span> in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model. Consider, further, that we already know that <span class="math inline">\(X=1\)</span> in a case. In that situation, nothing can be learned by observing <span class="math inline">\(M\)</span> since the prior observation of <span class="math inline">\(X\)</span> already reveals <span class="math inline">\(M\)</span>’s value given our prior beliefs.</p>
<p>To take a less extreme example, suppose that our priors put a <em>very high probability</em> on <span class="math inline">\(X\)</span>’s having a positive effect on <span class="math inline">\(M\)</span> and that, again, we already know that <span class="math inline">\(X=1\)</span> in a case. In that situation, we should <em>expect</em> to learn very little from observing <span class="math inline">\(M\)</span> since we believe that we are very likely to see <span class="math inline">\(M=1\)</span>, given that we already know <span class="math inline">\(X=1\)</span>. It is true that our beliefs will shift <em>if</em> we look for <span class="math inline">\(M\)</span> and find the unexpected value of <span class="math inline">\(M=0\)</span>. But because that data-realization is highly unlikely, we should expect the learning from observing <span class="math inline">\(M\)</span> to be minimal.</p>
<p>We address the concept of expected learning more systematically in <a href="12-clue-selection.html" class="quarto-xref"><span>Chapter 12</span></a> and <a href="13-case-selection.html" class="quarto-xref"><span>Chapter 13</span></a>, but our general point here is that, we will learn more from process-tracing evidence, to the extent that (a) we know enough about causal relations in a domain to know how to make causal sense of the evidence we find, but (b) we do not know so much that that evidence can be largely predicted from what we have already observed.</p>
</section><section id="population-level-uncertainty-and-case-level-causal-inference" class="level3" data-number="7.5.3"><h3 data-number="7.5.3" class="anchored" data-anchor-id="population-level-uncertainty-and-case-level-causal-inference">
<span class="header-section-number">7.5.3</span> Population-Level Uncertainty and Case-Level Causal Inference</h3>
<p>In the procedure we described for process tracing in this chapter (and different to what we introduce in Chapter 8), we have assumed that <span class="math inline">\(\lambda\)</span> is known and we do not place uncertainty around it.</p>
<p>This might appear somewhat heroic, but in fact for single case inference, if priors are defined directly over causal types, it is without loss of generality. The expected inferences we would make for any query accounting for uncertainty in priors over <em>causal types</em> is the same as the inferences we make if we use the expectation only.</p>
<p>With a little abuse of notation say that <span class="math inline">\(\theta \in D\)</span> if causal type <span class="math inline">\(\theta\)</span> produces data type <span class="math inline">\(D\)</span>; let <span class="math inline">\(q\)</span> denote a query and say <span class="math inline">\(\theta \in Q\)</span> if causal type <span class="math inline">\(\theta\)</span> satisfies the query.</p>
<p>Let <span class="math inline">\(\pi(\theta | \lambda)\)</span> denote the probability of causal type <span class="math inline">\(\theta\)</span> given <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p(\lambda)\)</span> a prior distribution over <span class="math inline">\(\lambda\)</span>. Then, the posterior on <span class="math inline">\(Q\)</span> given data <span class="math inline">\(D\)</span> is:</p>
<p><span class="math display">\[\Pr(Q | D) = \frac{\Pr(D,Q)}{\Pr(D)}=   \frac{\int_\pi\sum_{\theta \in Q \cap D}\pi(\theta | \lambda)p(\lambda)d\lambda}{\int_\pi\sum_{\theta \in D}\pi(\theta | \lambda) p(\lambda)d\lambda} =   \frac{\sum_{\theta \in Q \cap D}\overline{\pi}(\theta )}{\sum_{\theta \in D}\overline{\pi}(\theta)}\]</span></p>
<p>where <span class="math inline">\(\overline{\pi}(\theta) = \int \pi(\theta | \lambda) p(\lambda)d\lambda\)</span> is the expected value of <span class="math inline">\(\lambda\)</span> under <span class="math inline">\(f\)</span> and the last step involves swapping the summation and integral.</p>
<p>For intuition, in an <span class="math inline">\(X \rightarrow Y\)</span> model, if we observe <span class="math inline">\(X=Y=1\)</span> then <span class="math inline">\(D\)</span> consists of causal types <span class="math inline">\(D=\{(\theta^X_1, \theta^Y_{01}), (\theta^X_1, \theta^Y_{11})\}\)</span> and the query set for “<span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>” consists of <span class="math inline">\(Q=\{(\theta^X_1, \theta^Y_{01}), (\theta^X_0, \theta^Y_{01})\}\)</span>. Then <span class="math inline">\(Q \cap D = \{(\theta^X_1, \theta^Y_{01})\}\)</span>. Say we entertain two different values for the distribution of types: We believe with probability <span class="math inline">\(s\)</span> that <span class="math inline">\(\Pr(\theta = (\theta^X_1, \theta^Y_{01})) = \lambda'_b\)</span> and <span class="math inline">\(\Pr(\theta = (\theta^X_1, \theta^Y_{11})) = \lambda'_d\)</span> and we believe with probability <span class="math inline">\(1-s\)</span> that <span class="math inline">\(\Pr(\theta = (\theta^X_1, \theta^Y_{01})) = \lambda''_b\)</span> and <span class="math inline">\(\Pr(\theta = (\theta^X_1, \theta^Y_{11})) = \lambda''_d\)</span>. We then have:</p>
<p><span class="math display">\[\begin{eqnarray}
\Pr(Q | D) &amp;=&amp; \frac{\Pr(D,Q)}{\Pr(D)} \\
           &amp;=&amp;   \frac{s\lambda'_b+(1-s)\lambda''_b}{s(\lambda'_b+\lambda'_d) +(1-s)(\lambda''_b+\lambda''_d)} \\
           &amp;=&amp;   \frac{s\lambda'_b+(1-s)\lambda''_b}{\left(s\lambda'_b+(1-s)\lambda''_b\right) + \left(s\lambda'_d +(1-s)(\lambda''_d)\right)}  \\
           &amp;=&amp;   \frac{\overline{\lambda}_b}{\overline{\lambda}_b + \overline{\lambda}_d}
\end{eqnarray}\]</span></p>
<p>Note, however, that the same cannot be said if priors are specified over nodal types rather than directly over causal types. One might imagine for instance being certain that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> in a <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model but uncertain as to whether the effect works through a sequence of two positive effects or a sequence of two negative effects. In this case the expected effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(M\)</span> could be 0 as could the expected effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span>. Using this information without retaining information about the joint distribution of beliefs over these relations would lead us astray.</p>
<div style="page-break-after: always;"></div>
</section></section><section id="chapter-appendix-process-tracing-with-causalqueries" class="level2" data-number="7.6"><h2 data-number="7.6" class="anchored" data-anchor-id="chapter-appendix-process-tracing-with-causalqueries">
<span class="header-section-number">7.6</span> Chapter Appendix: Process Tracing with <code>CausalQueries</code>
</h2>
<p></p>
<section id="example-1-simple-model" class="level3" data-number="7.6.1"><h3 data-number="7.6.1" class="anchored" data-anchor-id="example-1-simple-model">
<span class="header-section-number">7.6.1</span> Example 1: Simple Model</h3>
<p>Imagine a simple model in which <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>. We can define the model thus:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">make_model</span><span class="op">(</span><span class="st">"X -&gt; M -&gt; Y"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This model will be of limited use to us without some more specification of <em>how</em> processes work. We can make progress for instance if we have informative priors. Most simply we can impose various monotonicity assumptions thus:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_restrictions</span><span class="op">(</span><span class="fu">decreasing</span><span class="op">(</span><span class="st">"X"</span>, <span class="st">"M"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_restrictions</span><span class="op">(</span><span class="fu">decreasing</span><span class="op">(</span><span class="st">"M"</span>, <span class="st">"Y"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>From this model we can draw a single case and examine parameter values (<span class="math inline">\(\theta\)</span>) and observed data for the case. See <a href="#tbl-HJ-7-T-append-1" class="quarto-xref">Table&nbsp;<span>7.8</span></a>.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-HJ-7-T-append-1" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-HJ-7-T-append-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.8: Nodal types and observed nodal values for a single hypothetical case from an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model
</figcaption><div aria-describedby="tbl-HJ-7-T-append-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead><tr class="header">
<th style="text-align: left;">node</th>
<th style="text-align: left;">nodal_type</th>
<th style="text-align: right;">observed</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">X</td>
<td style="text-align: left;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">M</td>
<td style="text-align: left;">00</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">00</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>We can also start making inferences given a specified query given different clue patterns. Here for instance we query the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> for a case with <span class="math inline">\(X=Y=1\)</span> given different possible observations on <span class="math inline">\(M\)</span> (see <a href="#tbl-HJ-7-T-append-2" class="quarto-xref">Table&nbsp;<span>7.9</span></a>).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">queries</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">query_model</span><span class="op">(</span>model <span class="op">=</span> <span class="va">model</span>, </span>
<span>            query <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Y[X=1] &gt; Y[X=0]"</span>,</span>
<span>                      <span class="st">"Y==1 &amp; X==1 &amp; M==0"</span>,</span>
<span>                      <span class="st">"Y==1 &amp; X==1 &amp; M==1"</span><span class="op">)</span>,</span>
<span>            using <span class="op">=</span> <span class="st">"priors"</span>,</span>
<span>            case_level <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-HJ-7-T-append-2" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-HJ-7-T-append-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.9: Inferences given different clue observations (simple model)
</figcaption><div aria-describedby="tbl-HJ-7-T-append-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead><tr class="header">
<th style="text-align: left;">label</th>
<th style="text-align: left;">query</th>
<th style="text-align: left;">given</th>
<th style="text-align: left;">using</th>
<th style="text-align: left;">case_level</th>
<th style="text-align: right;">mean</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Y[X=1] &gt; Y[X=0] :|: X==1 &amp; Y==1</td>
<td style="text-align: left;">Y[X=1] &gt; Y[X=0]</td>
<td style="text-align: left;">X==1 &amp; Y==1</td>
<td style="text-align: left;">priors</td>
<td style="text-align: left;">TRUE</td>
<td style="text-align: right;">0.202</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y[X=1] &gt; Y[X=0] :|: X==1 &amp; Y==1 &amp; M==0</td>
<td style="text-align: left;">Y[X=1] &gt; Y[X=0]</td>
<td style="text-align: left;">X==1 &amp; Y==1 &amp; M==0</td>
<td style="text-align: left;">priors</td>
<td style="text-align: left;">TRUE</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y[X=1] &gt; Y[X=0] :|: X==1 &amp; Y==1 &amp; M==1</td>
<td style="text-align: left;">Y[X=1] &gt; Y[X=0]</td>
<td style="text-align: left;">X==1 &amp; Y==1 &amp; M==1</td>
<td style="text-align: left;">priors</td>
<td style="text-align: left;">TRUE</td>
<td style="text-align: right;">0.252</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>We see here that the monotonicity assumptions are enough to make observation of <span class="math inline">\(M\)</span> into a hoop test for the proposition that (X,{=},1) caused (Y,{=},1).</p>
</section><section id="example-2-many-clues" class="level3" data-number="7.6.2"><h3 data-number="7.6.2" class="anchored" data-anchor-id="example-2-many-clues">
<span class="header-section-number">7.6.2</span> Example 2: Many Clues</h3>
<p>For a second example, we imagine a more complex process with three types of clues: a mediator clue (<span class="math inline">\(K1\)</span>) a moderator clue (<span class="math inline">\(K2\)</span>) and a post treatment clue (<span class="math inline">\(K3\)</span>)—which could for instance represent whether a case has been selected for study in the first place. </p>
<p>The model is constructed and graphed thus (see <a href="#fig-HJ-F-7-5" class="quarto-xref">Figure&nbsp;<span>7.5</span></a>):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">make_model</span><span class="op">(</span><span class="st">"X -&gt; K1 -&gt; Y &lt;- K2; Y -&gt; K3; Y &lt;-&gt; K3"</span><span class="op">)</span> </span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We impose various monotonicity assumptions and set priors reflecting a belief that those cases in which <span class="math inline">\(K1\)</span> and <span class="math inline">\(K2\)</span> are likely to jointly produce <span class="math inline">\(Y\)</span> are very likely to be selected for study (<span class="math inline">\(K3 = 1\)</span>) regardless of the value of <span class="math inline">\(Y\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">make_model</span><span class="op">(</span><span class="st">"X -&gt; K1 -&gt; Y &lt;- K2; Y -&gt; K3; Y &lt;-&gt; K3"</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_restrictions</span><span class="op">(</span><span class="fu">decreasing</span><span class="op">(</span><span class="st">"X"</span>, <span class="st">"K1"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_restrictions</span><span class="op">(</span><span class="fu">decreasing</span><span class="op">(</span><span class="st">"K1"</span>, <span class="st">"Y"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_restrictions</span><span class="op">(</span><span class="fu">decreasing</span><span class="op">(</span><span class="st">"K2"</span>, <span class="st">"Y"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_restrictions</span><span class="op">(</span><span class="fu">decreasing</span><span class="op">(</span><span class="st">"Y"</span>, <span class="st">"K3"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">set_priors</span><span class="op">(</span>given <span class="op">=</span> <span class="st">"Y.0001"</span>, nodal_type <span class="op">=</span> <span class="st">"11"</span>, <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-7-5" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-7-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-process-tracing-with-models_files/figure-html/fig-HJ-F-7-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-7-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Three potentially informative clues for the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>
</figcaption></figure>
</div>
</div>
</div>
<p><a href="#tbl-HJ-T-7-3K" class="quarto-xref">Table&nbsp;<span>7.10</span></a> gives an example of a single case drawn from this model, showing both nodal types (<span class="math inline">\(\theta\)</span>) and observed data for the case.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-HJ-T-7-3K" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-HJ-T-7-3K-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.10: Data from model with three clues
</figcaption><div aria-describedby="tbl-HJ-T-7-3K-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead><tr class="header">
<th style="text-align: left;">node</th>
<th style="text-align: left;">nodal_type</th>
<th style="text-align: right;">observed</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">K1</td>
<td style="text-align: left;">01</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">K2</td>
<td style="text-align: left;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">K3</td>
<td style="text-align: left;">01</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">X</td>
<td style="text-align: left;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y</td>
<td style="text-align: left;">1101</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>The next code chunk generates inferences for a case in which <span class="math inline">\(X=1\)</span> and <span class="math inline">\(Y=1\)</span> depending on which clue pattern we observe (see <a href="#tbl-HJ-T-7-3Kb" class="quarto-xref">Table&nbsp;<span>7.11</span></a> for output).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">queries</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">query_model</span><span class="op">(</span>model <span class="op">=</span> <span class="va">model</span>, </span>
<span>            query <span class="op">=</span> <span class="st">"Y[X=1] &gt; Y[X=0]"</span>,</span>
<span>            given <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Y==1 &amp; X==1"</span>,</span>
<span>                      <span class="st">"Y==1 &amp; X==1 &amp; K1==1"</span>,</span>
<span>                      <span class="st">"Y==1 &amp; X==1 &amp; K2==1"</span>,</span>
<span>                      <span class="st">"Y==1 &amp; X==1 &amp; K3==1"</span>,</span>
<span>                      <span class="st">"Y==1 &amp; X==1 &amp; K1==1 &amp; K2==1 &amp; K3==1"</span><span class="op">)</span>,</span>
<span>            using <span class="op">=</span> <span class="st">"priors"</span>,</span>
<span>            case_level <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-HJ-T-7-3Kb" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-HJ-T-7-3Kb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7.11: Inferences given different clue observations
</figcaption><div aria-describedby="tbl-HJ-T-7-3Kb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead><tr class="header">
<th style="text-align: left;">given</th>
<th style="text-align: right;">posterior</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Y==1 &amp; X==1</td>
<td style="text-align: right;">0.251</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y==1 &amp; X==1 &amp; K1==1</td>
<td style="text-align: right;">0.246</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y==1 &amp; X==1 &amp; K2==1</td>
<td style="text-align: right;">0.250</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y==1 &amp; X==1 &amp; K3==1</td>
<td style="text-align: right;">0.253</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Y==1 &amp; X==1 &amp; K1==1 &amp; K2==1 &amp; K3==1</td>
<td style="text-align: right;">0.248</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>We see that positive data on <span class="math inline">\(K1\)</span> or <span class="math inline">\(K3\)</span> each increase confidence that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span>, with more learning from <span class="math inline">\(K1\)</span>. Seeing <span class="math inline">\(K2=1\)</span> weakens confidence. Positive data on all three clues increases confidence.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-BennettBayes" class="csl-entry" role="listitem">
Bennett, Andrew. 2008. <span>“Process Tracing. A Bayesian Perspective.”</span> In <em>The Oxford Handbook of Political Methodology</em>, edited by Janet M. Box-Steffensmeier, Henry E. Brady, and David Collier, 702–21. Oxford, UK: Oxford University Press.
</div>
<div id="ref-BennettCheckel2015PT" class="csl-entry" role="listitem">
Bennett, Andrew, and Jeffrey Checkel. 2015. <span>“Process Tracing: From Philosophical Roots to Best Practices.”</span> In <em>Process Tracing: From Metaphor to Analytic Tool</em>, edited by Andrew Bennett and Jeffrey Checkel, 3–37. New York: Cambridge University Press.
</div>
<div id="ref-collier2011understanding" class="csl-entry" role="listitem">
Collier, David. 2011. <span>“Understanding Process Tracing.”</span> <em>PS: Political Science &amp; Politics</em> 44 (04): 823–30.
</div>
<div id="ref-frangakis2002principal" class="csl-entry" role="listitem">
Frangakis, Constantine E, and Donald B Rubin. 2002. <span>“Principal Stratification in Causal Inference.”</span> <em>Biometrics</em> 58 (1): 21–29.
</div>
<div id="ref-george2005case" class="csl-entry" role="listitem">
George, Alexander L., and Andrew A. Bennett. 2005. <em>Case Studies and Theory Development in the Social Sciences</em>. A BCSIA Book. MIT Press. <a href="http://books.google.ch/books?id=JEGzE6ExN-gC">http://books.google.ch/books?id=JEGzE6ExN-gC</a>.
</div>
<div id="ref-hernan2006instruments" class="csl-entry" role="listitem">
Hernán, Miguel A, and James M Robins. 2006. <span>“Instruments for Causal Inference: An Epidemiologist’s Dream?”</span> <em>Epidemiology</em> 17 (4): 360–72.
</div>
<div id="ref-humphreys2015mixing" class="csl-entry" role="listitem">
Humphreys, Macartan, and Alan M Jacobs. 2015. <span>“Mixing Methods: A Bayesian Approach.”</span> <em>American Political Science Review</em> 109 (04): 653–73.
</div>
<div id="ref-pearl2009causality" class="csl-entry" role="listitem">
Pearl, Judea. 2009. <em>Causality</em>. Cambridge university press.
</div>
<div id="ref-Van-Evera:1997" class="csl-entry" role="listitem">
Van Evera, Stephen. 1997. <em>Guide to Methods for Students of Political Science</em>. Ithaca, NY: Cornell University Press.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>This differs from the task for mixed methods research that we will address in <a href="09-mixing-methods.html" class="quarto-xref"><span>Chapter 9</span></a>. There we will address questions about the distribution of causal types in populations.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The reference population for a case is defined based on whatever we already know about the case. Thus, for instance, if we already know that the case has <span class="math inline">\(Y=1\)</span> before we begin process tracing, then the relevant population for the formation of prior beliefs is all cases in which <span class="math inline">\(Y=1\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>In words, the probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occurring is equal to the probability of <span class="math inline">\(A\)</span> occurring times the probability of <span class="math inline">\(B\)</span> occurring <em>given</em> that <span class="math inline">\(A\)</span> occurs.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>For a given value of <span class="math inline">\(\lambda^K_{01}\)</span>, we hold the other <span class="math inline">\(\lambda^K\)</span> values equal by assigning a value of <span class="math inline">\((1-\lambda^K_{01})/3\)</span> to each.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>For a given value of <span class="math inline">\(\lambda^K_{11}\)</span>, we hold the other <span class="math inline">\(\lambda^K\)</span>’s equal by assigning a value of <span class="math inline">\((1-\lambda^K_{11})/3\)</span> to each; likewise for <span class="math inline">\(\lambda^Y_{11}\)</span> and the other <span class="math inline">\(\lambda^Y\)</span> values.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>This proposition is almost coextensive with the definition of a DAG. A DAG is a particular kind of dependency model (“graphoid”) that is a summary of a collection of “independency statements”, <span class="math inline">\((I)\)</span>, over distinct subsets of <span class="math inline">\(\mathcal V\)</span> (Pearl and Verma 1987), where <span class="math inline">\(I(\mathcal Q,\mathcal W,\mathcal K)\)</span> means “we learn nothing about <span class="math inline">\(Q\)</span> from <span class="math inline">\(K\)</span> if we already know <span class="math inline">\(W\)</span>.” More formally: <span class="math inline">\(I(\mathcal K, \mathcal W,\mathcal Q) \leftrightarrow P(\mathcal K,\mathcal Q|\mathcal W)=P(\mathcal K|\mathcal W)P(\mathcal Q|\mathcal W)\)</span>. A DAG dependency model is one where the set of independencies corresponds exactly to the relations that satisfy <span class="math inline">\(d\)</span>-separation (Pearl and Verma 1987, p376). Thus on DAG <span class="math inline">\(\mathcal G\)</span>, <span class="math inline">\(I(\mathcal K,\mathcal W,\mathcal Q)_{\mathcal G}\)</span> implies that <span class="math inline">\(K\)</span> and <span class="math inline">\(Q\)</span> are <span class="math inline">\(d\)</span>-separated by <span class="math inline">\(W\)</span>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Put differently, there will not be any conditional independencies that are <em>not</em> captured in the DAG.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>That is, we can rule out that the case is an <span class="math inline">\(a\)</span> type, or one with a negative causal effect.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Recall, for instance, how a query about <span class="math inline">\(X\)</span>’s causal effect on <span class="math inline">\(Y\)</span> in an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> model is a question about the values of both <span class="math inline">\(\theta^M\)</span> and <span class="math inline">\(\theta^Y\)</span>.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Note the “possibly” can be dropped under the assumption that the underlying probability model is “stable” (Pearl 2009, section 2.9.1) and with the interpretation that <span class="math inline">\(K\)</span> is informative about <span class="math inline">\(Q\)</span> for some, but not necessarily all, values of <span class="math inline">\(W\)</span>.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>In other words, the clue would then be providing leverage on the mediator’s nodal type, that is, on a <span class="math inline">\(\theta\)</span> node pointing into the mediator itself.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>As a simple example one might imagine a system in which <span class="math inline">\(X = K\)</span> if <span class="math inline">\(q \in {a,b}\)</span> and <span class="math inline">\(X = 1-K\)</span> if <span class="math inline">\(q \in {c,d}\)</span>. Then, if we observe, say, <span class="math inline">\(X=Y=K=1\)</span>, we can infer that <span class="math inline">\(q = b\)</span>. Another way to think about what is happening in graph (5) is that <span class="math inline">\(K\)</span> is providing information about the <em>assignment process</em>. In this graph, the causal effect (<span class="math inline">\(Y\)</span>’s potential outcomes, determined by <span class="math inline">\(Q\)</span>) is also a partial determinant of the assignment of cases to values on <span class="math inline">\(X\)</span>. In terms of cross-case correlational inference, then, we would think of this as a situation of confounding. Observing another cause of <span class="math inline">\(X\)</span>, then, allows us to more fully characterize the process of assignment.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./06-theory-as-causal-models.html" class="pagination-link" aria-label="Theories as Causal Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Theories as Causal Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./08-PT-application.html" class="pagination-link" aria-label="Process Tracing Applications">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Process Tracing Applications</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>