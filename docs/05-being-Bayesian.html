<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>5&nbsp; Bayesian Answers – Integrated Inferences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06-theory-as-causal-models.html" rel="next">
<link href="./04-causal-questions.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="style.css">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-causal-models.html">I Foundations</a></li><li class="breadcrumb-item"><a href="./05-being-Bayesian.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Answers</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Integrated Inferences</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Start</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Front matter</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quick guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">I Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-causal-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-illustrating-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Illustrating Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-causal-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Causal Queries</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-being-Bayesian.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Answers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-theory-as-causal-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Theories as Causal Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">II Model-based Causal Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-process-tracing-with-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Process Tracing with Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-PT-application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Process Tracing Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-mixing-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Integrated Inferences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-mixed-application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Integrated Inferences Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-fusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Mixing Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">III Design choices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-clue-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Clue Selection as a Decision Problem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-case-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Case Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-wide-or-deep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Going Wide, Going Deep</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">IV Models in Question</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-justifying-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Justifying Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-evaluating-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Evaluating Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Final Words</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">End matter</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-errata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Errata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#bayes-basics" id="toc-bayes-basics" class="nav-link active" data-scroll-target="#bayes-basics"><span class="header-section-number">5.1</span> Bayes Basics</a>
  <ul class="collapse">
<li><a href="#simple-instances" id="toc-simple-instances" class="nav-link" data-scroll-target="#simple-instances"><span class="header-section-number">5.1.1</span> Simple Instances</a></li>
  <li><a href="#bayes-rule-for-discrete-hypotheses" id="toc-bayes-rule-for-discrete-hypotheses" class="nav-link" data-scroll-target="#bayes-rule-for-discrete-hypotheses"><span class="header-section-number">5.1.2</span> Bayes’ Rule for Discrete Hypotheses</a></li>
  <li><a href="#continuous-parameters-vector-valued-parameters" id="toc-continuous-parameters-vector-valued-parameters" class="nav-link" data-scroll-target="#continuous-parameters-vector-valued-parameters"><span class="header-section-number">5.1.3</span> Continuous Parameters, Vector-valued parameters</a></li>
  <li><a href="#sec-Dirichlet" id="toc-sec-Dirichlet" class="nav-link" data-scroll-target="#sec-Dirichlet"><span class="header-section-number">5.1.4</span> The Dirichlet Family</a></li>
  <li><a href="#moments-mean-and-variance" id="toc-moments-mean-and-variance" class="nav-link" data-scroll-target="#moments-mean-and-variance"><span class="header-section-number">5.1.5</span> Moments: Mean and Variance</a></li>
  <li><a href="#sec-learning" id="toc-sec-learning" class="nav-link" data-scroll-target="#sec-learning"><span class="header-section-number">5.1.6</span> Learning</a></li>
  <li><a href="#bayes-estimation-in-practice" id="toc-bayes-estimation-in-practice" class="nav-link" data-scroll-target="#bayes-estimation-in-practice"><span class="header-section-number">5.1.7</span> Bayes Estimation in Practice</a></li>
  </ul>
</li>
  <li>
<a href="#bayes-applied" id="toc-bayes-applied" class="nav-link" data-scroll-target="#bayes-applied"><span class="header-section-number">5.2</span> Bayes Applied</a>
  <ul class="collapse">
<li><a href="#simple-bayesian-process-tracing" id="toc-simple-bayesian-process-tracing" class="nav-link" data-scroll-target="#simple-bayesian-process-tracing"><span class="header-section-number">5.2.1</span> Simple Bayesian Process Tracing</a></li>
  <li><a href="#a-generalization-bayesian-inference-on-arbitrary-queries" id="toc-a-generalization-bayesian-inference-on-arbitrary-queries" class="nav-link" data-scroll-target="#a-generalization-bayesian-inference-on-arbitrary-queries"><span class="header-section-number">5.2.2</span> A Generalization: Bayesian Inference on Arbitrary Queries</a></li>
  </ul>
</li>
  <li>
<a href="#features-of-bayesian-updating" id="toc-features-of-bayesian-updating" class="nav-link" data-scroll-target="#features-of-bayesian-updating"><span class="header-section-number">5.3</span> Features of Bayesian Updating</a>
  <ul class="collapse">
<li><a href="#AppPriors" id="toc-AppPriors" class="nav-link" data-scroll-target="#AppPriors"><span class="header-section-number">5.3.1</span> Priors Matter</a></li>
  <li><a href="#simultaneous-joint-updating" id="toc-simultaneous-joint-updating" class="nav-link" data-scroll-target="#simultaneous-joint-updating"><span class="header-section-number">5.3.2</span> Simultaneous, joint updating</a></li>
  <li><a href="#posteriors-are-independent-of-the-ordering-of-data" id="toc-posteriors-are-independent-of-the-ordering-of-data" class="nav-link" data-scroll-target="#posteriors-are-independent-of-the-ordering-of-data"><span class="header-section-number">5.3.3</span> Posteriors Are Independent of the Ordering of Data</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-causal-models.html">I Foundations</a></li><li class="breadcrumb-item"><a href="./05-being-Bayesian.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Answers</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-HJC5" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Answers</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-default callout-note callout-titled" title="Chapter summary">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this chapter, we outline the logic of Bayesian updating and show how it is used for answering causal queries. We illustrate with applications to correlational and process tracing analyses.</p>
</div>
</div>
<p><br></p>
<p>Bayesian methods are sets of procedures that allow us to figure out how to update beliefs in light of new information.</p>
<p>We begin with a prior belief about the probability that a hypothesis is true. New data then allow us to form a posterior belief about the probability of that hypothesis. Bayesian inference takes into account three considerations: the consistency of the evidence with a hypothesis, the uniqueness of the evidence to that hypothesis, and background knowledge that we have about the hypothesis.</p>
<p>In the next section, we review the basic logic of Bayesian updating. The following section applies that logic to the problem of updating on causal queries given a causal model and data. The last section discusses principles of learning that follow from the use of Bayesian updating.</p>
<section id="bayes-basics" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="bayes-basics">
<span class="header-section-number">5.1</span> Bayes Basics</h2>
<p>For simple problems, Bayesian inference accords well with common intuitions about the interpretation of evidence. Once problems get slightly more complex, however, our intuitions often fail us.</p>
<section id="simple-instances" class="level3" data-number="5.1.1"><h3 data-number="5.1.1" class="anchored" data-anchor-id="simple-instances">
<span class="header-section-number">5.1.1</span> Simple Instances</h3>
<p>Suppose I draw a card from a deck. The chance that it is a Jack of Spades is just 1 in 52. However, suppose that I first tell you that the card is indeed a spade and then ask you what the chances are that it is a Jack of Spades. In this situation, you should guess 1 in 13. If I said it was a face card and a spade, on the other hand, you should say 1 in 3. But if I told you that the card was a heart, you should respond that there is no chance that it is a Jack of Spades.</p>
<p>All of these answers involve applications of Bayes’ rule in a simple setup. In each case, the answer is derived by, first, assessing what is <em>possible</em>, given the available information, and then assessing how likely the outcome of interest is among those states of the world that are possible. We want to know the likelihood that a card is the Jack of Spades in light of the evidence provided. We calculate this thus:<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><span class="math display">\[\text{Prob (Jack of Spades | Info)} = \frac{\text{Is Jack of Spades Consistent with Info? (0 or 1)}}{\text{How many cards are consistent with Info?}}\]</span></p>
<p> The probability that a card is the Jack of Spades given the available information can be calculated as a function of whether or not a Jack of Spades is at all <em>possible</em> given the information and, if so, of how many other types of cards would also be consistent with this evidence. The probability of a Jack of Spades increases as the number of other cards consistent with the available evidence falls.</p>
<!-- The same logic goes through when things are not quite so black and white. -->
<p>Now consider two slightly trickier examples (neither original to us).</p>
<p><strong>Interpreting Your Test Results</strong>. Say that you take a diagnostic test to see whether you suffer from a disease that affects 1 in 100 people. The test is strong in the sense that, if you have the disease, it will yield a positive result with a 99% probability; and if you do not have the disease, then with a 99% probability, it will deliver a negative result. Now consider that the test result comes out positive. What are the chances you have the disease? Intuitively, it might seem that the answer is 99%—but that would be to mix up two different probabilities: the probability of a positive result if you have the disease (that’s the 99%) with the probability you have the disease given a positive result (the quantity we are interested in). In fact, the probability you have the disease, given your positive result, is only 50%. You can think of that as the share of people that have the disease among all those that test positive.</p>
<p>The logic is most easily seen if you think through it using frequencies (see <span class="citation" data-cites="hoffrage1998using">Hoffrage and Gigerenzer (<a href="20-references.html#ref-hoffrage1998using" role="doc-biblioref">1998</a>)</span> for this problem and ways to address it). If 10,000 people took the test, then 100 of these would have the disease (1 in 100), and 99 of these would test positive. At the same time, 9,900 people tested would <em>not</em> have the disease, yet 99 of these would also test positive (the 1% error rate). So 198 people in total would test positive, but only half of them are from the group that has the disease. The simple fact that the vast majority of people do not have the disease means that, even if the false positive rate is low, a substantial share of those testing positive are going to be people who do not have the disease.</p>
<p>As an equation this might be written:</p>
<p><span class="math display">\[\begin{align*}
\text{Probability Sick | Test} &amp;=&amp; \frac{\text{How many are sick and test positive?}}{\text{How many test positive overall?}}\\
&amp;=&amp; \frac{99}{99 + 99}
\end{align*}\]</span></p>
<p><strong>Two-Child Problem</strong> Consider, last, an old puzzle described in <span class="citation" data-cites="gardner1961second">Gardner (<a href="20-references.html#ref-gardner1961second" role="doc-biblioref">1961</a>)</span>. <em>Mr Smith has two children, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. At least one of them is a boy. What are the chances they are both boys?</em> To be explicit about the puzzle, we will assume that the information that one child is a boy is given as a truthful answer to the question, “Is at least one of the children a boy?”</p>
<p>Assuming that there is a 50% probability that a given child is a boy, people often assume the answer is 50%. But surprisingly, the answer is 1 in 3. The reason is that the information provided rules out only the possibility that both children are girls. So the right answer is found by readjusting the probability that two children are boys based on this information. As in the Jack of Spades example, we consider all possible states of the world, ask which ones are possible given the available information, and then assess the probability of the outcome we are interested in relative to the other still-possible states. Once we have learned that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not both girls, that leaves three other possibilities: <span class="math inline">\(A\)</span> is a girl, <span class="math inline">\(B\)</span> is a boy; <span class="math inline">\(A\)</span> is a boy, <span class="math inline">\(B\)</span> is a girl; <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are both boys. Since these are equally likely outcomes, the last of these has a probability of 1 in 3. As an equation, we have:</p>
<p><span class="math display">\[\begin{align*}
\text{Probability both boys | Not both girls} &amp;=&amp; \frac{\text{Probability  both boys}}{\text{Probability not both girls}} \\
&amp;=&amp; \frac{\text{1 in 4}}{\text{3 in 4}}
\end{align*}\]</span></p>
</section><section id="bayes-rule-for-discrete-hypotheses" class="level3" data-number="5.1.2"><h3 data-number="5.1.2" class="anchored" data-anchor-id="bayes-rule-for-discrete-hypotheses">
<span class="header-section-number">5.1.2</span> Bayes’ Rule for Discrete Hypotheses</h3>
<p>All of these examples make use of Bayes’ rule, a simple and powerful formula for deriving updated beliefs from new data.</p>
<p>A simple version of the formula—really the definition of a conditional probability—is:</p>
<p><span id="eq-condprob"><span class="math display">\[
\Pr(H|d)=\frac{\Pr(H, d)}{\Pr(d)}
\tag{5.1}\]</span></span></p>
<p>where <span class="math inline">\(H\)</span> represents a hypothesis, and <span class="math inline">\(d\)</span> represents a particular realization of new data (e.g., a particular piece of evidence that we might observe).</p>
<p>The elaborated version, which we call Bayes’ rule, can be written:</p>
<p><span id="eq-Bayes"><span class="math display">\[
\Pr(H|d)=\frac{\Pr(d|H)\Pr(H)}{\Pr(d)} = \frac{\Pr(d|H)\Pr(H)}{\sum_{H'}\Pr(d|H')\Pr(H'))}
\tag{5.2}\]</span></span></p>
<p>where the summation runs over an exhaustive and exclusive set of hypotheses.</p>
<p>What this formula gives us is a way to calculate our <em>posterior</em> belief (<span class="math inline">\(\Pr(H|d)\)</span>): the degree of confidence that we should have in the hypothesis <em>after</em> seeing the new data.</p>
<p>Inspecting the first line of the formula, we can see that our posterior belief derives from three considerations.</p>
<p></p>
<p>First is the strength of our prior level of confidence in the hypothesis, <span class="math inline">\(\Pr(H)\)</span>. All else equal, a hypothesis with a higher prior likelihood is going to end up having a higher posterior probability as well. The reason is that, the more probable our hypothesis is at the outset, the greater the chance that new data consistent with the hypothesis has <em>in fact</em> been generated by a state of the world implied by the hypothesis. The more prevalent an illness, the more likely that a positive test result has <em>in fact</em> come from an individual who has the illness.</p>
<p></p>
<p>Second is the likelihood <span class="math inline">\(\Pr(d|H)\)</span>: How likely are we to have observed this <em>particular</em> pattern in the data if the hypothesis were true? We can think of the likelihood as akin to the “true positive” rate of a test. If a test for an illness has a true positive rate of <span class="math inline">\(99\%\)</span>, this is the same as saying that there is a <span class="math inline">\(0.99\)</span> probability of observing a positive result if the hypothesis (the person has the illness) is true.</p>
<p>Third is the unconditional probability of the data <span class="math inline">\(\Pr(d)\)</span>, which appears in the denominator. This quantity asks: How likely are we to have observed this pattern of the data <em>at all,</em> regardless of whether the hypothesis is true or false? If this data pattern is something we might expect to see even if the hypothesis is not true, then seeing this data pattern will not weigh strongly in favor of the hypothesis. If positive test results are quite common regardless of whether someone has the illness, then a positive test result should not shift our beliefs much in favor of thinking that the patient is ill.</p>
<p>One helpful way to think about these last two quantities is that they capture, respectively, how <em>consistent</em> the data are with our hypothesis and how <em>specific</em> the data are to our hypothesis (with specificity higher for <em>lower</em> values of <span class="math inline">\(\Pr(d)\)</span>). We update more strongly in favor of our hypothesis the more consistent the data that we observe are with the hypothesis; but that updating is dampened the more consistent the data pattern is with alternative hypotheses.</p>
<p>As shown in the second line of Equation (5.2), <span class="math inline">\(\Pr(d)\)</span> can be usefully written as a weighted average over different ways (alternative hypotheses, <span class="math inline">\(H'\)</span>) in which the data could have come about. If we have three alternative hypotheses, for instance, we ask what the probability of the data pattern is under each hypothesis and then average across those probabilities, weighting each by the prior probability of its associated hypothesis.</p>
<p>Assessing <span class="math inline">\(\Pr(d)\)</span> requires putting prior probabilities on an exclusive and exhaustive set of hypotheses. However, it does not require a listing of all possible hypotheses, just some <em>exhaustive</em> collection of hypotheses (i.e., a set whose probability adds up to 1). For example, in a murder trial, we might need to assess the unconditional probability that the accused’s fingerprints would be on the door. We can conceive of two mutually exclusive hypotheses that are collectively exhaustive of the possibilities: The accused is guilty, or they are not guilty. We can average across the probability of the accused’s fingerprints being on the door under each of these two hypotheses, weighting by their prior probabilities. What we do <em>not</em> have to do is decompose the “not guilty” hypothesis into a set of hypotheses about who <em>else</em> might be guilty. As a procedure for assessing the probability of the evidence under the not-guilty hypothesis, it might be helpful to think through who else might have done it, but there is no logical problem with working with just the two hypotheses (guilty and not guilty) since they together capture all possible states of the world. In Section <a href="#sec-derived" class="quarto-xref"><span>Section 5.2.1.2</span></a>, we work through an example in which we can calculate the probability of data conditional on some effect <em>not</em> being present.</p>
<p>Also, while the hypotheses that enter the formula have to be mutually exclusive, that does not prevent us from drawing downstream inferences about hypotheses that are not mutually exclusive. For instance, we might use Bayes’ rule to form posteriors over which one of four people is guilty: an elderly man, John; a young man, Billy; an older woman, Maria; or a young woman, Kathy. These are mutually exclusive hypotheses. However, we can then use the posterior on each of these hypotheses to update our beliefs about the probability that a man is guilty and about the probability that an elderly person is guilty. Our beliefs about whether the four individuals did it will have knock-on effects on our beliefs about whether an individual with their characteristics did it. The fact that “man” and “elderly” are not mutually exclusive in no way means that we cannot learn about both of these hypotheses from an underlying Bayesian calculation, as long as the hypotheses to which we apply Bayes’ rule are themselves mutually exclusive.</p>
</section><section id="continuous-parameters-vector-valued-parameters" class="level3" data-number="5.1.3"><h3 data-number="5.1.3" class="anchored" data-anchor-id="continuous-parameters-vector-valued-parameters">
<span class="header-section-number">5.1.3</span> Continuous Parameters, Vector-valued parameters</h3>
<p> The basic Bayesian formula extends in a simple way to continuous variables. For example, suppose we are interested in the value of some variable, <span class="math inline">\(\beta\)</span>. Rather than discrete hypotheses, we are now considering a set of possible values that this continuous variable might take on. So now our beliefs will take the form of a probability <em>distribution</em> over possible values of <span class="math inline">\(\beta\)</span>: essentially, beliefs about which values of <span class="math inline">\(\beta\)</span> are more (and how much more) likely than which other values of <span class="math inline">\(\beta\)</span>. We will generally refer to a variable that we are seeking to learn about from the data as a “parameter.”</p>
<p>We start with a <em>prior</em> probability distribution over the parameter of interest, <span class="math inline">\(\beta\)</span>. Then, once we encounter new data, <span class="math inline">\(d\)</span>, we calculate a <em>posterior</em> distribution over <span class="math inline">\(\beta\)</span> as:</p>
<p><span class="math display">\[p(\beta|d)=\frac{p(d|\beta)p(\beta)}{\int_{\beta'}p({d|\beta'})p(\beta')d\beta}\]</span></p>
<p>Here, the likelihood, <span class="math inline">\(p(d|\beta)\)</span>, is not a single probability but a function that maps each possible value of <span class="math inline">\(\beta\)</span> to the probability of the observed data arising if that were the true value. The likelihood will thus take on a higher value for those values of <span class="math inline">\(\beta\)</span> with which the data pattern is more consistent. Note also that we are using integration rather than summation in the denominator here because we are averaging across a continuous set of possible values of <span class="math inline">\(\beta\)</span>, rather than a discrete set of hypotheses. </p>
<p>We can then take a further step and consider learning about <em>combinations</em> of beliefs about the world. Consider a vector <span class="math inline">\(\theta\)</span> that contains multiple parameters that we are uncertain about the value of, say, the levels of popular support for five different candidates. We want to learn from the data which combinations of parameter values—what level of support for candidate <span class="math inline">\(1\)</span>, for candidate <span class="math inline">\(2\)</span>, and so on– are most likely the true values. Just as for a single parameter, we can have a prior probability distribution over <span class="math inline">\(\theta\)</span>, reflecting our beliefs before seeing the data about which combinations of values are more or less likely. When we observe data (say, survey data about the performance of the five candidates in an election), we can then update to a set of posteriors beliefs over <span class="math inline">\(\theta\)</span> using:</p>
<p><span class="math display">\[p(\theta|d)=\frac{p(d|\theta)p(\theta)}{\int_{\theta'}p({d|\theta'})p(\theta')d\theta}\]</span></p>
<p>This equation is identical to the prior one, except that we are now forming and updating beliefs about the vector-valued parameter, <span class="math inline">\(\theta\)</span>. The likelihood now has to tell us the probability of different possible distributions of support that we could observe in the survey under different possible true levels of support for these candidates. Suppose, for instance, that we observe levels of support in the survey of <span class="math inline">\(d = (12\%, 8\%, 20\%, 40\%, 20\%)\)</span>. The likelihood function might tell us that this is a distribution that we are highly likely to observe if the true distribution is, for instance <span class="math inline">\(\theta = (10\%, 10\%, 10\%, 50\%, 20\%)\)</span> but very unlikely to observe if the true distribution is, for instance, <span class="math inline">\(\theta = (30\%, 30\%, 10\%, 5\%, 25\%)\)</span>. More generally, the likelihood function will generate a likelihood of the observed survey data for <em>all</em> possible combinations of values in the <span class="math inline">\(\theta\)</span> vector. Our posterior beliefs will then shift from our prior toward that combination of values in <span class="math inline">\(\theta\)</span> under which the data that we have observed have the highest likelihood.</p>
</section><section id="sec-Dirichlet" class="level3" data-number="5.1.4"><h3 data-number="5.1.4" class="anchored" data-anchor-id="sec-Dirichlet">
<span class="header-section-number">5.1.4</span> The Dirichlet Family</h3>
<p>Bayes’ rule requires the ability to express a prior distribution over possible states of the world. It does not require that the prior have any particular properties other than being a probability distribution. In practice, however, when dealing with continuous parameters, it can be helpful to use “off the shelf” distributions. </p>
<p>For the framework developed in this book, we will often be interested in forming beliefs and learning about the <em>share</em> of units that are of a particular type, such as the shares of units for which the nodal type for <span class="math inline">\(Y\)</span> is <span class="math inline">\(\theta^Y_{01}, \theta^Y_{10}, \theta^Y_{00}\)</span>, or <span class="math inline">\(\theta^Y_{11}\)</span>. Formally, this kind of problem is quite similar to the example that we just discussed in which public support is distributed across a set of candidates, with each candidate having some underlying share of support. A distinctive feature of beliefs about shares is that they are constrained in a specific way: Whatever our belief about the shares of support held by different candidates might be, those shares must always add up to 1.</p>
<p>For this type of problem, we will make heavy use of “Dirichlet” distributions. The Dirichlet is a family of distributions that capture beliefs about shares, taking into account the logical constraint that shares must always sum to 1. We can use a Dirichlet distribution to express our best guess about the proportions of each type in a population, or the “expected” shares. We can also use a Dirichlet to express our <em>uncertainty</em> about those proportions.</p>
<p>To think about how uncertainty and learning from data operate with Dirichlet distributions, it is helpful to conceptualize a very simple question about shares. Suppose that members of a population fall within one of two groups, so we are trying to estimate just a single proportion: for example, the share of people in a population that voted (which also, of course, implies the share that did not). Our beliefs about this proportion can differ (or change) in two basic ways. For one thing, two people’s “best guesses” about this quantity (their expected value) could differ. One person might believe, for instance, that the turnout rate was most likely 0.3 while a second person might believe it was most likely 0.5.</p>
<p>At the same time, levels of uncertainty can also differ. Imagine that two people have the <em>same</em> “best guess” about the share who voted, both believing that the turnout rate was most likely around 0.5. However, they differ in how certain they are about this claim. One individual might have no information about the question and thus believe that any turnout rate between 0 and 1 is equally likely: This implies an expected turnout rate of 0.5. The other person, in contrast, might have a great deal of information and thus be very confident that the number is 0.5.</p>
<p>For questions about how a population is divided into two groups—say, one in which an outcome occurs, and another in which the outcome does not occur—we can capture both the expected value of beliefs and their uncertainty by using a special case of the Dirichlet distribution known as the Beta distribution. Any such question is in fact, a question about a single proportion—the proportion in one of the groups (since the proportion in which the outcome did not occur is just one minus the proportion in which it did). The Beta is a distribution over the <span class="math inline">\([0,1]\)</span> interval, the interval over which a single proportion can range. A given Beta distribution can be described by two parameters, known as <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. In the case where both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are equal to 1, the distribution is uniform: All values for the proportion are considered equally likely. As <span class="math inline">\(\alpha\)</span> rises, large values for the proportion are seen as more likely; as <span class="math inline">\(\beta\)</span> rises, lower outcomes are considered more likely. If both parameters rise proportionately, then our “best guess” about the proportion does not change, but the distribution becomes tighter, reflecting lower uncertainty.</p>
<p>An attractive feature of the Beta distribution is that Bayesian learning from new data can be easily described. Suppose one starts with a prior distribution Beta(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>) over the share of cases with some outcome (e.g., the proportion of people who votes), and then one observes a positive case—an individual who voted. The Bayesian posterior distribution is now a Beta with parameters <span class="math inline">\(\alpha+1, \beta\)</span>: the first parameter relating to positive cases literally just goes up by 1. More generally, if we observe <span class="math inline">\(n_1\)</span> new positive cases and <span class="math inline">\(n_0\)</span> new negative cases, our updated beliefs will have parameters <span class="math inline">\(\alpha+n_1, \beta +n_0\)</span>. So if we start with uniform priors about population shares, and build up knowledge as we see outcomes, our posterior beliefs should be Beta distributions with updated parameters.</p>
<p><a href="#fig-HJ-F-5-1" class="quarto-xref">Figure&nbsp;<span>5.1</span></a> shows a set of Beta distributions described by different <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> values. In the top left, we start with a distribution that has even greater variance than the uniform, with alpha and beta both set to 0.5 (corresponding to the non-informative “Jeffrey’s prior”). In each row, we keep <span class="math inline">\(\alpha\)</span> constant, reflecting observation of the same number of positive cases, but increase <span class="math inline">\(\beta\)</span> reflecting the kind of updating that would occur as we observe new negative cases. As we can see, the distribution tightens around 0 as <span class="math inline">\(\beta\)</span> increases, reflecting both a reduction in our “best guess” of the proportion positive and mounting certainty about that low proportion. As we go down a column, we hold <span class="math inline">\(\beta\)</span> constant but increase <span class="math inline">\(\alpha\)</span>, reflecting the observation of more positive cases; we see a rightward shift in the center of gravity of each distribution and increasing certainty about that higher proportion.</p>
<p>Note that we can think of proportions as probabilities, and we will often write somewhat interchangeably about the two concepts in this book. To say that the proportion of units in a population with a positive outcome is 0.3 is the same as saying that there is a 0.3 probability that a unit randomly drawn from the population will have a positive outcome. Likewise, to say that a coin lands on heads with 0.5 probability is the same as saying that we expect that 0.5 of all coin tosses will be heads.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-5-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-5-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05-being-Bayesian_files/figure-html/fig-HJ-F-5-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-5-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1: Beta distributions
</figcaption></figure>
</div>
</div>
</div>
<p>The general form of the Dirichlet distribution covers situations in which there are beliefs not just over a single proportion or probability, but over collections of proportions or probabilities. For example, if four outcomes are possible and their shares in the population are <span class="math inline">\(\theta_1, \theta_2, \theta_3\)</span>, and <span class="math inline">\(\theta_4\)</span>, then beliefs about these shares are distributions over all four-element vectors of numbers that add up to 1 (also known as a three-dimensional unit simplex).</p>
<p>The Dirichlet distribution always has as many parameters as there are outcomes, and these are traditionally recorded in a vector denoted <span class="math inline">\(\alpha\)</span>. Similar to the Beta distribution, an uninformative prior (Jeffrey’s prior) has <span class="math inline">\(\alpha\)</span> parameters of <span class="math inline">\((.5,.5,.5, \dots)\)</span> and a uniform (“flat”) distribution has <span class="math inline">\(\alpha = (1,1,1,,\dots)\)</span>. As with the Beta distribution, all Dirichlets update in a simple way. If we have a Dirichlet prior over three types with parameter <span class="math inline">\(\alpha = (\alpha_1, \alpha_2, \alpha_3)\)</span> and we observe an outcome of type <span class="math inline">\(1\)</span>, for example, then the posterior distribution is also Dirichlet but now with parameter vector <span class="math inline">\(\alpha' = (\alpha_1+1, \alpha_2,\alpha_3)\)</span>.</p>
</section><section id="moments-mean-and-variance" class="level3" data-number="5.1.5"><h3 data-number="5.1.5" class="anchored" data-anchor-id="moments-mean-and-variance">
<span class="header-section-number">5.1.5</span> Moments: Mean and Variance</h3>
<p> In what follows, we often refer to the “posterior mean” or the “posterior variance.” These are simply summary statistics of the posterior distribution, or moments, and can be calculated easily once the posterior distribution is known (or approximated, see below) given data <span class="math inline">\(d\)</span>.</p>
<p>The posterior mean, for instance for <span class="math inline">\(\theta_1\)</span>—a component of <span class="math inline">\(\theta\)</span>—is <span class="math inline">\(\int \theta_1 p(\theta | d) d\theta\)</span>. Similarly, the posterior variance is <span class="math inline">\(\int (\theta_1 - (\overline{\theta}_1 | d))^2  p(\theta | d) d\theta\)</span>. In the same way we we can imagine a query that is a function of multiple parameters, for instance <span class="math inline">\(q(\theta) = \theta_3 - \theta_2\)</span> and calculate the expected value of <span class="math inline">\(q\)</span> using <span class="math inline">\(\hat{q}(d) = \int q(\theta)  p(\theta | d) d\theta\)</span> and the variance as <span class="math inline">\(V(q |d) = \int (q(\theta) - \hat{q}(d))^2  p(\theta | d) d\theta\)</span>.</p>
<p>Note that we calculate these quantities using the posterior distribution over the full parameter vector, <span class="math inline">\(\theta\)</span>. To put the point more intuitively, the most likely value of <span class="math inline">\(\theta_1\)</span> will depend on which values of other parameters are most common and on which values of <span class="math inline">\(\theta_1\)</span> are most likely in combination with the most common values of those other parameters. This is a point that particularly matters when the parameters of interest are dependent on each other in some way: For instance, if we are interested both in voter turnout and in the share of the vote that goes to a Democrat, and we think that these two phenomena are correlated with each other.</p>
</section><section id="sec-learning" class="level3" data-number="5.1.6"><h3 data-number="5.1.6" class="anchored" data-anchor-id="sec-learning">
<span class="header-section-number">5.1.6</span> Learning</h3>
<p></p>
<p>Bayesian updating is all about learning. We can see right away from Equation <a href="#eq-Bayes" class="quarto-xref">Equation&nbsp;<span>5.2</span></a> whether we <em>learned</em> anything from data <span class="math inline">\(d\)</span>. The simplest notion of learning is that our beliefs after seeing <span class="math inline">\(d\)</span> are different than they were before we saw <span class="math inline">\(d\)</span>. That is <span class="math inline">\(\Pr(H|d) \neq \Pr(H)\)</span>. Or using Equation <a href="#eq-Bayes" class="quarto-xref">Equation&nbsp;<span>5.2</span></a>, we have learned something if: <span class="math display">\[\begin{equation}
\frac{\Pr(d|H)\Pr(H)}{\sum_{H'}\Pr(d|H')\Pr(H'))} \neq \Pr(H)
\end{equation}\]</span></p>
<p>So long as <span class="math inline">\(\Pr(H)\in(0,1)\)</span>, this can be written as:</p>
<p><span id="eq-learningcondition"><span class="math display">\[
\Pr(d|H) \neq {\sum_{H'\neq H}\frac{\Pr(H')}{(1-\Pr(H))}\Pr(d|H')}
\tag{5.3}\]</span></span></p>
<p>which simply means that the probability of <span class="math inline">\(d\)</span> under the hypothesis is not the same as the probability of <span class="math inline">\(d\)</span> averaged across all other hypotheses.</p>
<p>Two notions are useful for describing how much one can learn or is likely to learn from data: the probative value of data and the expected learning from data. We describe both here and pick up both ideas in later sections.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>To consider the simplest scenario, suppose there are two mutually exclusive and exhaustive hypotheses, <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> and that we place a prior probability of <span class="math inline">\(p\)</span> on <span class="math inline">\(H_1\)</span>. Imagine that the available evidence can take on two values, <span class="math inline">\(K=0\)</span> or <span class="math inline">\(K=1\)</span>. Likelihoods are described by <span class="math inline">\(\phi_0\)</span> and <span class="math inline">\(\phi_1\)</span>, where <span class="math inline">\(\phi_0\)</span> denotes the probability <span class="math inline">\(K=1\)</span> under <span class="math inline">\(H_0\)</span> and <span class="math inline">\(\phi_1\)</span> denotes the probability <span class="math inline">\(K=1\)</span> under <span class="math inline">\(H_1\)</span>. Equation <a href="#eq-Bayes" class="quarto-xref">Equation&nbsp;<span>5.2</span></a> then becomes:</p>
<p><span id="eq-Bayes2"><span class="math display">\[
\Pr(H_1|K=1)=\frac{\phi_1p}{\phi_1p + \phi_0(1-p)}
\tag{5.4}\]</span></span></p>
<p>and the condition for learning (Equation <a href="#eq-learningcondition" class="quarto-xref">Equation&nbsp;<span>5.3</span></a>) reduces to <span class="math inline">\(\phi_1 \neq \phi_0\)</span>, so long as <span class="math inline">\(p\in(0,1)\)</span>.</p>
<p>More generally, the informativeness of evidence depends on how different <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_0\)</span> are from each other: how different the likelihood of seeing that evidence is under the two hypotheses. How best to measure that difference? There are many possibilities (see <span class="citation" data-cites="kaye1986quantifying">Kaye (<a href="20-references.html#ref-kaye1986quantifying" role="doc-biblioref">1986</a>)</span> for a review), but a compelling approach is to use the log of the ratio of the likelihoods. This is a simple and elegant measure that corresponds to what <span class="citation" data-cites="good1950probability">Isidore Jacob Good (<a href="20-references.html#ref-good1950probability" role="doc-biblioref">1950</a>)</span> proposes in multiple contributions, a measure of the “weight of evidence.” <span class="citation" data-cites="kaye1986quantifying">Kaye (<a href="20-references.html#ref-kaye1986quantifying" role="doc-biblioref">1986</a>)</span> refers to this as the most common measure of “probative value.” <span class="citation" data-cites="fairfield2017explicit">Fairfield and Charman (<a href="20-references.html#ref-fairfield2017explicit" role="doc-biblioref">2017</a>)</span> also use this measure, highlighting how it provides a useful way of characterizing the impact of, and of analyzing, evidence. </p>
<div class="callout callout-style-default callout-note callout-titled" title="Chapter summary">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter summary
</div>
</div>
<div class="callout-body-container callout-body">
<div id="defpv" class="definition">
<p>Probative value</p>
</div>
<p></p>
<p>Suppose that, if a hypothesis <span class="math inline">\(H\)</span> is true, a clue <span class="math inline">\(K\)</span> is observed with probability <span class="math inline">\(\phi_1\)</span> (and otherwise is not observed). The probability that the clue is observed if the hypothesis is not true is denoted as <span class="math inline">\(\phi_0\)</span>. Let <span class="math inline">\(p\)</span> refer to the prior that the hypothesis is true.</p>
<p>Then the “<strong>probative value</strong>” of an observed clue <span class="math inline">\(K\)</span> is:</p>
<p><span class="math display">\[\text{Probative value} := \log\left(\frac{\phi_1}{\phi_0}\right)\]</span></p>
</div>
</div>
<p>Some features of this measure of probative value are worth noting.</p>
<p>First, perhaps not immediately obvious, this notion of probative value should be thought of with respect to the <em>realized</em> value of the clue, not the possible data that might have been found. That is, it is about the data you have, not the data you might have. Thus, a clue (if found to be present) might have weak probative value if the clue is found, but strong probative value if it is <em>not</em> found. To illustrate, say <span class="math inline">\(\phi_1 = \Pr(K = 1 | H_1) = 0.999\)</span> and <span class="math inline">\(\phi_0 = \Pr(K = 1 | H = 0) = 0.333\)</span>. The probative value of the found clue is <span class="math inline">\(\log(.999/.333) = 0.47\)</span>—a piece of evidence “barely worth mentioning” according to <span class="citation" data-cites="jeffreys1998theory">Jeffreys (<a href="20-references.html#ref-jeffreys1998theory" role="doc-biblioref">1998</a>)</span>. Our beliefs will shift only a little toward <span class="math inline">\(H_1\)</span> if the clue is found. The <em>non</em>-appearance of the same clue, however, has strong probative value for <span class="math inline">\(H_0\)</span>. In this case, probative value is <span class="math inline">\(\log\left(\frac{\Pr(K = 0 | H_0)}{\Pr(K = 0 | H_1)}\right) = \log\left(\frac{1-\phi_0}{1-\phi_1}\right) = \log(.667/.001) = 2.82\)</span> —“decisive” according to <span class="citation" data-cites="jeffreys1998theory">Jeffreys (<a href="20-references.html#ref-jeffreys1998theory" role="doc-biblioref">1998</a>)</span>. </p>
<p>An important implication here is that knowledge of the probative value of a clue, thus defined, is not necessarily a good guide to the <em>selection</em> of a clue to search for. When deciding on which evidence to go looking for, we do not know what we will find. Thus, knowing that the probative value of a clue is strong <em>if</em> we happen to find it—but that the clue’s absence would be minimally informative—does not tell us whether it is worth expending resources looking for that clue.</p>
<p>Second, this measure of probative value makes no use of our priors on the hypotheses. In fact, <span class="citation" data-cites="good1984c197">Irving John Good (<a href="20-references.html#ref-good1984c197" role="doc-biblioref">1984</a>)</span>’s first desideratum of a measure of the weight of evidence is that it should be a function of <span class="math inline">\(\phi_0\)</span> and <span class="math inline">\(\phi_1\)</span> only. <span class="citation" data-cites="kaye2003misquantification">Kaye and Koehler (<a href="20-references.html#ref-kaye2003misquantification" role="doc-biblioref">2003</a>)</span> also provide multiple arguments for the exclusion of information on priors from determinations of probative value. Yet, ignoring our prior confidence in the hypotheses when selecting clues to search for leaves us unable to tell whether we are setting ourselves up for a finding that is “decisive” or one that is “barely worth mentioning.” If <span class="math inline">\(K=1\)</span> constitutes strong evidence in favor of <span class="math inline">\(H_1\)</span> while <span class="math inline">\(K=0\)</span> is weak evidence in favor of <span class="math inline">\(H_0\)</span>, it may not be worth looking for the clue if we are highly confident <em>ex ante</em> that <span class="math inline">\(H_0\)</span> is right—since, under those beliefs, we are very unlikely to find <span class="math inline">\(K=1\)</span>, the evidence with high probative value.</p>
<p>Anticipating discussions in later chapters (especially <a href="06-theory-as-causal-models.html" class="quarto-xref"><span>Chapter 6</span></a> and the chapters in Part 3 of the book), we can think of a data strategy as a strategy that produces a probability distribution over the types of data that we might encounter. For instance, our data strategy might be to look for a particular clue <span class="math inline">\(K\)</span>: So we then expect to find <span class="math inline">\(K=1\)</span> with some probability and clue <span class="math inline">\(K=0\)</span> with some probability. Our strategy might also be much more complex, involving random sampling of cases and a search for data in later stages conditional on what we find in earlier stages. Either way, our beliefs about what we are likely to find—and thus the value of a given data strategy—are shaped by our prior beliefs about the world.</p>
<p>In later analyses in this book, particularly when we turn to assessing research strategies, we use a measure of learning that takes prior confidence in the hypotheses fully into account: the expected reduction in uncertainty arising from a strategy. We can think of the expected reduction in uncertainty associated with a research strategy as the difference between the variance in our prior distribution on a query and the expected posterior variance on that query under the strategy. We can also (almost equivalently) conceptualize our uncertainty as “loss,” or the (squared) errors arising from a strategy.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> So then the expected gain from a research strategy can be thought of as the <em>reduction</em> in loss, or squared errors, that we expect to reap when we see new data (relative to the errors we make without the new data).</p>
<p>How can we assess expected reductions in loss under a research strategy? For any data strategy, <span class="math inline">\(D\)</span>, we can imagine having seen different data patterns (<span class="math inline">\(d\)</span>) that are <em>possible</em> under the strategy. We can then assess our beliefs about the errors we will likely make if we see and draw inferences from those possible data patterns. Finally, we can ask, prospectively, what errors we <em>expect</em> to make given our prior beliefs about the world and the kinds of data patterns that those beliefs imply we are most likely to observe.</p>
<p>Expected loss (equivalently, expected squared error or expected posterior variance) for query <span class="math inline">\(q\)</span> and data strategy <span class="math inline">\(D\)</span> can then be written:<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><span class="math display">\[\mathcal{L}(q, D)=\mathbb{E}_\theta(\mathbb{E}_{{d}|\theta, D}(q(\theta)-\hat{q}({d}))^2)\]</span></p>
<p>Where <span class="math inline">\(\hat{q}(d)\)</span> is the expected value of the query after observing data <span class="math inline">\(d\)</span>. To describe the <em>reduction in loss</em> that flows from strategy <span class="math inline">\(D\)</span>, we need to calculate the loss metric a second time, this time using the prior distribution. Since our loss is defined as expected squared errors, this is simply the prior variance. We can then define the expected learning from a data strategy as follows (<a href="#def-ell" class="quarto-xref">Definition&nbsp;<span>5.1</span></a>).</p>
<div id="def-ell" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 5.1</strong></span> </p>
<p>Let <span class="math inline">\(V(q)&gt;0\)</span> denote prior variance on query <span class="math inline">\(q\)</span> and <span class="math inline">\(\mathcal{L}(q, D)\)</span> the expected error on <span class="math inline">\(q\)</span> from implementation of data strategy <span class="math inline">\(D\)</span>. Then:</p>
<p><span class="math display">\[\begin{eqnarray*}
\text{Expected learning}(q, D) &amp;:=&amp; 1 - \frac{\mathcal{L}(q, D)}{V(q)}
\end{eqnarray*}\]</span></p>
</div>
<p>Note that expected learning ranges between 0 and 1. It is 1 when <span class="math inline">\(\mathcal{L}(q, D) = 0\)</span>—when we expect to end up with no uncertainty about the query after implementing the data strategy. And expected learning is 0 when <span class="math inline">\(\mathcal{L}(q, D) = V(q)\)</span>—when we expect no reduction in uncertainty.</p>
<p>Returning to our running illustration, suppose that if a hypothesis <span class="math inline">\(H_1\)</span> is true, then <span class="math inline">\(K=1\)</span> is observed with probability <span class="math inline">\(\phi_1\)</span> (and otherwise is not observed). If <span class="math inline">\(H_0\)</span> is true, then the clue is observed with probability <span class="math inline">\(\phi_0\)</span>. Let <span class="math inline">\(p\)</span> denote the prior probability that <span class="math inline">\(H_1\)</span> is true. Then, the prior uncertainty is <span class="math inline">\(V(H_1) = p(1-p)\)</span>. The expected loss under the data strategy of looking for <span class="math inline">\(K\)</span> is calculated by assessing (squared) errors in four situations—defined by whether <span class="math inline">\(H_1\)</span> or <span class="math inline">\(H_0\)</span> is true, and by whether or not we observe <span class="math inline">\(K=1\)</span> when we go looking for it. We can use our priors and <span class="math inline">\(\phi\)</span> likelihoods to put a probability on each of these four situations, giving the expected loss as: <span class="math display">\[\begin{eqnarray}
\mathcal{L} &amp;=&amp; p\phi_1 \left(1-\frac{\phi_1 p}{\phi_1 p + {\phi_0 (1-p)}}\right)^2 + \\
&amp;&amp;  p(1-\phi_1) \left(1-\frac{(1-\phi_1)p}{(1-\phi_1) p + {(1-\phi_0) (1-p)}}\right)^2  +\\
&amp;&amp; (1-p)\phi_0\left(0-\frac{\phi_1 p}{\phi_1 p + {\phi_0 (1-p)}}\right)^2 + \\
&amp;&amp; (1-p)(1-\phi_0)\left(0-\frac{(1-\phi_1)p}{(1-\phi_1) p + {(1-\phi_0) (1-p)}}\right)^2
\end{eqnarray}\]</span></p>
<p>Putting these together (and simplifying), expected learning would then be:</p>
<p><span class="math display">\[\begin{eqnarray*}
\text{Expected learning} &amp;=&amp; \frac{(\phi_1-\phi_0)^2p(1-p)}{\phi_0(1-\phi_0) - (\phi_1-\phi_0)^2p^2-(\phi_1-\phi_0)p(2\phi_0-1)}
\end{eqnarray*}\]</span></p>
<p>This expression takes still simpler forms in special situations. For instance, in the situation in which <span class="math inline">\(p = 0.5\)</span> we have:</p>
<p><span class="math display">\[\text{Expected learning} = \frac{(\phi_1-\phi_0)^2}{ 2(\phi_1+\phi_0)- (\phi_1 +\phi_0)^2}\]</span></p>
<p>Notably, this expression has some commonalities with probative value. Expected learning—like probative value—is clearly 0 when <span class="math inline">\(\phi_1 = \phi_0\)</span>—that is, when a clue is just as likely under an alternative hypothesis as under a given hypothesis (as we saw above already). In addition, expected learning is bounded by 0 and 1, and is largest when the probative value is greatest—when <span class="math inline">\(\phi_1=1\)</span> and <span class="math inline">\(\phi_0 =0\)</span> (or vice versa). </p>
<p>But there nevertheless are disagreements. Compare, for instance, two clues we could go looking for, <span class="math inline">\(K_1\)</span> and <span class="math inline">\(K_2\)</span>. For <span class="math inline">\(K_1\)</span>, suppose that we have <span class="math inline">\((\phi_1 = 0.99, \phi_0 = 0.01)\)</span>, while for <span class="math inline">\(K_2\)</span>, we have <span class="math inline">\((\phi_1 = 0.099, \phi_0 = 0.001)\)</span>. The probative value measure does not distinguish between these two clues: The probative value of finding the two clues is the same. However, with <span class="math inline">\(p=0.5\)</span>, the expected learning from searching for the two clues is very different: Expected learning from a search for <span class="math inline">\(K_1\)</span> is very large (an expected 95% reduction in variance), but expected learning for <span class="math inline">\(K_2\)</span> is small (5% reduction). This is because we do not <em>expect</em> to observe <span class="math inline">\(K_2\)</span> when we look for it, and we learn little if it is sought but not found.</p>
<p>We can also have clues for which the expected learning is the same but the probative value of a clue found differs greatly: For instance, still with <span class="math inline">\(p = 0.5\)</span>, if we have <span class="math inline">\(K_3\)</span> with<span class="math inline">\((\phi_1 = 0.9, \phi_0 = 0.5)\)</span> and <span class="math inline">\(K_4\)</span> with <span class="math inline">\((\phi_1 = 0.5, \phi_0 = 0.1)\)</span>).</p>
<p>A nice feature of the expected learning measure is that the concept generalizes easily to more complex research situations—for instance, to situations in which the decision to search for one clue depends on what we find when we search for a prior clue. Moreover, variants of the measure can be produced for different loss functions that reflect researcher desiderata when embarking on a research project. </p>
</section><section id="bayes-estimation-in-practice" class="level3" data-number="5.1.7"><h3 data-number="5.1.7" class="anchored" data-anchor-id="bayes-estimation-in-practice">
<span class="header-section-number">5.1.7</span> Bayes Estimation in Practice</h3>
<p>Although the principle of Bayesian inference is quite simple, in practice generating posteriors for continuous parameters is computationally complex. With continuous parameters, there is an infinity of possible parameter values, and there will rarely be an analytic solution—a way of <em>calculating</em> the posterior distribution. Instead, researchers use some form of sampling from the parameter “space” to generate an <em>approximation</em> of the posterior distribution.</p>
<p>Imagine, for instance, that you were interested in forming a posterior belief about the share of U.S. voters intending to vote Democrat, given polling data. (This is not truly continuous, but it might as well be with large elections.)</p>
<p>One approach would be to coarsen the parameter space: We could calculate the probability of observing the polling data given a discrete set of possible values, for example, <span class="math inline">\(\theta = 0, \theta = 0.1, \theta = 0.2, \dots, \theta = 1\)</span>. We could then apply Bayes’ rule to calculate a posterior probability for each of these possible true values. The downside of this approach, however, is that, for a decent level of precision, it becomes computationally expensive to carry out with large parameter spaces—and parameter spaces get large quickly. For instance, if we are interested in vote shares, we might find <span class="math inline">\(0.4, 0.5\)</span>, and <span class="math inline">\(0.6\)</span> too coarse and want posteriors for 0.51 or even 0.505. The latter would require a separate Bayesian calculation for each of 200 parameter values. And if we had <em>two</em> parameters that we wanted to slice up each into 200 possible values, we would then have 40,000 parameter pairs to worry about. What’s more, <em>most</em> of those calculations would not be very informative if the plausible values lie within some small (though possibly unknown) range—such as between 0.4 and 0.6.</p>
<p>An alternative approach is to use variants of Markov Chain Monte Carlo (MCMC) sampling. Under MCMC approaches, parameter vectors—possible combinations of values for the parameters of interest—are sampled, and their likelihood is evaluated. If a sampled parameter vector is found to have a high likelihood, then new parameter vectors <em>near</em> it are drawn with a high probability in the next round. Based on the likelihood associated with these new draws, additional draws are then made in turn. We are thus sampling more from the parts of the posterior distribution that are closer to the most probable values of the parameters of interest, and the result is a chain of draws that build up to approximate the posterior distribution. The output from these procedures is not a set of probabilities for every possible parameter vector but rather a set of draws of parameter vectors from the underlying (but not directly observed) posterior distribution.</p>
<p>Many algorithms have been developed to achieve these tasks efficiently. In all of our applications using the <code>CausalQueries</code> software package, we rely on the <code>stan</code> procedures, which use MCMC methods: specifically, the Hamiltonian Monte Carlo algorithm and the no-U-turn sampler. Details on these approaches are given in the <a href="https://mc-stan.org/docs/2_18/reference-manual/hmc-chapter.html">Stan Reference Manual</a> <span class="citation" data-cites="stan2020stan">(<a href="20-references.html#ref-stan2020stan" role="doc-biblioref">Stan et al. 2020</a>)</span>.</p>
</section></section><section id="bayes-applied" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="bayes-applied">
<span class="header-section-number">5.2</span> Bayes Applied</h2>
<section id="simple-bayesian-process-tracing" class="level3" data-number="5.2.1"><h3 data-number="5.2.1" class="anchored" data-anchor-id="simple-bayesian-process-tracing">
<span class="header-section-number">5.2.1</span> Simple Bayesian Process Tracing</h3>
<p> Process tracing, in its most basic form, seeks to use within-case evidence to draw inferences about a case. We first outline the logic of Bayesian process tracing <em>without</em> explicit reference to a causal model, and then introduce how Bayesian process tracing can be underpinned by a causal model.</p>
<p>To begin without a model: Suppose we want to know whether <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in a case, and we use data on a within-case “clue,” <span class="math inline">\(K\)</span>, to make an inference about that question. We refer to the within-case evidence gathered during process tracing as <em>clues</em> in order to underline their probabilistic relationship to the causal relationship of interest. Readers familiar with the framework in <span class="citation" data-cites="collier2004sources">Collier, Brady, and Seawright (<a href="20-references.html#ref-collier2004sources" role="doc-biblioref">2004</a>)</span> can usefully think of “clues” as akin to causal process observations, although we highlight that there is no requirement that the clues be generated by the causal process connecting <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>. </p>
<p>As we will show, we can think of our question — did <span class="math inline">\(X\)</span> taking on the value it did in this case cause <span class="math inline">\(Y\)</span> to take on the value it did — as a question about the case’s nodal type for <span class="math inline">\(Y\)</span>. So, to make inferences, the analyst looks for clues that will be observed with some probability if the case is of a given type and that will <em>not</em> be observed with some probability if the case is <em>not</em> of that type.</p>
<p>It is relatively straightforward to express the logic of process tracing in Bayesian terms. As noted by others (e.g., <span class="citation" data-cites="BennettBayes">Bennett (<a href="20-references.html#ref-BennettBayes" role="doc-biblioref">2008</a>)</span>, <span class="citation" data-cites="beachpedersen2013process">Beach and Pedersen (<a href="20-references.html#ref-beachpedersen2013process" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="rohlfing2012case">Rohlfing (<a href="20-references.html#ref-rohlfing2012case" role="doc-biblioref">2012</a>)</span>), there is an evident connection between the use of evidence in process tracing and Bayesian inference. See <span class="citation" data-cites="fairfield2017explicit">Fairfield and Charman (<a href="20-references.html#ref-fairfield2017explicit" role="doc-biblioref">2017</a>)</span> for a detailed treatment of a Bayesian approach to qualitative research. As we have shown elsewhere, translating process tracing into Bayesian terms can also aid the integration of qualitative with quantitative causal inferences (<span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>).</p>
<p>To illustrate, suppose we are interested in economic crisis as a possible cause of regime collapse. We already have <span class="math inline">\(X,Y\)</span> data on one authoritarian regime: We know that it suffered an economic crisis (<span class="math inline">\(X=1\)</span>) and collapsed (<span class="math inline">\(Y=1\)</span>). We want to know what caused the collapse: Was it the economic crisis or something else? To make progress, we will try to draw inferences given a “clue.” Beliefs about the probabilities of observing clues for cases with different causal effects derive from theories of, or evidence about, the causal process connecting <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Suppose we theorize that the mechanism through which economic crisis generates collapse runs via diminished regime capacity to reward its supporters during an economic downturn. A possible clue to the operation of a causal effect, then, might be the observation of diminishing rents flowing to regime supporters shortly after the crisis. If we believe the theory – and using the <span class="math inline">\(a, b, c, d\)</span> notation for types from Chapter 2 – then this is a clue that we might believe to be highly probable for cases of type <span class="math inline">\(b\)</span> that have experienced economic crisis (those for which the crisis in fact caused the collapse) but of low probability for cases of type <span class="math inline">\(d\)</span> that have experienced crisis (those for which the collapse occurred for other reasons).</p>
<p>To make use of Bayes’ rule we need to:</p>
<ol type="1">
<li>define our parameters</li>
<li>provide prior beliefs about the parameters</li>
<li>define a likelihood function—indicating the probability of observing different data patterns given stipulated parameters</li>
<li>provide the “probability of the data”—this can be calculated from 2. and 3.</li>
<li>plug these into Bayes’ rule to calculate a posterior on the parameters</li>
</ol>
<p>We can then calculate the posterior on any quantity of interest that can be formed by combining or transforming these parameters.</p>
<p>We discuss each of these steps in turn. We start with the simplest situation where we want to assess whether <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span>.</p>
<p><strong>Parameters.</strong> The inferential challenge is to determine whether the regime collapsed <em>because</em> of the crisis (it is a <span class="math inline">\(b\)</span> type) or whether it would have collapsed even without it (<span class="math inline">\(d\)</span> type). We do so using further information from the case—one or more clues.</p>
<p>Let <span class="math inline">\(\theta\in \{a,b,c,d\}\)</span> refer to the type of an individual case. In this initial setup, our hypothesis consists simply of a belief about <span class="math inline">\(\theta\)</span> for the case under examination: Specifically, whether the case is a <span class="math inline">\(b\)</span> type (<span class="math inline">\(\theta=b)\)</span>. The parameter of interest is the causal type, <span class="math inline">\(\theta\)</span>.</p>
<p>We first assume that we know the likelihood and then walk through <em>deriving</em> the likelihood from a causal model.</p>
<section id="known-priors-and-known-likelihood" class="level4" data-number="5.2.1.1"><h4 data-number="5.2.1.1" class="anchored" data-anchor-id="known-priors-and-known-likelihood">
<span class="header-section-number">5.2.1.1</span> Known Priors and Known Likelihood</h4>
<p>We imagine first that the priors and the likelihood can simply be supplied by the researcher.</p>
<p><strong>Prior.</strong> We let <span class="math inline">\(p\)</span> denote a prior degree of confidence assigned to the hypothesis (<span class="math inline">\(p = Pr(H)\)</span>). This is, here, our prior belief that an authoritarian regime that has experienced an economic crisis is a <span class="math inline">\(b\)</span>. </p>
<p><strong>Likelihood.</strong> We use the variable <span class="math inline">\(K\)</span> to register the outcome of the search for a clue, with <span class="math inline">\(K_1\)</span> indicating that a specific clue is searched for and found, and <span class="math inline">\(K_0\)</span> indicating that the clue is searched for and not found. The likelihood, <span class="math inline">\(\Pr(K=1|H)\)</span> is the probability of observing the clue, when we look for it in our case, if the hypothesis is true—that is, here, if the case is a <span class="math inline">\(b\)</span> type. The key feature of a clue is that the probability of observing the clue is believed to depend on the case’s causal type. In order to calculate the probability of the data, we will in fact, need two such probabilities: We let <span class="math inline">\(\phi_b\)</span> denote the probability of observing the clue for a case of <span class="math inline">\(b\)</span> type (<span class="math inline">\(\Pr(K=1|\theta=b)\)</span>), and <span class="math inline">\(\phi_d\)</span> the probability of observing the clue for a case of <span class="math inline">\(d\)</span> type (<span class="math inline">\(\Pr(K=1|\theta=d)\)</span>). The key idea in many accounts of process tracing is that the <em>differences</em> between these probabilities provide clues with probative value, that is, the ability to generate learning about causal types. The likelihood, <span class="math inline">\(\Pr(K=1|H)\)</span>, is simply <span class="math inline">\(\phi_b\)</span>.</p>
<p><strong>Probability of the data.</strong> This is the probability of observing the clue when we look for it in a case, <em>regardless</em> of its type, <span class="math inline">\((\Pr(K=1))\)</span>. More specifically, it is the probability of the clue in an <span class="math inline">\(X = 1\)</span> case with a positive outcome <span class="math inline">\(Y = 1\)</span>. As such a case can only be a <span class="math inline">\(b\)</span> or a <span class="math inline">\(d\)</span> type, this probability can be calculated simply from <span class="math inline">\(\phi_b\)</span> and <span class="math inline">\(\phi_d\)</span>, together with our prior beliefs about how likely an <span class="math inline">\(X=1, Y=1\)</span> case is to be a <span class="math inline">\(b\)</span> or a <span class="math inline">\(d\)</span> type.</p>
<p>This probability aligns (inversely) with Van Evera’s (1994) concept of “uniqueness.” </p>
<p><strong>Inference.</strong> We can now apply Bayes’ rule to describe the learning that results from process tracing. If we observe the clue when we look for it in the case, then our <em>posterior</em> belief in the hypothesis that the case is of type <em>b</em> is:</p>
<p><span class="math display">\[\begin{eqnarray*}
\Pr(\theta = b |K=1, X=Y=1)=  \frac{\phi_b p }{\phi_b p+\phi_d (1-p)}
\end{eqnarray*}\]</span></p>
<p>In this exposition, we did not use a causal model in a meaningful way—we simply needed the priors and the clue probabilities.</p>
</section><section id="sec-derived" class="level4" data-number="5.2.1.2"><h4 data-number="5.2.1.2" class="anchored" data-anchor-id="sec-derived">
<span class="header-section-number">5.2.1.2</span> Process Tracing with a Model: Derived Priors, Derived Likelihood</h4>
<p></p>
<p>A central claim of this book is that the priors and likelihoods that we use in Bayesian process tracing do not need to be treated as primitives or raw inputs into our analysis: They can themselves be justified by an underlying—“lower level”— <em>causal model</em>. When we ground process tracing in a causal model, we can transparently derive our priors and the likelihoods of the evidence from a set of explicitly stated substantive beliefs about how the world works. As we elaborate below, grounding process tracing in a model also helpfully imposes a kind of logical consistency on our priors and likelihoods as they all emerge from the same underlying belief set.</p>
<p>We elaborate this point in much greater detail later, but we illustrate at a high level how Bayesian updating from a causal model works. Imagine a world in which an <span class="math inline">\(X, Y\)</span> relationship is completely mediated by <span class="math inline">\(K\)</span>: So we have the structural causal model <span class="math inline">\(X \rightarrow K \rightarrow Y\)</span>. Moreover, suppose, from prior observations of the conditional distribution of outcomes given their causes, we mobilize background knowledge that:</p>
<ul>
<li>
<span class="math inline">\(\Pr(K=1 | X=0) = 0\)</span>, <span class="math inline">\(\Pr(K=1 | X=1) = 0.5\)</span>
</li>
<li>
<span class="math inline">\(\Pr(Y=1 | K=0) = 0.5\)</span>, <span class="math inline">\(\Pr(Y=1 | K=1) = 1\)</span>
</li>
</ul>
<p>This background knowledge is consistent with a world in which units are equally split between <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> types in the first step (which we will write as <span class="math inline">\(b^K\)</span>, <span class="math inline">\(c^K\)</span>), and units are equally split between <span class="math inline">\(b\)</span> and <span class="math inline">\(d\)</span> types in the second step (<span class="math inline">\(b^Y\)</span>, <span class="math inline">\(d^Y\)</span>). To see this, note that these probabilities are inconsistent with adverse effects at each stage. The differences in means then correspond to the share of types with positive effects.</p>
<p>We can calculate the types for the <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> relationship (<span class="math inline">\(\theta\)</span>) by combining types for each step. For instance, if a unit is a <span class="math inline">\((b^K, b^Y)\)</span> then it has type <span class="math inline">\(\theta=b\)</span> overall. If it is <span class="math inline">\(d^Y\)</span> in the final step, then it is a <span class="math inline">\(d\)</span> overall and so on.</p>
<p>Assume that the case at hand is sampled from this world.</p>
<p>Then, we can <em>calculate</em> that the prior probability, <span class="math inline">\(p\)</span>, that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=Y=1\)</span> is <span class="math inline">\(p = \frac13\)</span>. Given <span class="math inline">\(X=1\)</span>, the observation of <span class="math inline">\(Y=1\)</span> is consistent with <span class="math inline">\(b\)</span> types at both stages, a situation that our background knowledge tells us arises with probability 0.25; or with a <span class="math inline">\(d\)</span> type in the second stage, which arises with probability 0.5. The conditional probability that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in this case is, therefore, <span class="math inline">\(0.25/0.75 = 1/3\)</span>.</p>
<p>We can also use <a href="#tbl-worksheet" class="quarto-xref">Table&nbsp;<span>5.1</span></a> to figure out the priors—where, to be clear, we mean beliefs prior to observing <span class="math inline">\(K\)</span> albeit posterior to observing <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Here, we represent the four combinations of types at the two stages that are consistent with our background knowledge. We place a prior on each combination, also based on this background knowledge. If the <span class="math inline">\(X \rightarrow K\)</span> effect is a <span class="math inline">\(b\)</span> type 50% of the time and a <span class="math inline">\(c\)</span> type 50% of the time, while the <span class="math inline">\(K \rightarrow Y\)</span> stage is half <span class="math inline">\(b\)</span>’s and half <span class="math inline">\(d\)</span>’s, then we will have each combination a quarter of the time.</p>
<p>We can then calculate the probability that <span class="math inline">\(K=1\)</span> for a treated <span class="math inline">\(b\)</span> and <span class="math inline">\(d\)</span> case respectively as <span class="math inline">\(\phi_b=1\)</span> and <span class="math inline">\(\phi_d=0.5\)</span>. We can work this out as well from <a href="#tbl-worksheet" class="quarto-xref">Table&nbsp;<span>5.1</span></a>. For <span class="math inline">\(\phi_b\)</span>, the probability of <span class="math inline">\(K=1\)</span> for a <span class="math inline">\(b\)</span> type, we take the average value for <span class="math inline">\(K|X=1\)</span> in the rows for which <span class="math inline">\(\theta = b\)</span>—which in this case is just the first row, where the value of <span class="math inline">\(K|X=1\)</span> is <span class="math inline">\(1\)</span>. For <span class="math inline">\(\phi_d\)</span>, we take the average value of <span class="math inline">\(K|X=1\)</span> in the rows for which <span class="math inline">\(\theta = d\)</span>: <span class="math inline">\((1 + 0)/2 = 0.5\)</span>. Note that, when we average across possible states of the world, we weight each state by its prior probability (though this weighting falls away here since the priors are the same for each row).</p>
<div id="tbl-worksheet" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-worksheet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5.1: Worksheet to figure out implied “priors” (<span class="math inline">\(\Pr(\theta=b | X=1, Y=1)\)</span>) and posteriors (<span class="math inline">\(\Pr(\theta=b |X=1, Y=1, K=1)\)</span> from a chain model for a case with <span class="math inline">\(X=1, Y=1\)</span>.
</figcaption><div aria-describedby="tbl-worksheet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(\theta^K\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\theta^Y\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\theta\)</span></th>
<th style="text-align: center;"><span class="math inline">\(K|X=1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(Y|X=1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\theta = b| X=Y=1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\theta =b| X=Y=K=1\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(b^K\)</span></td>
<td style="text-align: center;"><span class="math inline">\(b^Y\)</span></td>
<td style="text-align: center;"><span class="math inline">\(b\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">TRUE</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(b^K\)</span></td>
<td style="text-align: center;"><span class="math inline">\(d^Y\)</span></td>
<td style="text-align: center;"><span class="math inline">\(d\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">FALSE</td>
<td style="text-align: center;">FALSE</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(c^K\)</span></td>
<td style="text-align: center;"><span class="math inline">\(b^Y\)</span></td>
<td style="text-align: center;"><span class="math inline">\(c\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">.</td>
<td style="text-align: center;">.</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(c^K\)</span></td>
<td style="text-align: center;"><span class="math inline">\(d^Y\)</span></td>
<td style="text-align: center;"><span class="math inline">\(d\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">FALSE</td>
<td style="text-align: center;">.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Then, using Bayes’ rule (Equation <a href="#eq-Bayes" class="quarto-xref">Equation&nbsp;<span>5.2</span></a>) we can calculate the updated belief via:</p>
<p><span class="math display">\[\begin{eqnarray*}
\Pr(\theta = b |K=1, X=Y=1)&amp;=&amp;\frac{1\times \frac13}{1 \times \frac13 + \frac12 \times \frac23}\\
&amp;=&amp; \frac12
\end{eqnarray*}\]</span></p>
<p>We can also read the answer by simply taking the average value of the last column of <a href="#tbl-worksheet" class="quarto-xref">Table&nbsp;<span>5.1</span></a>, which has entries only for those cases in which we have <span class="math inline">\(X=1\)</span>, <span class="math inline">\(Y=1\)</span> and <span class="math inline">\(K=1\)</span>. Counting <span class="math inline">\(TRUE\)</span> as <span class="math inline">\(1\)</span> and <span class="math inline">\(FALSE\)</span> as <span class="math inline">\(0\)</span>, we get an average of <span class="math inline">\(0.5\)</span>. Thus, upon observing the clue <span class="math inline">\(K=1\)</span> in an <span class="math inline">\(X=1, Y=1\)</span> case, we shift our beliefs that <span class="math inline">\(X=1\)</span> caused <span class="math inline">\(Y=1\)</span> from a prior of <span class="math inline">\(\frac13\)</span> to a posterior of <span class="math inline">\(\frac12\)</span>. In contrast, had we observed <span class="math inline">\(K=0\)</span>, our posterior would have been 0.</p>
<p>One thing that these calculations demonstrate is that, as a practical matter, we do not have to go through the process of calculating a likelihood to engage in Bayesian updating. If we can directly calculate <span class="math inline">\(\Pr(H,d)\)</span> and <span class="math inline">\(\Pr(d)\)</span>, then we can make direct use of Equation <a href="#eq-condprob" class="quarto-xref">Equation&nbsp;<span>5.1</span></a> instead of Equation <a href="#eq-Bayes" class="quarto-xref">Equation&nbsp;<span>5.2</span></a>.</p>
<p>A few broader lessons for Bayesian process tracing are worth highlighting.</p>
<p>First, we see that we can draw both our priors on a hypothesis and the probative value of the evidence from the same causal model. A model-free approach to Bayesian process tracing might encourage us to think of our priors and the probative values of the evidence as independent quantities. We might be tempted to engage in thought experiments examining how inferences change as priors change (as we did, e.g., in the treatment in <span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span>), keeping probative value fixed. But such a thought experiment may entertain values of the relevant probabilities that cannot be jointly justified by any single plausible underlying belief about how the world works. A model forces a kind of epistemic consistency on the beliefs entering into process tracing. If we altered the model used in the above illustration—for example, if we had a stronger first stage and so a larger value for <span class="math inline">\(\Pr(K=1|X=0)\)</span>—this would alter <em>both</em> our prior, <span class="math inline">\(p\)</span>, and our calculations of <span class="math inline">\(\phi_d\)</span>.</p>
<p>Second, we see that, when we use a causal model, our priors and the probative value of evidence can, in principle, be justified by prior data. For instance, in this case, we show how the relevant probabilities can be derived from patterns emerging from a series of experiments (and a belief that the case at hand is not different from—“exchangeable with”—those in the experiment). We can thus place a lighter burden on subjective beliefs.</p>
<p>Third, contrary to some advice (e.g., <span class="citation" data-cites="fairfield2017explicit">Fairfield and Charman (<a href="20-references.html#ref-fairfield2017explicit" role="doc-biblioref">2017</a>)</span>, Table 3) we can get by without a full specification of all alternative causes for <span class="math inline">\(Y=1\)</span>. Thinking through alternative hypotheses may be a very useful exercise for assessing subjective beliefs, but as a general matter, it is not necessary and may not be helpful. Our background model and data give enough information to figure out the probability that <span class="math inline">\(K=1\)</span> if <span class="math inline">\(X\)</span> did not cause <span class="math inline">\(Y\)</span>. To be clear, we do not here assume that other causes do not exist; rather, we simply are not required to engage with them to engage with inference. </p>
<p>Fourth, this basic procedure can be used for many different types of queries, background models, and clue types. Nothing here is tied to a focus on the treatment effects emanating from a single cause for a single unit when researchers have access to a single mediator clue. The generalization is worked through in <a href="07-process-tracing-with-models.html" class="quarto-xref"><span>Chapter 7</span></a>, but the core logic is all in this example already.</p>
</section><section id="connection-with-classical-qualitative-tests" class="level4" data-number="5.2.1.3"><h4 data-number="5.2.1.3" class="anchored" data-anchor-id="connection-with-classical-qualitative-tests">
<span class="header-section-number">5.2.1.3</span> Connection with Classical Qualitative Tests</h4>
<p> The example we discussed in the last section was of a “hoop test,” one of the four classical tests (“smoking gun,” “hoop,” “straw in the wind,” and “doubly decisive”) described by <span class="citation" data-cites="Van-Evera:1997">Van Evera (<a href="20-references.html#ref-Van-Evera:1997" role="doc-biblioref">1997</a>)</span> and <span class="citation" data-cites="collier2011understanding">Collier (<a href="20-references.html#ref-collier2011understanding" role="doc-biblioref">2011</a>)</span>. Seeing the clue led to a modest boost in confidence in the hypothesis, while not seeing the clue fully disconfirmed the hypothesis. In <a href="15-justifying-models.html" class="quarto-xref"><span>Chapter 15</span></a> we show how all these tests can be derived from more fundamental causal models in the same way.</p>
<p>The hoop test in this example makes use of an extreme probability—a probability of 0 of not seeing a clue if a hypothesis is true. But the core logic of process-tracing tests does not depend on such extreme probabilities. Rather, the logic described here allows for a simple generalization of Van Evera’s typology of tests by conceiving of the certainty and uniqueness of clues as lying along a continuum. In this sense, the four tests might be thought of as special cases—particular regions that lie on the boundaries of a “probative-value space.”</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-5-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-5-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05-being-Bayesian_files/figure-html/fig-HJ-F-5-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1152">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-5-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.2: A mapping from the probability of observing a clue if the proposition that a case is a <span class="math inline">\(b\)</span> type is true (<span class="math inline">\(\phi-b\)</span>) or false (<span class="math inline">\(\phi-d\)</span>) to a generalization of the tests described in Van-Evera (1997).
</figcaption></figure>
</div>
</div>
</div>
<p>To illustrate the idea, we represent the range of combinations of possible probabilities for <span class="math inline">\(\phi_b\)</span> and <span class="math inline">\(\phi_d\)</span> as a square in <a href="#fig-HJ-F-5-2" class="quarto-xref">Figure&nbsp;<span>5.2</span></a> and mark the spaces inhabited by Van Evera’s tests. As can be seen, the type of test involved depends on both the probative value of the clue for the proposition that the unit is a <span class="math inline">\(b\)</span> type (monotonic in <span class="math inline">\(\phi_b/\phi_d\)</span>) and the probative value of the absence of the clue for the proposition that the units is a <span class="math inline">\(d\)</span> type (monotonic in <span class="math inline">\((1-\phi_d)/(1-\phi_b)\)</span>). A clue acts as a smoking gun for proposition “<span class="math inline">\(b\)</span>” (the proposition that the case is a <span class="math inline">\(b\)</span> type) if it is highly unlikely to be observed if proposition <span class="math inline">\(b\)</span> is false, and more likely to be observed if the proposition is true (bottom left, above diagonal). A clue acts as a “hoop” test if it is highly likely to be found if <span class="math inline">\(b\)</span> is true, even if it is still quite likely to be found if it is false. Doubly decisive tests arise when a clue is very likely if <span class="math inline">\(b\)</span> and very unlikely if not. It is, however, also easy to imagine clues with probative values lying in the large space between these extremes.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> </p>
</section></section><section id="a-generalization-bayesian-inference-on-arbitrary-queries" class="level3" data-number="5.2.2"><h3 data-number="5.2.2" class="anchored" data-anchor-id="a-generalization-bayesian-inference-on-arbitrary-queries">
<span class="header-section-number">5.2.2</span> A Generalization: Bayesian Inference on Arbitrary Queries</h3>
<p> In <a href="04-causal-questions.html" class="quarto-xref"><span>Chapter 4</span></a>, we described queries of interest as queries over causal types.</p>
<p>Returning to our discussion of queries in <a href="04-causal-questions.html" class="quarto-xref"><span>Chapter 4</span></a>, suppose we start with the model <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span>, and our query is whether <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(Y\)</span>. This is a query that is satisfied by four sets of causal types: those in which <span class="math inline">\(X\)</span> has a positive effect on <span class="math inline">\(M\)</span> and <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(Y\)</span>, with <span class="math inline">\(X\)</span> being either 0 or 1; and those in which <span class="math inline">\(X\)</span> has a negative effect on <span class="math inline">\(M\)</span> and <span class="math inline">\(M\)</span> has a negative effect on <span class="math inline">\(Y\)</span>, with <span class="math inline">\(X\)</span> being either 0 or 1. Our inferences on the query will thus involve gathering these different causal types, and their associated posterior probabilities, together. As we showed in <a href="04-causal-questions.html" class="quarto-xref"><span>Chapter 4</span></a>, the same is true for very complex causal estimands.</p>
<p>Once queries are defined in terms of causal types, the formation of beliefs, given data <span class="math inline">\(d\)</span>, about queries follows immediately from application of Equation <a href="#eq-condprob" class="quarto-xref">Equation&nbsp;<span>5.1</span></a>.</p>
<p>Let <span class="math inline">\(Q(q)\)</span> define the set of types that satisfy query <span class="math inline">\(q\)</span>, and let <span class="math inline">\(D(d)\)</span> denote the set of types that generate data <span class="math inline">\(d\)</span> (recall that each causal type, if fully specified, implies a data type).</p>
<p>The updated beliefs about the query are given by the distribution:</p>
<p><span class="math display">\[p(q' | d) = \int_{Q(q')} p(\theta|d)d\theta =  \frac{\int_{Q(q') \cap D(d)} p(\theta)d\theta}{\int_{D(d)}p(\theta') d\theta'}\]</span></p>
<p>This expression gathers together all the causal types (combinations of nodal types) that satisfy a query and assesses how likely these are, collectively, given the data.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>Return now to Mr.&nbsp;Smith’s puzzle from Section 5.1.1. We can think of the two “nodal types” here as the sexes of the two children, child <span class="math inline">\(A\)</span> and child <span class="math inline">\(B\)</span>. The query here is <span class="math inline">\(q\)</span>: “Are both boys?” The statement “<span class="math inline">\(q=1\)</span>” is equivalent to the statement, “<span class="math inline">\(A\)</span> is a boy &amp; <span class="math inline">\(B\)</span> is a boy.” Thus it takes the value <span class="math inline">\(q=1\)</span> under just one causal type, when both nodes have been assigned to the value “boy.” Statement <span class="math inline">\(q=0\)</span> is the statement “<span class="math inline">\(A\)</span> is a boy &amp; <span class="math inline">\(B\)</span> is a girl” or “<span class="math inline">\(A\)</span> is a girl &amp; <span class="math inline">\(B\)</span> is a boy” or “<span class="math inline">\(A\)</span> is a girl &amp; <span class="math inline">\(B\)</span> is a girl”. Thus, <span class="math inline">\(q=0\)</span> in three contexts. If we assume that each of the two children is equally likely to be a boy or a girl with independent probabilities, then each of the four contexts is equally likely. The result can then be figured out as <span class="math inline">\(p(q=1) = \frac{1\times \frac{1}{4}}{1\times \frac{1}{4} + 1\times \frac{1}{4}+1\times \frac{1}{4}+0\times \frac{1}{4}} = \frac{1}{3}\)</span>. This answer requires summing over only one causal type. The quantity <span class="math inline">\(p(q=0)\)</span> is of course, the complement of this, but using Bayes’ formula one can see that it can also be found by summing over the posterior probability of the three causal types for which the statement <span class="math inline">\(q=0\)</span> is true.</p>
</section></section><section id="features-of-bayesian-updating" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="features-of-bayesian-updating">
<span class="header-section-number">5.3</span> Features of Bayesian Updating</h2>
<p>Bayesian updating has implications that may not be obvious at first glance. These will matter for all forms of inference we examine in this book, but they can all be illustrated in simple settings.</p>
<section id="AppPriors" class="level3" data-number="5.3.1"><h3 data-number="5.3.1" class="anchored" data-anchor-id="AppPriors">
<span class="header-section-number">5.3.1</span> Priors Matter</h3>
<p>As we noted in the previous section, probative value does not depend upon priors. However, the amount of learning that results from a given piece of new data <em>can</em> depend strongly on prior beliefs. We have already seen this with the example of interpreting our test results above. <a href="#fig-HJ-F-5-3" class="quarto-xref">Figure&nbsp;<span>5.3</span></a> illustrates the point for process tracing inferences.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-5-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-5-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05-being-Bayesian_files/figure-html/fig-HJ-F-5-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="960">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-5-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.3: A smoking in which gun test with greatest impact on beliefs when priors are middling low and the clue is observed; a ‘hoop test’ in which the greatest effects arise when priors are middling high and the clue is not observed.
</figcaption></figure>
</div>
</div>
</div>
<p>In each subgraph of <a href="#fig-HJ-F-5-3" class="quarto-xref">Figure&nbsp;<span>5.3</span></a> , we show how much learning occurs under different scenarios. The horizontal axis indicates the level of prior confidence in the hypothesis, and the curve indicates the posterior belief that arises if we do (or do not) observe the clue. We label the figures referencing classic tests that they approximate though, of course, there can be stronger or weaker versions of each of these tests.</p>
<p>As can be seen, the amount of learning that occurs—the shift in beliefs from prior to posterior—depends a good deal on what prior we start out with. For the smoking gun example (with probative value of just 0.9—substantial, but not strong, according to <span class="citation" data-cites="jeffreys1998theory">Jeffreys (<a href="20-references.html#ref-jeffreys1998theory" role="doc-biblioref">1998</a>)</span>), the amount of learning is highest for values around 0.25—and then declines as we have more and more prior confidence in our hypothesis. For the hoop test (also with probative value of just 0.9), the amount of learning when the clue is <em>not</em> observed is greatest for hypotheses in which we have middling-high confidence (around 0.75), and minimal for hypotheses in which we have a very high or a very low level of confidence. At the maximum, beliefs change from 0.74 to 0.26—-a nearly two thirds down weighting of the proposition.</p>
<p>The implication here is that our inferences with respect to a hypothesis must be based not just on the search for a clue predicted by the hypothesis but also on the <em>plausibility</em> of the hypothesis, based on other things we know.</p>
<p>We emphasize two respects in which these implications depart from common intuitions.</p>
<p>First, we cannot make <em>general</em> statements about how decisive different categories of test, in Van Evera’s framework, will be. It is commonly stated that hoop testsare devastating to a theory when they are failed, while smoking gun tests provide powerful evidence in favor of a hypothesis. But, in fact the amount learned depends not just on features of the clues but also on prior beliefs. </p>
<p>Second, although scholars frequently treat evidence that goes against the grain of the existing literature as especially enlightening, in the Bayesian framework the contribution of such evidence may sometimes be modest, precisely because received wisdom carries weight. Thus, although the discovery of <em>disconfirming</em> evidence—an observation thought to be strongly inconsistent with the hypothesis—for a hypothesis commonly believed to be true is more informative (has a larger impact on beliefs) than <em>confirming</em> evidence, this does not mean that we learn more than we would have if the prior were weaker. It is not true as a general proposition that we learn more the bigger the “surprise” a piece of evidence is. The effect of disconfirming evidence on a hypothesis about which we are highly confident can be <em>smaller</em> than it would be for a hypothesis about which we are only somewhat confident. When it comes to very strong hypotheses, the “discovery” of disconfirming evidence is very likely to be a false negative; likewise, the discovery of supporting evidence for a very implausible hypothesis is very likely to be a false positive. The Bayesian approach takes account of these features naturally.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
</section><section id="simultaneous-joint-updating" class="level3" data-number="5.3.2"><h3 data-number="5.3.2" class="anchored" data-anchor-id="simultaneous-joint-updating">
<span class="header-section-number">5.3.2</span> Simultaneous, joint updating</h3>
<p>When we update, we often update over multiple quantities. When we see a smoking gun, for instance, we might update our beliefs that the butler did it, but we might also update our beliefs about how likely we are to see smoking guns—maybe they are not as rare as we thought. </p>
<p>Intuitively we might think of this updating as happening sequentially—first of all, we update over the general proposition, then we update over the particular claim. But in fact, it’s simpler to update over both quantities at once. What we need to avoid is just updating over some of the unknown quantities while keeping others fixed.</p>
<p>As a simple illustration, say we thought there were a two thirds chance that we were in World A in which <em>K</em> serves as a smoking gun test and a one third chance that were in world <em>B</em> in which <em>K</em> provides a hoop test. Specifically, we have:</p>
<p><em>World A</em>:</p>
<ul>
<li><span class="math inline">\(\Pr(H = 0, K=0| W = A) = \frac{1}3\)</span></li>
<li><span class="math inline">\(\Pr(H = 0, K =1 | W = A) = 0\)</span></li>
<li><span class="math inline">\(\Pr(H= 1, K = 0 | W = A) = \frac{1}3\)</span></li>
<li><span class="math inline">\(\Pr(H = 1, K = 1 | W = A) = \frac{1}3\)</span></li>
</ul>
<p><em>World B</em>:</p>
<ul>
<li><span class="math inline">\(\Pr(H = 0, K=0| W = B) = \frac{1}3\)</span></li>
<li><span class="math inline">\(\Pr(H = 0, K =1 | W = B) = \frac{1}3\)</span></li>
<li><span class="math inline">\(\Pr(H= 1, K = 0 | W = B) = 0\)</span></li>
<li><span class="math inline">\(\Pr(H = 1, K = 1 | W = B) = \frac{1}3\)</span></li>
</ul>
<p>What should we infer when we see <span class="math inline">\(K=1\)</span>. If we knew we were in World <em>A</em>, then on learning <span class="math inline">\(K=1\)</span> we would be sure that <span class="math inline">\(H=1\)</span>; whereas if we knew that we were in World <em>B</em>, then on learning <span class="math inline">\(K\)</span> we would put the probability that <span class="math inline">\(H = 1\)</span> at 0.5. We might be tempted to infer that the expected probability that <span class="math inline">\(H = 1\)</span> is then <span class="math inline">\(\frac23 \times 1 +  \frac13 \times \frac12  = \frac{5}6\)</span>.</p>
<p>This is incorrect because when we observe <span class="math inline">\(K=1\)</span> we need to update not just on our inferences <em>given</em> whatever world we are in, but also our beliefs <em>about</em> what world we are in. We might tackle the problem in three ways.</p>
<p>First, we might simplify. Integrating over worlds the joint probabilities for <span class="math inline">\(H\)</span> and <span class="math inline">\(K\)</span> are:</p>
<p><em>Average World</em>:</p>
<ul>
<li><span class="math inline">\(\Pr(H = 0, K=0) = \frac{1}3\)</span></li>
<li><span class="math inline">\(\Pr(H = 0, K =1) = \frac{1}9\)</span></li>
<li><span class="math inline">\(\Pr(H= 1, K = 0) = \frac{2}9\)</span></li>
<li><span class="math inline">\(\Pr(H = 1, K = 1) = \frac{1}3\)</span></li>
</ul>
<p>And from these numbers we can calculate the probability <span class="math inline">\(H=1\)</span> given <span class="math inline">\(K=1\)</span> as <span class="math inline">\(\frac{\frac13}{\frac13 + \frac19} = \frac34\)</span>.</p>
<p>TThis is the simplest approach. However, it gives no information about the learning over worlds. In practice, we might want to keep track of our beliefs about worlds. These might, for instance, be of theoretical interest and knowing which world we are in may be useful for the <em>next</em> case we look at.</p>
<p>So in approach 2 we update over the worlds and infer that we are in World A with probability <span class="math inline">\(\frac{\frac13\frac23}{\frac13\frac23 + \frac13\frac23} = \frac12\)</span>. The numerator is the prior probability of being in World A times the probability of seeing <span class="math inline">\(K=1\)</span> given we are in world <span class="math inline">\(A\)</span>; the denominator is the probability of seeing <span class="math inline">\(K=1\)</span>. We can now do the correct calculation and infer probability <span class="math inline">\(\frac12 \times 1 +  \frac12 \times \frac12  = \frac{3}4\)</span>.</p>
<p>In a third approach, we imagine eight possible states and update directly over these eight states.</p>
<ul>
<li><span class="math inline">\(\Pr(H = 0, K=0, W = A) = \frac{2}9\)</span></li>
<li><span class="math inline">\(\Pr(H = 0, K =1, W = A) = 0\)</span></li>
<li><span class="math inline">\(\Pr(H= 1, K = 0, W = A) = \frac{2}9\)</span></li>
<li><span class="math inline">\(\Pr(H = 1, K = 1, W = A) = \frac{2}9\)</span></li>
<li><span class="math inline">\(\Pr(H = 0, K=0, W = B) = \frac{1}9\)</span></li>
<li><span class="math inline">\(\Pr(H = 0, K =1, W = B) = \frac{1}9\)</span></li>
<li><span class="math inline">\(\Pr(H= 1, K = 0, W = B) = 0\)</span></li>
<li><span class="math inline">\(\Pr(H = 1, K = 1, W = B) = \frac{1}9\)</span></li>
</ul>
<p>Then applying Bayes’ rule over these states yields the posterior probability: <span class="math inline">\(\frac{\frac29 + \frac19}{\frac{2}9 + \frac19 +\frac19}=\frac34\)</span>. The numerator gathers the probability for all states in which <span class="math inline">\(K=1\)</span> and <span class="math inline">\(H=1\)</span>, and the denominator gathers the probability for all states in which <span class="math inline">\(K=1\)</span>.</p>
<p>Thus, we have three ways to apply Bayes’ rule in this simple setup.</p>
<p>More generally, we propose that researchers update over a causal model. As we explain later in this book, updating over a causal model allows us to learn across cases and levels of analysis: we can make inferences about the case at hand, about the population from which the case is drawn, and about other cases of interest, given data on those cases. In this example for instance, the inferences we would draw about future cases could be quite different if we believed <span class="math inline">\(W\)</span> was the same for all units~– and so our uncertainty represents what we might call “uncertainty about laws”~– than if we believed that each unit was assigned <span class="math inline">\(W\)</span> independently with a common probability~– in which case we would think of the uncertainty as representing “uncertainty about units.” Under the former belief, learning from one unit is informative for learning about another; under the second belief, it is not.</p>
</section><section id="posteriors-are-independent-of-the-ordering-of-data" class="level3" data-number="5.3.3"><h3 data-number="5.3.3" class="anchored" data-anchor-id="posteriors-are-independent-of-the-ordering-of-data">
<span class="header-section-number">5.3.3</span> Posteriors Are Independent of the Ordering of Data</h3>
<p>We often think of learning as a process in which we start off with some set of beliefs—our priors—we gather data, and update our beliefs, forming a posterior; we then observe new data, and we update again, forming a new posterior, having treated the previous posterior as a new prior. In such scenario, it might seem natural that it would matter which data we saw first and which later.</p>
<p>In fact, however, Bayesian updating is blind to ordering. If we learn first that a card is a face card and second that it is black, our posteriors that the card is a Jack of Spades go from 1 in 52 to 1 in 12 to 1 in 6. If we learn first that the card is black and second that it is a face card, our posteriors that it is a Jack of Spades go from 1 in 52 to 1 in 26 to 1 in 6. We end up in the same place in both cases. And we would have had the same conclusion if we learned in one go that the card is a black face card.</p>
<p>The math here is easy enough. Our posterior given two sets of data <span class="math inline">\(D_1, D_2\)</span> can be written:</p>
<p><span class="math display">\[p(\theta | D_1, D_2) = \frac{p(\theta, D_1, D_2)}{p(D_1, D_2)} = \frac{p(\theta, D_1 | D_2)p(D_2)}{p(D_1 | D_2)p(D_2)}= \frac{p(\theta, D_1 | D_2)}{p(D_1 | D_2)}\]</span></p>
<p>or, equivalently:</p>
<p><span class="math display">\[p(\theta | D_1, D_2) = \frac{p(\theta, D_1, D_2)}{p(D_1, D_2)} = \frac{p(\theta, D_2 | D_1)p(D_1)}{p(D_2 | D_1)p(D_1)}= \frac{p(\theta, D_2 | D_1)}{p(D_2 | D_1)}\]</span></p>
<p>In other words, our posteriors given both <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span> can be thought of as the result of updating on <span class="math inline">\(D_2\)</span> given we already know <span class="math inline">\(D_1\)</span>, or as the result of updating on <span class="math inline">\(D_1\)</span> given we already know <span class="math inline">\(D_2\)</span>.</p>
<p>This fact will be useful in applications. Suppose that we are interested in <span class="math inline">\(X'\)</span>s effect on <span class="math inline">\(Y\)</span>, starting with a flat prior. We might first encounter data on <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> for a set of cases. Perhaps we subsequently observe additional data on (say) a moderator, <span class="math inline">\(K\)</span>. It might seem natural to update once from the <span class="math inline">\(X,Y\)</span> data and then a second time from the data on <span class="math inline">\(K\)</span>. Rather than updating twice, however, the fact that updating is invariant to order means that we can start with a flat prior and update once with the data on <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, and <span class="math inline">\(K\)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-beachpedersen2013process" class="csl-entry" role="listitem">
Beach, Derek, and Rasmus Brun Pedersen. 2013. <em>Process-Tracing Methods: Foundations and Guidelines</em>. Ann Arbor, MI: University of Michigan Press.
</div>
<div id="ref-BennettBayes" class="csl-entry" role="listitem">
Bennett, Andrew. 2008. <span>“Process Tracing. A Bayesian Perspective.”</span> In <em>The Oxford Handbook of Political Methodology</em>, edited by Janet M. Box-Steffensmeier, Henry E. Brady, and David Collier, 702–21. Oxford, UK: Oxford University Press.
</div>
<div id="ref-collier2011understanding" class="csl-entry" role="listitem">
Collier, David. 2011. <span>“Understanding Process Tracing.”</span> <em>PS: Political Science &amp; Politics</em> 44 (04): 823–30.
</div>
<div id="ref-collier2004sources" class="csl-entry" role="listitem">
Collier, David, Henry E Brady, and Jason Seawright. 2004. <span>“Sources of Leverage in Causal Inference: Toward an Alternative View of Methodology.”</span> In <em>Rethinking Social Inquiry: Diverse Tools, Shared Standards</em>, edited by David Collier and Henry E Brady, 229–66. Lanham, MD: Rowman &amp; Littlefield.
</div>
<div id="ref-fairfield2017explicit" class="csl-entry" role="listitem">
Fairfield, Tasha, and Andrew Charman. 2017. <span>“Explicit Bayesian Analysis for Process Tracing: Guidelines, Opportunities, and Caveats.”</span> <em>Political Analysis</em> 25 (3): 363–80.
</div>
<div id="ref-gardner1961second" class="csl-entry" role="listitem">
Gardner, Martin. 1961. <em>The Second Scientific American Book of Mathematical Puzzles and Diversions</em>. Simon; Schuster New York.
</div>
<div id="ref-good1984c197" class="csl-entry" role="listitem">
Good, Irving John. 1984. <span>“C197. The Best Explicatum for Weight of Evidence.”</span> <em>Journal of Statistical Computation and Simulation</em> 19 (4): 294–99.
</div>
<div id="ref-good1950probability" class="csl-entry" role="listitem">
Good, Isidore Jacob. 1950. <span>“Probability and the Weighing of Evidence.”</span>
</div>
<div id="ref-hoffrage1998using" class="csl-entry" role="listitem">
Hoffrage, Ulrich, and Gerd Gigerenzer. 1998. <span>“Using Natural Frequencies to Improve Diagnostic Inferences.”</span> <em>Academic Medicine</em> 73 (5): 538–40.
</div>
<div id="ref-humphreys2015mixing" class="csl-entry" role="listitem">
Humphreys, Macartan, and Alan M Jacobs. 2015. <span>“Mixing Methods: A Bayesian Approach.”</span> <em>American Political Science Review</em> 109 (04): 653–73.
</div>
<div id="ref-jeffreys1998theory" class="csl-entry" role="listitem">
Jeffreys, Harold. 1998. <em>The Theory of Probability</em>. OUP Oxford.
</div>
<div id="ref-kaye1986quantifying" class="csl-entry" role="listitem">
Kaye, David H. 1986. <span>“Quantifying Probative Value.”</span> <em>BUL Rev.</em> 66: 761.
</div>
<div id="ref-kaye2003misquantification" class="csl-entry" role="listitem">
Kaye, David H, and Jonathan J Koehler. 2003. <span>“The Misquantification of Probative Value.”</span> <em>Law and Human Behavior</em> 27 (6): 645–59.
</div>
<div id="ref-pearl2000causality" class="csl-entry" role="listitem">
Pearl, Judea. 2000. <em>Causality: Models, Reasoning and Inference</em>. Vol. 29. Cambridge Univ Press.
</div>
<div id="ref-pearl2012causal" class="csl-entry" role="listitem">
———. 2012. <span>“The Causal Foundations of Structural Equation Modeling.”</span> DTIC Document.
</div>
<div id="ref-rohlfing2012case" class="csl-entry" role="listitem">
Rohlfing, I. 2012. <em>Case Studies and Causal Inference: An Integrative Framework</em>. Research Methods Series. New York: Palgrave Macmillan. <a href="http://books.google.ca/books?id=4W%5C_XuA3njRQC">http://books.google.ca/books?id=4W\_XuA3njRQC</a>.
</div>
<div id="ref-stan2020stan" class="csl-entry" role="listitem">
Stan, Development Team et al. 2020. <span>“Stan Modeling Language Users Guide and Reference Manual.”</span> <em>Technical Report</em>. <a href="https://mc-stan.org/docs/2_24/reference-manual/index.html">https://mc-stan.org/docs/2_24/reference-manual/index.html</a>.
</div>
<div id="ref-Van-Evera:1997" class="csl-entry" role="listitem">
Van Evera, Stephen. 1997. <em>Guide to Methods for Students of Political Science</em>. Ithaca, NY: Cornell University Press.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>The vertical bar, <span class="math inline">\(|\)</span>, in this equation should be read as “given that.” Thus, <span class="math inline">\(Pr(A|B)\)</span> should be read as the probability that <span class="math inline">\(A\)</span> is true or occurs given that <span class="math inline">\(B\)</span> is true or occurs.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In a footnote in <span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span> we describe a notion of probative value that made use of expected learning. We think, however, it is better to keep these notions separate to avoid confusion and so adopt the definition used by <span class="citation" data-cites="kaye1986quantifying">Kaye (<a href="20-references.html#ref-kaye1986quantifying" role="doc-biblioref">1986</a>)</span> and <span class="citation" data-cites="fairfield2017explicit">Fairfield and Charman (<a href="20-references.html#ref-fairfield2017explicit" role="doc-biblioref">2017</a>)</span>. As a practical matter, however that work used the same concept of expected learning as presented here and varied probative value by varying the <span class="math inline">\(\phi\)</span> quantities directly.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>We discuss the relationship between expected error and expected posterior variance more fully in <a href="06-theory-as-causal-models.html" class="quarto-xref"><span>Chapter 6</span></a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This quantity is given in <span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span> (Equation 4). The idea behind this expression is that to assess loss, we need to specify our query <span class="math inline">\(q\)</span>, which is itself a function of a set of underlying parameters, <span class="math inline">\(\theta\)</span>, that characterize the world. Suppose that <span class="math inline">\(\theta\)</span> correctly characterizes the world so that the true value of the query is <span class="math inline">\(q(\theta)\)</span>. Then, the beliefs about the world in <span class="math inline">\(\theta\)</span> imply a probability distribution over the type of data we might see under a given data strategy. For any particular data realization <span class="math inline">\(d\)</span> that we could potentially observe, we can derive an <em>estimate</em> of our query, <span class="math inline">\(\hat{q}(d)\)</span>. We can then calculate the inaccuracy of that estimate relative to the truth, <span class="math inline">\(q(\theta)\)</span>. We operationalize that inaccuracy, or loss, as a squared deviation, though any other metric could also be employed. We then calculate the expected loss over the different values of <span class="math inline">\(\theta\)</span> that we entertain—say, given a prior probability distribution over <span class="math inline">\(\theta\)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>We thank Tasha Fairfield for discussions around this graph, which differs from that in <span class="citation" data-cites="humphreys2015mixing">Humphreys and Jacobs (<a href="20-references.html#ref-humphreys2015mixing" role="doc-biblioref">2015</a>)</span> by placing tests more consistently on common rays (capturing ratios) originating from (0,0) and (1,1).<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>For an abstract representation of the relations between assumptions, queries, data, and conclusions, see Figure 1 in <span class="citation" data-cites="pearl2012causal">Pearl (<a href="20-references.html#ref-pearl2012causal" role="doc-biblioref">2012</a>)</span>. For a treatment of the related idea of <em>abduction</em>, see <span class="citation" data-cites="pearl2000causality">Pearl (<a href="20-references.html#ref-pearl2000causality" role="doc-biblioref">2000</a>)</span>, p 206.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>We note, however, that one common intuition—that little is learned from disconfirming evidence on a low-plausibility hypothesis or from confirming evidence on a high-plausibility one—<em>is</em> correct.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./04-causal-questions.html" class="pagination-link" aria-label="Causal Queries">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Causal Queries</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./06-theory-as-causal-models.html" class="pagination-link" aria-label="Theories as Causal Models">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Theories as Causal Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>