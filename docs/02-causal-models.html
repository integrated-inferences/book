<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>2&nbsp; Causal Models – Integrated Inferences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-illustrating-models.html" rel="next">
<link href="./01-intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="style.css">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-causal-models.html">I Foundations</a></li><li class="breadcrumb-item"><a href="./02-causal-models.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Causal Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Integrated Inferences</a> 
        <div class="sidebar-tools-main">
    <a href="./Integrated-Inferences.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Start</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Front matter</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quick guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">I Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-causal-models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-illustrating-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Illustrating Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-causal-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Causal Queries</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-being-Bayesian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bayesian Answers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-theory-as-causal-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Theories as Causal Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">II Model-based Causal Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-process-tracing-with-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Process Tracing with Causal Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-PT-application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Process Tracing Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-mixing-methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Integrated Inferences</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-mixed-application.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Integrated Inferences Applications</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-fusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Mixing Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">III Design choices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-clue-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Clue Selection as a Decision Problem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-case-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Case Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-wide-or-deep.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Going Wide, Going Deep</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">IV Models in Question</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-justifying-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Justifying Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-evaluating-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Evaluating Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17-conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Final Words</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">End matter</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19-errata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Errata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20-references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p><img src=".\figures/cover_smaller.jpg" class="img-fluid"></p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-counterfactualmodel" id="toc-sec-counterfactualmodel" class="nav-link active" data-scroll-target="#sec-counterfactualmodel"><span class="header-section-number">2.1</span> The Counterfactual Model</a>
  <ul class="collapse">
<li><a href="#potential-outcomes" id="toc-potential-outcomes" class="nav-link" data-scroll-target="#potential-outcomes"><span class="header-section-number">2.1.1</span> Potential Outcomes</a></li>
  <li><a href="#sec-generalize" id="toc-sec-generalize" class="nav-link" data-scroll-target="#sec-generalize"><span class="header-section-number">2.1.2</span> A Generalization</a></li>
  <li><a href="#summaries-of-potential-outcomes" id="toc-summaries-of-potential-outcomes" class="nav-link" data-scroll-target="#summaries-of-potential-outcomes"><span class="header-section-number">2.1.3</span> Summaries of Potential Outcomes</a></li>
  </ul>
</li>
  <li>
<a href="#causal-models-and-directed-acyclic-graphs" id="toc-causal-models-and-directed-acyclic-graphs" class="nav-link" data-scroll-target="#causal-models-and-directed-acyclic-graphs"><span class="header-section-number">2.2</span> Causal Models and Directed Acyclic Graphs</a>
  <ul class="collapse">
<li><a href="#the-nodes" id="toc-the-nodes" class="nav-link" data-scroll-target="#the-nodes"><span class="header-section-number">2.2.1</span> The Nodes</a></li>
  <li><a href="#the-functions" id="toc-the-functions" class="nav-link" data-scroll-target="#the-functions"><span class="header-section-number">2.2.2</span> The Functions</a></li>
  <li><a href="#the-distributions" id="toc-the-distributions" class="nav-link" data-scroll-target="#the-distributions"><span class="header-section-number">2.2.3</span> The Distributions</a></li>
  <li><a href="#sec-cond_indep_2" id="toc-sec-cond_indep_2" class="nav-link" data-scroll-target="#sec-cond_indep_2"><span class="header-section-number">2.2.4</span> 2.2.4 Conditional Independence</a></li>
  </ul>
</li>
  <li>
<a href="#graphing-models-and-using-graphs" id="toc-graphing-models-and-using-graphs" class="nav-link" data-scroll-target="#graphing-models-and-using-graphs"><span class="header-section-number">2.3</span> Graphing Models and Using Graphs</a>
  <ul class="collapse">
<li><a href="#sec-graphing" id="toc-sec-graphing" class="nav-link" data-scroll-target="#sec-graphing"><span class="header-section-number">2.3.1</span> Rules for Graphing Causal Models</a></li>
  <li><a href="#conditional-independence-from-dags" id="toc-conditional-independence-from-dags" class="nav-link" data-scroll-target="#conditional-independence-from-dags"><span class="header-section-number">2.3.2</span> Conditional Independence from DAGs</a></li>
  <li><a href="#simplifying-models" id="toc-simplifying-models" class="nav-link" data-scroll-target="#simplifying-models"><span class="header-section-number">2.3.3</span> Simplifying Models</a></li>
  </ul>
</li>
  <li><a href="#sec-conc2" id="toc-sec-conc2" class="nav-link" data-scroll-target="#sec-conc2"><span class="header-section-number">2.4</span> Conclusion</a></li>
  <li>
<a href="#chapter-appendix" id="toc-chapter-appendix" class="nav-link" data-scroll-target="#chapter-appendix"><span class="header-section-number">2.5</span> Chapter Appendix</a>
  <ul class="collapse">
<li><a href="#steps-for-constructing-causal-models" id="toc-steps-for-constructing-causal-models" class="nav-link" data-scroll-target="#steps-for-constructing-causal-models"><span class="header-section-number">2.5.1</span> Steps for Constructing Causal Models</a></li>
  <li><a href="#model-construction-in-code" id="toc-model-construction-in-code" class="nav-link" data-scroll-target="#model-construction-in-code"><span class="header-section-number">2.5.2</span> Model Construction in Code</a></li>
  <li><a href="#sec-tryci" id="toc-sec-tryci" class="nav-link" data-scroll-target="#sec-tryci"><span class="header-section-number">2.5.3</span> Exercise: Reading Conditional Independence from a Graph</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-causal-models.html">I Foundations</a></li><li class="breadcrumb-item"><a href="./02-causal-models.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Causal Models</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-HJC2" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Causal Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-default callout-note callout-titled" title="Chapter summary">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chapter summary
</div>
</div>
<div class="callout-body-container callout-body">
<p>We provide a lay-language primer on the counterfactual model of causality and the logic of causal models. Topics include the representation of causal models with causal graphs and using causal graphs to read off relations of conditional independence among variables in a causal domain.</p>
</div>
</div>
<p><br></p>
<p>Causal claims are everywhere. Causal knowledge is often not just the goal of empirical social science, it is also an <em>input</em> into causal inference.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Causal assumptions are hidden in seemingly descriptive statements: Claims that someone is guilty, or exploited, or powerful, or weak involve beliefs about how things would be if conditions were different. Even when scholars carefully try to avoid causal claim-making, causal verbs—depends, drives, produces, influences—are hard to avoid.</p>
<p>But while causal claims are commonplace, it is not always clear what exactly is meant by a causal relation and how causal knowledge about one thing can be marshaled to justify causal claims about another. For our purposes, the counterfactual view of causality addresses the first question. Causal models address the second. In this chapter, we discuss each in turn. The present chapter is largely conceptual, with ideas worked through with a couple of “toy” running examples. In <a href="03-illustrating-models.html" class="quarto-xref"><span>Chapter 3</span></a>, we then apply and illustrate many of the key concepts from this chapter by translating a few prominent arguments from the field of political science into the language of structural causal models.</p>
<section id="sec-counterfactualmodel" class="level2" data-number="2.1"><h2 data-number="2.1" class="anchored" data-anchor-id="sec-counterfactualmodel">
<span class="header-section-number">2.1</span> The Counterfactual Model</h2>
<p></p>
<p>We begin with what we might think of as a meta-model, the counterfactual model of causation. At its core, a counterfactual understanding of causation captures a simple notion of causation as “difference-making.”<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> In the counterfactual view, to say that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> is to say: <em>had</em> <span class="math inline">\(X\)</span> been different, <span class="math inline">\(Y\)</span> <em>would have been</em> different.</p>
<p>A causal effect, in this view, is the difference between two things (two values of <span class="math inline">\(Y\)</span>) that might have happened. This means that <em>by definition, causal effects are not measurable quantities</em>. They are not differences between two observable outcomes in the world, but, at best, differences between one observable outcome and a second counterfactual outcome. For this reason, causal effects need to be inferred, not measured.</p>
<p>In this view, the antecedent, “had <span class="math inline">\(X\)</span> been different,” imagines a <em>controlled</em> change in <span class="math inline">\(X\)</span>—an intervention that alter <span class="math inline">\(X\)</span>’s value—rather than a naturally arising difference in <span class="math inline">\(X\)</span>. The usual counterfactual claim, then, is not that <span class="math inline">\(Y\)</span> is different from how it might have been had circumstances been such that <span class="math inline">\(X\)</span> were different; it is, rather, that if one could somehow have <em>made</em> <span class="math inline">\(X\)</span> different in a case, then <span class="math inline">\(Y\)</span> would have been different in that case.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>Consider a simple example. Teacher <em>A</em> is extraordinary. Students with teacher <em>A</em> do not study and would perform well whether or not they studied. Students with teacher <em>B</em> perform well if and only if they study. Moreover, students with teacher <em>B</em> do in fact study. And all perform well.</p>
<p>When we say that one of teacher <em>B</em>’s students did well <em>because</em> they studied, we are comparing the outcome that they experienced to the outcome that they would have experienced if (1) they had had teacher <em>B</em>, as they did but (2) counterfactually, had <em>not</em> studied.</p>
<p>Notably, when we define the effect of studying, we are <em>not</em> comparing the realized outcome of the studiers to the outcome of the students who <em>in fact</em> did not study. That is because the students who in fact did not study had teacher <em>A</em>, not <em>B</em>. Moreover, we are not comparing the realized outcome of a student of teacher <em>B</em> to what that same student would have achieved if they had had teacher <em>A</em> (and for that reason, had not studied). The reason again is that this comparison includes the effect of having teacher <em>A</em> and not the effect of studying <em>given</em> they had teacher <em>B</em>.</p>
<p>Here is a second example, drawn from a substantive domain that we will return to many times in this book. In his seminal book on democracy and distribution, Carles Boix argues that low economic inequality is a cause of democratization <span class="citation" data-cites="boix2003democracy">(<a href="20-references.html#ref-boix2003democracy" role="doc-biblioref">Boix 2003</a>)</span>. At high levels of inequality, Boix argues, the elite would rather repress the poor than submit to democracy and its redistributive consequences; at low levels of inequality, in contrast, redistribution under democracy will be less costly for the elite than would continued repression. Now, in light of this theory, consider the claim that Switzerland democratized (<span class="math inline">\(D=1\)</span>) because it had a relatively low level of economic inequality (<span class="math inline">\(I=0\)</span>). In the counterfactual view, this claim is equivalent to saying that, if Switzerland had had a <em>high</em> level of inequality, the country would not have democratized. Low economic inequality made a difference. The comparison for the causal statement is with the outcome Switzerland would have experienced under an intervention that boosted its historic level of economic inequality (but made no other change)—<em>not</em> with how Switzerland would have performed if it had been like one of the countries that <em>in fact</em> had higher levels of inequality, cases that likely differ from Switzerland in other causally relevant ways.</p>
<section id="potential-outcomes" class="level3" data-number="2.1.1"><h3 data-number="2.1.1" class="anchored" data-anchor-id="potential-outcomes">
<span class="header-section-number">2.1.1</span> Potential Outcomes</h3>
<p></p>
<p>Researchers often employ what is called the “potential outcomes” framework when they need precise formal language for describing counterfactual quantities <span class="citation" data-cites="Rubin1974">(<a href="20-references.html#ref-Rubin1974" role="doc-biblioref">Rubin 1974</a>)</span>. In this framework, we characterize how a given unit responds to a causal variable by positing the outcomes that the unit <em>would</em> take on at different values of the causal variable. Most commonly, <span class="math inline">\(Y_i(0)\)</span> and <span class="math inline">\(Y_i(1)\)</span> are used to denote the values that <span class="math inline">\(Y\)</span> <em>would</em> take for unit <span class="math inline">\(i\)</span> if <span class="math inline">\(X\)</span> were 0 and 1, respectively.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> </p>
<p>One setting in which it is quite easy to think about potential outcomes is medical treatment. Imagine that some individuals in a diseased population have received a drug (<span class="math inline">\(X=1\)</span>) while others have not received the drug (<span class="math inline">\(X=0\)</span>). Assume that, subsequently, a researcher observes which individuals become healthy (<span class="math inline">\(Y=1\)</span>) and which do not (<span class="math inline">\(Y=0\)</span>). Given the assignments of all other individuals,<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> we can treat each individual as belonging to one of four unobserved response “types,” defined by the outcomes that the individual <em>would have</em> if they received or did not receive treatment:<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<ul>
<li>
<strong>a</strong>dverse: Those individuals who would get better if and only if they do not receive the treatment</li>
<li>
<strong>b</strong>eneficial: Those who would get better if and only if they do receive the treatment</li>
<li>
<strong>c</strong>hronic: Those who will remain sick whether or not they receive the treatment</li>
<li>
<strong>d</strong>estined: Those who will get better whether or not they receive the treatment.</li>
</ul>
<p><a href="#tbl-PO" class="quarto-xref">Table&nbsp;<span>2.1</span></a> maps the four types (<span class="math inline">\(a, b, c, d\)</span>) onto their respective potential outcomes. In each column, we have simply written down the outcome that a patient of a given type would experience if they are not treated, and the outcome they would experience if they are treated. We are here always imagining <em>controlled</em> changes in treatment: the responses if treatments are changed without changes to other background (or pre-treatment) conditions in the case.</p>
<div id="tbl-PO" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-PO-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.1: Potential outcomes: What would happen to each of four possible types of case if they were or were not treated.
</figcaption><div aria-describedby="tbl-PO-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead><tr class="header">
<th></th>
<th style="text-align: center;">Type <em>a</em>
</th>
<th style="text-align: center;">Type <em>b</em>
</th>
<th style="text-align: center;">Type <em>c</em>
</th>
<th style="text-align: center;">Type <em>d</em>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td style="text-align: center;">
<strong>a</strong>dverse</td>
<td style="text-align: center;">
<strong>b</strong>eneficial</td>
<td style="text-align: center;">
<strong>c</strong>hronic</td>
<td style="text-align: center;">
<strong>d</strong>estined</td>
</tr>
<tr class="even">
<td>Outcome if not treated</td>
<td style="text-align: center;">Healthy</td>
<td style="text-align: center;">Sick</td>
<td style="text-align: center;">Sick</td>
<td style="text-align: center;">Healthy</td>
</tr>
<tr class="odd">
<td>Outcome if treated</td>
<td style="text-align: center;">Sick</td>
<td style="text-align: center;">Healthy</td>
<td style="text-align: center;">Sick</td>
<td style="text-align: center;">Healthy</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>We highlight that, in this framework, case-level causal relations are treated as deterministic. A given case has a set of potential outcomes. Any uncertainty about outcomes enters as incomplete knowledge of a case’s “type,” not from underlying randomness in causal relations. This understanding of causality—as ontologically deterministic, but empirically imperfectly understood—is compatible with views of causation commonly employed by qualitative researchers (see, e.g., <span class="citation" data-cites="mahoney2008toward">Mahoney (<a href="20-references.html#ref-mahoney2008toward" role="doc-biblioref">2008</a>)</span>), and with understandings of causal determinism going back at least to <span class="citation" data-cites="laplace1901philosophical">Laplace (<a href="20-references.html#ref-laplace1901philosophical" role="doc-biblioref">1901</a>)</span>.</p>
<p>As we will also see, we can readily express this kind of incompleteness of knowledge within a causal model framework: Indeed, the way in which causal models manage uncertainty is central to how they allow us to pose questions of interest and to learn from evidence. Certainly, there are situations we could imagine in which one might want to conceptualize potential outcomes themselves as random (for instance, if individuals in different conditions play different lotteries). But for the vast majority of the settings we consider, not much of importance is lost if we treat potential outcomes as deterministic but possibly unknown: Every case <em>is</em> of a particular type; we just do not know which type that is.</p>
</section><section id="sec-generalize" class="level3" data-number="2.1.2"><h3 data-number="2.1.2" class="anchored" data-anchor-id="sec-generalize">
<span class="header-section-number">2.1.2</span> A Generalization</h3>
<p>Throughout the book, we generalize from this simple setup. Whenever we have one causal variable and one outcome, and both variables are binary (i.e., each can take on two possible values, 0 or 1), there are only four sets of possible potential outcomes, or “types.” More generally, for variable <span class="math inline">\(Y\)</span>, we will use <span class="math inline">\(\theta^Y\)</span> to capture the unit’s “type”: the way that <span class="math inline">\(Y\)</span> responds to its potential causes.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> We, further, add subscripts to denote particular types. Where there are four possible types, for instance, we use the notation <span class="math inline">\(\theta^Y_{ij}\)</span>, where the first subscript, <span class="math inline">\(i\)</span>, represents the case’s potential outcome when <span class="math inline">\(X=0\)</span>; and the second subscript, <span class="math inline">\(j\)</span>, is the case’s potential outcome when <span class="math inline">\(X=1\)</span>.</p>
<p>Adopting this notation, for a causal structure with one binary causal variable and a binary outcome, the four types can be represented as <span class="math inline">\(\{\theta^Y_{10}, \theta^Y_{01}, \theta^Y_{00}, \theta^Y_{11}\}\)</span>, as shown in <a href="#tbl-POGEN" class="quarto-xref">Table&nbsp;<span>2.2</span></a>:</p>
<div id="tbl-POGEN" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-POGEN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.2: Mapping types to potential outcomes: the values <span class="math inline">\(Y\)</span> takes on if <span class="math inline">\(X\)</span> were set at <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>.
</figcaption><div aria-describedby="tbl-POGEN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead><tr class="header">
<th></th>
<th style="text-align: center;">
<em>a</em>: <span class="math inline">\(\theta^Y=\theta^Y_{10}\)</span>
</th>
<th style="text-align: center;">
<em>b</em>: <span class="math inline">\(\theta^Y=\theta^Y_{01}\)</span>
</th>
<th style="text-align: center;">
<em>c</em>: <span class="math inline">\(\theta^Y=\theta^Y_{00}\)</span>
</th>
<th style="text-align: center;">
<em>d</em> : <span class="math inline">\(\theta^Y=\theta^Y_{11}\)</span>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Set <span class="math inline">\(X=0\)</span>
</td>
<td style="text-align: center;"><span class="math inline">\(Y(0)=1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Y(0)=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Y(0)=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Y(0)=1\)</span></td>
</tr>
<tr class="even">
<td>Set <span class="math inline">\(X=1\)</span>
</td>
<td style="text-align: center;"><span class="math inline">\(Y(1)=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Y(1)=1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Y(1)=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(Y(1)=1\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Returning to the matter of inequality and democratization to illustrate, let <span class="math inline">\(I=1\)</span> represent a high level of economic inequality and <span class="math inline">\(I=0\)</span> its absence; let <span class="math inline">\(D=1\)</span> represent democratization and <span class="math inline">\(D=0\)</span> its absence. <span class="math inline">\(\theta^D_{10}\)</span> (or <span class="math inline">\(a\)</span>) type is a case in which a high level of inequality, if it occurs, <em>prevents</em> democratization in a country that would otherwise have democratized. So the causal effect of high inequality in a case, <span class="math inline">\(i\)</span>, of <span class="math inline">\(\theta^D_{10}\)</span> type is <span class="math inline">\(\tau_i= -1\)</span>. A <span class="math inline">\(\theta^D_{01}\)</span> type (or <span class="math inline">\(b\)</span> type) is a case in which high inequality, if it occurs, generates democratization in a country that would otherwise have remained non-democratic (effect of <span class="math inline">\(\tau_i= 1\)</span>). A <span class="math inline">\(\theta^D_{00}\)</span> type (<span class="math inline">\(c\)</span> type) is a case that will not democratize regardless of the level of inequality (effect of <span class="math inline">\(\tau_i = 0\)</span>); and a <span class="math inline">\(\theta^D_{11}\)</span> type (<span class="math inline">\(d\)</span> type) is one that will democratize regardless of the level of inequality (again, effect of <span class="math inline">\(\tau_i= 0\)</span>).</p>
<p>In this setting, a causal <em>explanation</em> of a given case outcome amounts to a statement about its type. The claim that Switzerland’s low level of inequality was a cause of its democratization is equivalent to saying that Switzerland democratized and is a <span class="math inline">\(\theta^D_{10}\)</span> type. To claim that Benin democratized because of high inequality is equivalent to saying that Benin democratized and is a <span class="math inline">\(\theta^D_{01}\)</span> type. To claim, on the other hand, that Malawi democratized for reasons having nothing to do with its level of economic inequality is to characterize Malawi as a <span class="math inline">\(\theta^D_{11}\)</span> type (which implies that Malawi would have been democratic no matter what its level of inequality).</p>
<p>Now, let us consider more complex causal relations. Suppose there are two binary causal variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. We can specify any given case’s potential outcomes for each of the different possible combinations of their causal conditions. There are now four such conditions since each causal variable may take on <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> when the other is at <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>.</p>
<p>As for notation, we now need to expand <span class="math inline">\(\theta\)</span>’s subscript since we need to represent the value that <span class="math inline">\(Y\)</span> takes on under each of the four possible combinations of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> values. This requires four, rather than two, subscript digits. We map the subscripting for <span class="math inline">\(\theta_{hijk}\)</span> to potential outcome notation as shown in Equation <a href="#eq-posch2" class="quarto-xref">Equation&nbsp;<span>2.1</span></a>.</p>
<p><span id="eq-posch2"><span class="math display">\[
\theta^Y_{hijk} =
\left\{
\begin{array}{lll}
Y(0,0) &amp;=&amp; h,  \\
Y(1,0) &amp;=&amp; i,  \\
Y(0,1) &amp;=&amp; j,  \\
Y(1,1) &amp;=&amp; k
\end{array}
\right.
\tag{2.1}\]</span></span></p>
<p>where the first argument of <span class="math inline">\(Y(.,.)\)</span> is the value to which <span class="math inline">\(X_1\)</span> is set and the second is the value to which <span class="math inline">\(X_2\)</span> is set.</p>
<p>Thus, for instance, <span class="math inline">\(\theta^Y_{0100}\)</span> means that <span class="math inline">\(Y\)</span> is 1 if <span class="math inline">\(X_1\)</span> is set to 1 and <span class="math inline">\(X_2\)</span> to 0 and is 0 otherwise; <span class="math inline">\(\theta^Y_{0011}\)</span> is a type in which <span class="math inline">\(Y=1\)</span> if and only if <span class="math inline">\(X_2=1\)</span>; <span class="math inline">\(\theta^Y_{0001}\)</span> is a type for which <span class="math inline">\(Y=0\)</span> unless both <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are 1.</p>
<p>We now have 16 causal types for this node: 16 different patterns that <span class="math inline">\(Y\)</span> might display in response to changes in <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. The full set is represented in <a href="#tbl-HJ-T-2-3" class="quarto-xref">Table&nbsp;<span>2.3</span></a>, which also illustrates how we read types off of four-digit subscripts. For instance, the table shows us that for nodal type <span class="math inline">\(\theta^Y_{0101}\)</span>, <span class="math inline">\(X_1\)</span> has a positive causal effect on <span class="math inline">\(Y\)</span> but <span class="math inline">\(X_2\)</span> has no effect. On the other hand, for type <span class="math inline">\(\theta^Y_{0011}\)</span>, <span class="math inline">\(X_2\)</span> has a positive effect while <span class="math inline">\(X_1\)</span> has none.</p>
<p>The 16 types also capture interactions. For instance, for a <span class="math inline">\(\theta^Y_{0001}\)</span> type, <span class="math inline">\(X_2\)</span> has a positive causal effect if and only if <span class="math inline">\(X_1\)</span> is 1. For that type, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> serve as “complements.” For <span class="math inline">\(\theta^Y_{0111}\)</span>, <span class="math inline">\(X_2\)</span> has a positive causal effect if and only if <span class="math inline">\(X_1\)</span> is 0. For that type, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are “substitutes.”</p>
<div class="cell" data-layout-align="center">
<div id="tbl-HJ-T-2-3" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-HJ-T-2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.3: Two binary causes yield 16 causal types.
</figcaption><div aria-describedby="tbl-HJ-T-2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(\theta^Y\)</span></th>
<th style="text-align: center;">if <span class="math inline">\(X_1=0, X_2=0\)</span>
</th>
<th style="text-align: center;">if <span class="math inline">\(X_1=1,X_2=0\)</span>
</th>
<th style="text-align: center;">if <span class="math inline">\(X_1=0,X_2=1\)</span>
</th>
<th style="text-align: center;">if <span class="math inline">\(X_1=1, X_2=1\)</span>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0000}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1000}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0100}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1100}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0010}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1010}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0110}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1110}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0001}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1001}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0101}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1101}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0011}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1011}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{0111}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\theta^Y_{1111}\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>This is a rich framework in that it allows for all the possible ways in which a set of multiple causes can interact with each other. Often, when seeking to explain the outcome in a case, researchers proceed as though causes are necessarily <em>rival</em>, where <span class="math inline">\(X_1\)</span> being a cause of <span class="math inline">\(Y\)</span> implies that <span class="math inline">\(X_2\)</span> was not. Did Malawi democratize because it was a relatively economically equal society <em>or</em> because of international pressure to do so? In the counterfactual model, however, causal relations can be nonrival. If two out of three people vote for an outcome under majority rule, for example, then both of the two supporters caused the outcome: The outcome would not have occurred if <em>either</em> supporter’s vote were different. A typological, potential-outcomes conceptualization provides a straightforward way of representing this kind of complex causation.</p>
<p>Because of this complexity, when we say that <span class="math inline">\(X\)</span> caused <span class="math inline">\(Y\)</span> in a given case, we will generally mean that <span class="math inline">\(X\)</span> was <em>a</em> cause, not <em>the</em> (only) cause. Malawi might not have democratized if <em>either</em> a relatively high level of economic equality <em>or</em> international pressure had been absent. For most social phenomena that we study, there will be multiple, and sometimes a great many, difference-makers for any given case outcome.</p>
<p>We will mostly use <span class="math inline">\(\theta^Y_{ij}\)</span>-style notation in this book to refer to types. We will, however, occasionally revert to the simpler <span class="math inline">\(a, b, c, d\)</span> designations when that eases exposition. As types play a central role in the causal-model framework, we recommend getting comfortable with both forms of notation before going further.</p>
<p>Using the same framework, we can generalize to structures in which a unit has any number of causes and also to cases in which causes and outcomes are nonbinary. As one might imagine, the number of types increases rapidly (very rapidly) as the number of considered causal variables increases; it also increases rapidly if we allow <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> to take on more than two possible values. For example, if there are <span class="math inline">\(n\)</span> binary causes of an outcome, then there can be <span class="math inline">\(2^{\left(2^n\right)}\)</span> types of this form: that is, <span class="math inline">\(k=2^n\)</span> combinations of values of causes to consider, and <span class="math inline">\(2^k\)</span> distinct response patterns across the possible combinations. If causes and outcomes are ternary instead of binary, we have <span class="math inline">\(3^{\left(3^n\right)}\)</span> causal types.</p>
<p>Nevertheless, the basic principle of representing possible causal relations as patterns of potential outcomes remains unchanged, at least as long as variables are discrete.</p>
</section><section id="summaries-of-potential-outcomes" class="level3" data-number="2.1.3"><h3 data-number="2.1.3" class="anchored" data-anchor-id="summaries-of-potential-outcomes">
<span class="header-section-number">2.1.3</span> Summaries of Potential Outcomes</h3>
<p></p>
<p>So far, we have focused on causal relations at the level of an individual case. Causal relations at the level of a population are, however, simply a summary of causal relations for cases, and the same basic ideas can be used. We could, for instance, summarize our beliefs about the relationship between economic inequality and democratization by saying that we think that the world is comprised of a mixture of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span> types, as defined above. We could get more specific and express a belief about what proportions of cases in the world are of each of the four types. For instance, we might believe that <span class="math inline">\(a\)</span> types and <span class="math inline">\(d\)</span> types are quite rare while <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> types are quite common.</p>
<p>Moreover, our belief about the proportions of <span class="math inline">\(b\)</span> (positive effect) and <span class="math inline">\(a\)</span> (negative effect) cases imply a belief about inequality’s <em>average</em> effect on democratization as, in a binary setup, this quantity is simply the proportion of <span class="math inline">\(b\)</span> types minus the proportion of <span class="math inline">\(a\)</span> types. Such summaries allow us to move from the discussion of the cause of a single outcome to discussions of average effects, a distinction that we take up again in <a href="04-causal-questions.html" class="quarto-xref"><span>Chapter 4</span></a>.</p>
</section></section><section id="causal-models-and-directed-acyclic-graphs" class="level2" data-number="2.2"><h2 data-number="2.2" class="anchored" data-anchor-id="causal-models-and-directed-acyclic-graphs">
<span class="header-section-number">2.2</span> Causal Models and Directed Acyclic Graphs</h2>
<p></p>
<p>So far we have discussed how a single outcome is affected by one or more possible causes. However, these same ideas can be used to describe more complex relations between collections of variables—for example, with one variable affecting another directly as well as indirectly via its impact on a third variable. For instance, <span class="math inline">\(X\)</span> might affect <span class="math inline">\(Y\)</span> directly. But <span class="math inline">\(X\)</span> might also affect <span class="math inline">\(Y\)</span> by affecting <span class="math inline">\(M\)</span>, which in turn affects <span class="math inline">\(Y\)</span>. In the latter scenario, <span class="math inline">\(M\)</span> is a mediator of <span class="math inline">\(X\)</span>’s effect on <span class="math inline">\(Y\)</span>.</p>
<p>Potential outcomes tables can be used to describe such relations. However, as causal structures become more complex—especially, as the number of variables in a domain increases—a causal model can be a powerful organizing tool. In this section, we show how causal models and their visual counterparts, directed acyclic graphs (DAGs), can represent substantive beliefs about counterfactual causal relationships in the world. The key ideas in this section can be found in many texts (see, e.g., <span class="citation" data-cites="halpern2005causesa">Halpern and Pearl (<a href="20-references.html#ref-halpern2005causesa" role="doc-biblioref">2005</a>)</span> and <span class="citation" data-cites="galles1998axiomatic">Galles and Pearl (<a href="20-references.html#ref-galles1998axiomatic" role="doc-biblioref">1998</a>)</span>), and we introduce here a set of basic principles that readers will need to keep in mind in order to follow the argumentation in this book.</p>
<p>As we shift to talking about networks of causal relations between variables, we will also shift our language. When talking about causal networks, or causal graphs, we will generally refer to variables as “nodes.” And we will sometimes use familial terms to describe relations between nodes. For instance, if <span class="math inline">\(A\)</span> is a cause of <span class="math inline">\(B\)</span>, we will refer to <span class="math inline">\(A\)</span> as a “parent” of <span class="math inline">\(B\)</span>, and <span class="math inline">\(B\)</span> as a “child” of <span class="math inline">\(A\)</span>. Graphically, we have an arrow pointing from the parent to the child. If two variables have a child in common (both directly affecting the same variable), we refer to them as “spouses.” We can also say that a variable is a “causal ancestor” of another variable (its “causal descendant”) if there is a chain of parent-child relations from the “ancestor” to the “descendant.”</p>
<p>Returning to our running democratization example, suppose now that we have more fully specified beliefs about how the level of economic inequality can have an effect on whether a country democratizes. We might believe that inequality (<span class="math inline">\(I\)</span>) affects the likelihood of democratization (<span class="math inline">\(D\)</span>) by generating demands for redistribution (<span class="math inline">\(R\)</span>), which in turn can cause the mobilization (<span class="math inline">\(M\)</span>) of lower-income citizens, which in turn can cause democratization (<span class="math inline">\(D\)</span>). We might also believe that mobilization itself is not just a function of redistributive preferences but also of the degree of ethnic homogeneity (<span class="math inline">\(E\)</span>), which shapes the capacities of lower-income citizens for collective action. We visualize this model as a DAG in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>. In this model, <span class="math inline">\(R\)</span> is a parent of <span class="math inline">\(M\)</span>. <span class="math inline">\(I\)</span> is an ancestor of <span class="math inline">\(M\)</span> but not its parent. <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span> are spouses, and <span class="math inline">\(M\)</span> is their child (i.e., mobilization depends on both redistributive preferences and ethnic demography).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-2-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-causal-models_files/figure-html/fig-HJ-F-2-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-2-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: A simple causal model in which high inequality (<span class="math inline">\(I\)</span>) affects democratization (<span class="math inline">\(D\)</span>) via redistributive demands (<span class="math inline">\(R\)</span>) and mass mobilization (<span class="math inline">\(M\)</span>) which is also a function of ethnic homogeneity (<span class="math inline">\(E\)</span>). Arrows show relations of causal dependence between variables.
</figcaption></figure>
</div>
</div>
</div>
<p>Fundamentally, we treat causal models like this as formal representations of <em>beliefs</em> about how the world works—or, more specifically, about causal relations within a given domain. We might use a causal model to capture our own beliefs, a working simplification of our beliefs, or a set of potential beliefs that one might hold. The formalization of <em>prior</em> beliefs in the form of a causal model is the starting point for research design and inference in this book’s analytic framework.</p>
<p>We now provide a formal definition of a causal model (<a href="#def-cm" class="quarto-xref">Definition&nbsp;<span>2.1</span></a>) as used in this book, and then unpack the definition.</p>
<div id="def-cm" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 2.1</strong></span> <strong>Causal Model</strong></p>
<p></p>
<p>A “<strong>causal model</strong>” is:</p>
<p>1.1: An ordered list of <span class="math inline">\(n\)</span> endogenous nodes, <span class="math inline">\(\mathcal{V}= (V^1, V^2,\dots, V^n)\)</span>, with a specification of a range for each of them</p>
<p>1.2: A list of <span class="math inline">\(n\)</span> exogenous nodes, <span class="math inline">\(\Theta = (\theta^1, \theta^2,\dots , \theta^n)\)</span></p>
<p>2: A list of <span class="math inline">\(n\)</span> functions <span class="math inline">\(\mathcal{F}= (f^1, f^2,\dots, f^n)\)</span>, one for each element of <span class="math inline">\(\mathcal{V}\)</span> such that each <span class="math inline">\(f^i\)</span> takes as arguments <span class="math inline">\(\theta^i\)</span> as well as elements of <span class="math inline">\(\mathcal{V}\)</span> that are <em>prior</em> to <span class="math inline">\(V^i\)</span> in the ordering</p>
<p>and</p>
<p>3: A probability distribution over <span class="math inline">\(\Theta\)</span></p>
</div>
<p>This definition corresponds to Pearl’s definition of a “probabilistic causal model” (<span class="citation" data-cites="pearl2009causality">Pearl (<a href="20-references.html#ref-pearl2009causality" role="doc-biblioref">2009</a>)</span>, Definition 7.1.6). Also following Pearl, we use the term “structural causal model” to refer to a model that specifies parts 1.1, 1.2, and 2 of this definition but without part 3 (See e.g., <span class="citation" data-cites="pearl2009causality">Pearl (<a href="20-references.html#ref-pearl2009causality" role="doc-biblioref">2009</a>)</span> Definition 7.1.1).<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> </p>
<p>The three components of a causal model then are (1) the nodes—that is, the set of variables we are focused on and how they are defined (2) the causal functions—which characterize which nodes are caused by which other nodes and how, and (3) probability distributions over unexplained elements of a model (in our framework, the <span class="math inline">\(\theta\)</span> nodes). We discuss each in turn.</p>
<section id="the-nodes" class="level3" data-number="2.2.1"><h3 data-number="2.2.1" class="anchored" data-anchor-id="the-nodes">
<span class="header-section-number">2.2.1</span> The Nodes</h3>
<p> </p>
<p>The first component of a causal model is the set of variables (nodes) across which the model characterizes causal relations.</p>
<p>We have two sorts of variables: the named, “endogenous,” nodes, <span class="math inline">\(\mathcal{V}\)</span>, and the unnamed “exogenous” nodes, <span class="math inline">\(\Theta\)</span>.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>On the graph (DAG) in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, the five endogenous nodes are lettered. All these endogenous nodes have an arrow pointing into them indicating that the node at the end of the arrow is (possibly) caused in part by (or, “depends on”) the node at the beginning of the arrow.</p>
<p>Nodes <span class="math inline">\(R\)</span>, <span class="math inline">\(M\)</span>, and <span class="math inline">\(D\)</span> are all obviously endogenous because they depend on other named variables. <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> are not endogenous to other nodes in <span class="math inline">\(\mathcal{V}\)</span>, but we still call them endogenous because they depend on other nodes in the model, specifically on nodes in <span class="math inline">\(\Theta\)</span>. We will use the term “root nodes” to indicate nodes like this that are in <span class="math inline">\(\mathcal{V}\)</span> but are not endogenous to other nodes in <span class="math inline">\(\mathcal{V}\)</span>.</p>
<p>Our definition specified that the endogenous nodes should be <em>ordered</em>. We can in fact specify different orderings of nodes in this example. For instance we could have the ordering <span class="math inline">\(&lt;E, I, R, M, D&gt;\)</span>, or the ordering <span class="math inline">\(&lt;I, R, E, M, D&gt;\)</span> or even <span class="math inline">\(&lt;I, E, R, M, D&gt;\)</span>. The ordering <em>matters</em> only to the extent that it constrains the causal functions: <span class="math inline">\(f^j\)</span> can take as arguments only <span class="math inline">\(\theta^j\)</span> and elements of <span class="math inline">\(\mathcal{V}\)</span> that come before <span class="math inline">\(j\)</span> in the ordering. In practice, this prevents us from having a variable that is both a cause and a consequence of another variable.</p>
<p>In specifying these nodes, we also need to specify the ranges over which they can vary. We might specify, for instance, that all the endogenous nodes in the model are binary, taking on the values 0 or 1. We could, alternatively, define a set of categories across which a node ranges or allow a node to take on any real number value or any value between a set of bounds.</p>
<p>The exogenous nodes, <span class="math inline">\(\Theta\)</span>, require a little more explanation since they do not describe substantive nodes. Five such exogenous nodes are shown on the graph, one for each endogenous node (note though, very frequently we do not include the exogenous nodes explicitly when we draw a graph, but we should still imagine them there, pointing into each endogenous node).</p>
<p>In our discussion above, we introduced <span class="math inline">\(\theta\)</span> notation for representing types. Here, we simply build these types into a causal model. We imagine a <span class="math inline">\(\theta\)</span> term pointing into every node (whether explicitly represented on the graph or not). We can think of <span class="math inline">\(\theta\)</span> terms as unobservable and unspecified inputs into a causal system. These might include random processes (noise) or contextual features that we are unable to identify or do not understand, but that both affect outcomes and condition the effects of other, specified variables on outcomes.</p>
<p>As we will show, consistent with our discussion of potential outcomes and types, in discrete settings <em>we can think of</em> <span class="math inline">\(\theta\)</span> nodes as capturing the functional relations between variables and as such as, being quantities of direct interest for causal inquiry. We more fully develop this point—returning to the notion of <span class="math inline">\(\theta\)</span> terms as receptacles for causal effects—below.</p>
</section><section id="the-functions" class="level3" data-number="2.2.2"><h3 data-number="2.2.2" class="anchored" data-anchor-id="the-functions">
<span class="header-section-number">2.2.2</span> The Functions</h3>
<p>Next, we need to specify our beliefs about the causal relations among the nodes in our model. How is the value of one node affected by, and how does it affect, the values of others? For each endogenous node—each node influenced by others in the model—we need to express beliefs about how its value is affected by its parents (its immediate causes). We do this using a function <span class="math inline">\(f^i\)</span> for each node <span class="math inline">\(i\)</span>. We will usually refer to these functions as “causal functions” to highlight the fact that they capture causal relations between nodes.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> Critically, these functions contain all the information needed to construct potential outcomes (see <a href="#rem-lempo" class="quarto-xref">Remark&nbsp;<span>2.1</span></a> on these connections).</p>
<p>We can think in a qualitative and quantitative way about how one variable is affected by others. Qualitatively, if a variable <span class="math inline">\(i\)</span> depends on the value of another variable <span class="math inline">\(j\)</span> (given other variables prior to <span class="math inline">\(i\)</span> in the ordering), then that variable <span class="math inline">\(j\)</span> enters as an argument in <span class="math inline">\(f^i\)</span>. In that case, <span class="math inline">\(j\)</span> is a parent to <span class="math inline">\(i\)</span>. Whether a variable is a parent or not depends on the nodes in the model: if we think <span class="math inline">\(A\)</span> causes <span class="math inline">\(B\)</span> and <span class="math inline">\(B\)</span> causes <span class="math inline">\(C\)</span> and <span class="math inline">\(A\)</span> causes <span class="math inline">\(C\)</span> only via <span class="math inline">\(B\)</span> then <span class="math inline">\(A\)</span> is not a parent of <span class="math inline">\(C\)</span> in a model that includes <span class="math inline">\(B\)</span> among the endogenous nodes; but <span class="math inline">\(A\)</span> would be a parent of <span class="math inline">\(C\)</span> in a model that does not include <span class="math inline">\(B\)</span>.</p>
<p>Graphically, we can represent all such relations between variables and their parents with arrows and when we represent the relations in a causal model in this way we get a DAG—where the acyclicality and directedness are guaranteed by the ordering requirements we impose when we define a causal model.</p>
<p>Thus, the DAG already represents a critical part of our model: The arrows, or directed edges, tell us <em>which nodes we believe may be direct causal inputs into other nodes</em>. So, for instance, we believe that democratization (<span class="math inline">\(D\)</span>) is determined jointly by mobilization (<span class="math inline">\(M\)</span>) and some exogenous, unspecified factor (or set of factors), <span class="math inline">\(\theta^D\)</span>. As we have said, we can think of <span class="math inline">\(\theta^D\)</span> as all of the other influences on democratization, besides mobilization, that we either do not know of or have decided not to explicitly include in the model. We believe, likewise, that <span class="math inline">\(M\)</span> is determined by <span class="math inline">\(I\)</span> and an unspecified exogenous factor (or set of factors), <span class="math inline">\(\theta^M\)</span>. And we are conceptualizing inequality (<span class="math inline">\(I\)</span>) and ethnic heterogeneity (<span class="math inline">\(E\)</span>) as shaped solely by factors exogenous to the model, captured by <span class="math inline">\(\theta^I\)</span> and <span class="math inline">\(\theta^E\)</span>, respectively.</p>
<p>Beyond the qualitative beliefs captured by the arrows in a DAG, we can express more specific <em>quantitative</em> beliefs about causal relations in the form of a causal function. A function specifies how the value that one node takes is determined by the values that other nodes—its parents—take on. Specifying a function means writing down whatever general or theoretical knowledge we have about the direct causal relations between nodes.</p>
<p>We can specify this relationship in a vast variety of ways. It is useful, however, to distinguish broadly between parametric and nonparametric approaches. We take a nonparametric approach in this book—this is where our types come back in—but it is helpful to juxtapose that approach with a parametric approach to causal functions.</p>
<section id="parametric-approaches" class="level4" data-number="2.2.2.1"><h4 data-number="2.2.2.1" class="anchored" data-anchor-id="parametric-approaches">
<span class="header-section-number">2.2.2.1</span> Parametric Approaches</h4>
<p>A parametric approach specifies a functional form that relates parents to children. For instance, we might model one node as a linear function of another and write <span class="math inline">\(D=\alpha + \beta M\)</span>. Here, <span class="math inline">\(\beta\)</span> is a parameter that we may not know the value of at the outset of a study but about which we wish to learn. If we believe <span class="math inline">\(D\)</span> to be linearly affected by <span class="math inline">\(M\)</span> but also subject to forces that we do not yet understand and have not yet specified in our theory, then we might write: <span class="math inline">\(D=f^D(M, \theta^D) = \alpha + \beta M+\theta^D\)</span>. (This functional form may be familiar from its use in linear regressions.) In this function, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> might be the parameters of interest—features of the world that we seek to learn about—with <span class="math inline">\(\theta^D\)</span> treated as merely a random disturbance around the linear relationship.</p>
<p> We can also write down functions in which the relations between nodes are left wholly or partially unspecified, for instance, governed by parameters with unknown values. Consider, for instance the function <span class="math inline">\(D=\beta M^{\theta^D}\)</span>. Here, <span class="math inline">\(D\)</span> and <span class="math inline">\(M\)</span> are linearly related if <span class="math inline">\(\theta^D=1\)</span>. (If <span class="math inline">\(\theta^D=1\)</span>, then the function just reduces to the linear form, <span class="math inline">\(D=\beta M\)</span>.) However, if <span class="math inline">\(\theta^D\)</span> is not equal to <span class="math inline">\(1\)</span>, then <span class="math inline">\(M\)</span>’s effect on <span class="math inline">\(D\)</span> can be non-linear. For instance, if <span class="math inline">\(\theta^D\)</span> lies between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, then <span class="math inline">\(M\)</span> will have a diminishing marginal effect on <span class="math inline">\(D\)</span>. Here, <span class="math inline">\(\theta^D\)</span> itself would likely be a quantity of interest to the researcher since it conditions the causal relationship between the other two nodes.</p>
<p>The larger point is that functions can be written to be quite specific or extremely general, depending on the state of prior knowledge about the phenomenon under investigation. The use of a structural model does not require precise knowledge of specific causal relations, even of the functional forms through which two nodes are related.</p>
</section><section id="the-non-parametric-approach" class="level4" data-number="2.2.2.2"><h4 data-number="2.2.2.2" class="anchored" data-anchor-id="the-non-parametric-approach">
<span class="header-section-number">2.2.2.2</span> The Non-parametric Approach</h4>
<p></p>
<p>With discrete (non-continuous) data, causal functions can take fully <em>nonparametric</em> form. That is, nonparametric functions can allow for <em>any possible relation</em> between parents and children, not just those that can be expressed in an equation.</p>
<p>We use a nonparametric framework for most of this book and thus spend some time developing the approach here.</p>
<p>We begin by returning to the concept of types. Drawing on our original four types and the democratization example from earlier in this chapter, we know that we can fully specify causal relations between a binary <span class="math inline">\(M\)</span> and a binary <span class="math inline">\(D\)</span> using the concept of a type, represented by <span class="math inline">\(\theta^D\)</span>. We think of <span class="math inline">\(\theta^D\)</span> as akin to a variable that can take on different <em>values</em> in different cases, corresponding to the different possible types. Specifically, we allow <span class="math inline">\(\theta^D\)</span> to range across the four possible values (or types) <span class="math inline">\(\{\theta^D_{10}, \theta^D_{01}, \theta^D_{00}, \theta^D_{11}\}\)</span>. For instance, <span class="math inline">\(\theta^D_{10}\)</span> represents a negative causal effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(D\)</span> while <span class="math inline">\(\theta^D_{00}\)</span> represents <span class="math inline">\(D\)</span> remaining at 0 regardless of <span class="math inline">\(M\)</span>.</p>
<p>So the value that <span class="math inline">\(\theta^D\)</span> takes on in a case governs the causal relationship between <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span>. Put differently, <span class="math inline">\(\theta^D\)</span> represents <em>the nonparametric function that relates</em> <span class="math inline">\(M\)</span> to <span class="math inline">\(D\)</span>. We can formally specify <span class="math inline">\(D\)</span>’s behavior as a function of <span class="math inline">\(M\)</span> and <span class="math inline">\(\theta^D\)</span> in the following way:</p>
<p><span class="math display">\[f^D(M, \theta^D_{ij}) = \left\{\begin{array}{ccc} i &amp; \text{if} &amp; M=0 \\ j &amp; \text{if} &amp; M=1 \end{array}\right.\]</span></p>
<p>Here, we are saying that <span class="math inline">\(D\)</span>’s value in a case depends on two things: the value of <span class="math inline">\(M\)</span> and the case’s type, defining how <span class="math inline">\(D\)</span> responds to <span class="math inline">\(M\)</span>. We are then saying, more specifically, how <span class="math inline">\(D\)</span>’s value is given by the subscripts on <span class="math inline">\(\theta\)</span> once we know <span class="math inline">\(M\)</span>’s value: if <span class="math inline">\(M=0\)</span>, then <span class="math inline">\(D\)</span> is equal to the subscript <span class="math inline">\(i\)</span>; If <span class="math inline">\(M=1\)</span>, then <span class="math inline">\(D\)</span> is equal to <span class="math inline">\(j\)</span>. Note that <span class="math inline">\(\theta^D\)</span>’s possible values range over <em>all possible</em> ways in which D’s value can relate to M’s.</p>
<p>How should we think about what kind of <em>thing</em> <span class="math inline">\(\theta^D\)</span> is, in a more substantive sense? It is helpful to think of <span class="math inline">\(\theta^D\)</span> as an unknown and possibly random factor that conditions the effect of mobilization on democratization, determining whether <span class="math inline">\(M\)</span> has a negative effect, a positive effect, no effect with democratization never occurring, or no effect with democratization bound to occur regardless of mobilization. A little more generally it can be thought of as describing a “stratum”—a grouping together of units that may differ in innumerable ways but that, nevertheless, respond in the same way at the node in question given values of other nodes in the model <span class="citation" data-cites="frangakis2002principal">(<a href="20-references.html#ref-frangakis2002principal" role="doc-biblioref">Frangakis and Rubin 2002</a>)</span>. Importantly, while we might think of <span class="math inline">\(\theta^D\)</span> as an unknown or random quantity, in this framework <span class="math inline">\(\theta^D\)</span> should not be thought of as a nuisance—as “noise” that we would like to get rid of. Rather, under this nonparametric approach, <span class="math inline">\(\theta\)</span> terms are <em>the very quantities that we want to learn about</em>: We want to know whether <span class="math inline">\(M\)</span> likely had a positive, negative, or no effect on <span class="math inline">\(D\)</span>. We elaborate on this point in <a href="04-causal-questions.html" class="quarto-xref"><span>Chapter 4</span></a>.</p>
<p>More generally, we can use <span class="math inline">\(\theta\)</span> terms to capture causal functions involving any number of parent nodes. Every substantively defined node, <span class="math inline">\(J\)</span>, in a graph can be thought of as having a <span class="math inline">\(\theta^J\)</span> term pointing into it, and the (unobservable) value of <span class="math inline">\(\theta^J\)</span> provides the mapping from <span class="math inline">\(J\)</span>’s parents (if it has any) to the value of <span class="math inline">\(J\)</span>.</p>
<p>The ranges of each <span class="math inline">\(\theta^J\)</span> node depend on the number of parents <span class="math inline">\(J\)</span> has, as well as the ranges of <span class="math inline">\(J\)</span> and its parents. Thus, as described in <a href="#sec-generalize" class="quarto-xref"><span>Section 2.1.2</span></a>, binary nodes with <span class="math inline">\(n\)</span> parents can take on <span class="math inline">\(2^{2^n}\)</span> values. Each value corresponds to a unique combination of 0s and 1s for each of the <span class="math inline">\(2^n\)</span> combinations of values that the nodes’ parents can have.</p>
<p>Applied to the binary nodes in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, <span class="math inline">\(\theta^J\)</span> ranges as follows: </p>
<ul>
<li>
<strong>Nodes with no parents</strong>: For a parentless node, like <span class="math inline">\(I\)</span> or <span class="math inline">\(E\)</span>, <span class="math inline">\(\theta^J\)</span> represents an external “assignment” process that can take on one of two values. If <span class="math inline">\(\theta^J=\theta^J_{0}\)</span>, we simply mean that <span class="math inline">\(J\)</span> has been “assigned” to <span class="math inline">\(0\)</span>, while a value of <span class="math inline">\(\theta^J_{1}\)</span> means that <span class="math inline">\(J\)</span> has been assigned to 1. For instance, <span class="math inline">\(\theta^I_{0}\)</span> describes a case in which exogenous forces have generated low inequality.</li>
<li>
<strong>Binary nodes with one binary parent</strong>: For endogenous node <span class="math inline">\(R\)</span>, with only one parent (<span class="math inline">\(I\)</span>), <span class="math inline">\(\theta^R\)</span> takes on one of the four values of the form <span class="math inline">\(\theta^R_{ij}\)</span> (our four original types, <span class="math inline">\(\theta^R_{10}\)</span>, <span class="math inline">\(\theta^R_{01}\)</span>, etc.).</li>
<li>
<strong>Binary nodes with two binary parents</strong>: <span class="math inline">\(M\)</span> has two parent nodes. Thus, <span class="math inline">\(\theta^M\)</span> will take on a possible 16 values of the form <span class="math inline">\(\theta^M_{hijk}\)</span> (e.g., <span class="math inline">\(\theta^M_{0000}\)</span>, <span class="math inline">\(\theta^M_{0001}\)</span>, etc.), using the syntax detailed earlier in this chapter and unpacked in <a href="#tbl-HJ-T-2-3" class="quarto-xref">Table&nbsp;<span>2.3</span></a>.</li>
</ul>
<p> </p>
<p><strong>Nodal types and causal types.</strong> So far, we have been talking about types operating at specific nodes. For instance, we can think of the unit of Malawi as having a <span class="math inline">\(\theta^D\)</span> value—the type governing how <span class="math inline">\(D\)</span> responds to <span class="math inline">\(M\)</span> in this case. Let’s call this Malawi’s <em>nodal</em> causal type, or simply nodal type, for <span class="math inline">\(D\)</span>. But we can also conceptualize the full collection of Malawi’s nodal types: the nodal types governing causal effects in Malawi for all nodes in the model. This collection would include Malawi’s nodal type values for <span class="math inline">\(\theta^I\)</span>, <span class="math inline">\(\theta^E\)</span>, <span class="math inline">\(\theta^R\)</span>, <span class="math inline">\(\theta^M\)</span>, and <span class="math inline">\(\theta^D\)</span>. We refer to the collection of nodal types across all nodes for a given unit (i.e., a case) as the case’s <em>unit causal type</em>, or simply <em>causal type</em>. We denote a causal type by the vector <span class="math inline">\(\theta\)</span>, the elements of which are all of the nodal types in a given model (<span class="math inline">\(\theta^I\)</span>, <span class="math inline">\(\theta^E\)</span>, etc.). For analytic applications later in the book, this distinction between nodal types and causal types will become important.</p>
<p></p>
<p>We will sometimes refer to a unit’s causal type—the values of <span class="math inline">\(\theta\)</span>—as a unit’s <em>context</em>. This is because <span class="math inline">\(\theta\)</span> captures all exogenous forces acting on a unit. This includes the assignment process driving the model’s exogenous nodes (in our example, <span class="math inline">\(\theta^I\)</span> and <span class="math inline">\(\theta^E\)</span>) as well as all contextual factors and any idiosyncratic unit level features that shape causal relations between nodes (<span class="math inline">\(\theta^R\)</span>, <span class="math inline">\(\theta^M\)</span>, and <span class="math inline">\(\theta^D\)</span>). Put differently, <span class="math inline">\(\theta\)</span> captures both how a unit reacts to situations and which situations it is reacting to. Table 2.4 summarizes the difference between nodal types and causal types and their associated notation.</p>
<p>If we knew a unit’s causal type—all nodal types operating in the unit, for all nodes—then we would know everything there is to know about that unit. We would know the value of all exogenous nodes as well as how those values cascade through the model to determine the values of all endogenous nodes. So a unit’s causal type fully specifies all nodal values. More than that, because the causal type contains all causal information about a unit, it also tells us what values every endogenous node <em>would</em> take on under <em>counterfactual</em> values of other nodes. Of course, causal types, like nodal types, are fundamentally unobservable quantities. But (as we discuss later in the book) they are quantities that we will seek to draw inferences about from observable data.</p>
<div id="tbl-NTCT" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-NTCT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.4: Nodal types, causal types.
</figcaption><div aria-describedby="tbl-NTCT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 58%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><strong>Term</strong></th>
<th style="text-align: center;"><strong>Symbol</strong></th>
<th style="text-align: center;"><strong>Meaning</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Nodal type</td>
<td style="text-align: center;"><span class="math inline">\(\theta^J\)</span></td>
<td style="text-align: center;">The way that node <span class="math inline">\(J\)</span> responds to the values of its parents. Example: <span class="math inline">\(\theta^Y_{10}\)</span>: <span class="math inline">\(Y\)</span> takes the value 1 if <span class="math inline">\(X=0\)</span> and 0 if <span class="math inline">\(X=1\)</span>.</td>
</tr>
<tr class="even">
<td style="text-align: center;">Causal type</td>
<td style="text-align: center;"><span class="math inline">\(\theta\)</span></td>
<td style="text-align: center;">A causal type is a concatenation of nodal types, one for each node. Example: <span class="math inline">\((\theta^X_0, \theta^Y_{00})\)</span> is a causal type that has <span class="math inline">\(X=0\)</span> and that has <span class="math inline">\(Y=0\)</span> no matter what the value of <span class="math inline">\(X\)</span>.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>A few important aspects of causal functions are worth highlighting.</p>
<ol type="1">
<li><p>These functions express <em>causal</em> beliefs. When we write <span class="math inline">\(D=f^D(M, \theta^M) = \beta M\)</span> as a function, we do not just mean that we believe the values of <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span> in the world to be linearly related. We mean that we believe that the value of <span class="math inline">\(M\)</span> <em>determines</em> the value of <span class="math inline">\(D\)</span> through this linear function. Functions are, in this sense, <em>directional</em> statements, with causes on the right-hand side and an outcome on the left.</p></li>
<li><p>The collection of simple functions that map from the values of parents of a given node to the values of that node are sufficient to represent potentially complex webs of causal relations. For each node, we do not need to think through entire sequences of causation that might precede it. We need only specify how we believe it to be affected by its parents—that is to say, those nodes pointing <em>directly</em> into it. Our outcome of interest, <span class="math inline">\(D\)</span>, may be shaped by multiple, long chains of causality. To theorize how <span class="math inline">\(D\)</span> is generated, however, we write down how we believe <span class="math inline">\(D\)</span> is shaped by its parent—its direct cause, <span class="math inline">\(M\)</span>. We then, separately, express a belief about how <span class="math inline">\(M\)</span> is shaped by <em>its</em> parents, <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>. A node’s function must include as inputs all, and only, those nodes that point directly into that node.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p></li>
<li><p>As in the general potential-outcomes framework, all relations in a causal model are conceptualized as deterministic at the case level. Yet, there is not as much at stake here as one might think at first; by this we simply mean that a node’s value is <em>determined</em> by the values of its parents <em>along with</em> any stochastic or unknown components. We express uncertainty about causal relations, however, as unknown parameters, the nodal types.</p></li>
</ol>
<div id="rem-lempo" class="proof remark">
<p><span class="proof-title"><em>Remark 2.1</em>. </span><strong>Potential outcomes and causal functions</strong></p>
<p> </p>
<p>We sometimes describe the values of outcomes using causal functions and sometimes we use potential outcomes notation. These two representations relate to each other in a simple way.</p>
<p><strong>Causal functions</strong> are part of the definition of causal models. A causal function (such as <span class="math inline">\(f^Y\)</span>) takes as arguments <em>only the parents of a node</em> (along with the nodal type). It can only be evaluated if values for the parents of the node are provided. For instance, say <span class="math inline">\(Y\)</span> depends directly on <span class="math inline">\(X\)</span> and indirectly on <span class="math inline">\(X\)</span> via <span class="math inline">\(M\)</span>. We can then calculate the value that <span class="math inline">\(Y\)</span> takes when <span class="math inline">\(X=1\)</span> and <span class="math inline">\(M=1\)</span> via <span class="math inline">\(f^Y(X=1, M=1, \theta^Y)\)</span>. But we cannot use <span class="math inline">\(f^Y\)</span> alone to assess the value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X=1\)</span> but the value of <span class="math inline">\(M\)</span> is unspecified. The key point is that the number of arguments in a causal function is fixed and limited to the parents plus the nodal type.</p>
<p>When we use potential outcomes notation (like <span class="math inline">\(Y(X=1)\)</span>), we describe outcomes given the values of other nodes <em>that may or may not be the parents of the node of interest</em>. Thus when we write <span class="math inline">\(Y(X=1)\)</span>, we are not specifying <span class="math inline">\(M\)</span>, only <span class="math inline">\(X\)</span>. The interpretation is that we are requesting the value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> is set to 1 and <span class="math inline">\(M\)</span> takes on whatever value it takes on in that condition. Similarly, <span class="math inline">\(Y(M=1)\)</span> asks what value <span class="math inline">\(Y\)</span> takes on when <span class="math inline">\(M\)</span> is set to 1 but <span class="math inline">\(X\)</span> takes on whatever value it takes on naturally. We can also ask about these values given other conditions that might obtain but were not controlled. Thus, <span class="math inline">\(\Pr(Y(M=1)=1 | X=1)\)</span> is the probability that <span class="math inline">\(Y=1\)</span> for cases in which <span class="math inline">\(M\)</span> has been <em>set</em> to 1 and <span class="math inline">\(X\)</span> just happens to be 1.</p>
<p>These two ways of describing outcomes are related since the potential outcomes quantities can be derived from the causal functions. Thus, in the example above in which <span class="math inline">\(X\)</span> has a direct and indirect effect on <span class="math inline">\(Y\)</span> via <span class="math inline">\(M\)</span>, we can calculate <span class="math inline">\(Y(X=1)\)</span>—interpreted as the value <span class="math inline">\(Y\)</span> takes when <span class="math inline">\(X\)</span> is set to <span class="math inline">\(1\)</span> and <span class="math inline">\(M\)</span> takes whatever value it would take naturally (given <span class="math inline">\(X\)</span> is set to <span class="math inline">\(1\)</span>)—using a causal function nested within a causal function: <span class="math inline">\(f^Y(X=1, M=f^M(X=1, \theta^M), \theta^Y)\)</span>. Similarly, in a <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> chain model, we can write <span class="math inline">\(Y(X=1)\)</span> <em>even though</em> <span class="math inline">\(X\)</span> is not a parent of <span class="math inline">\(Y\)</span>, and calculate its value via <span class="math inline">\(Y(X=1) = f^Y(M = f^M(X=1, \theta^M), Y)\)</span>.</p>
</div>
</section></section><section id="the-distributions" class="level3" data-number="2.2.3"><h3 data-number="2.2.3" class="anchored" data-anchor-id="the-distributions">
<span class="header-section-number">2.2.3</span> The Distributions</h3>
<p>Putting collections of nodes and causal functions that relate these to each other together gives us what we call a <em>structural causal model.</em> A structural causal model expresses our beliefs about the skeletal structure of causal relations in a domain: It tells us which nodes are exogenous (entirely caused by things outside the model), which nodes are endogenous (caused by exogenous nodes or other endogenous nodes), and which nodes can have effects on which other nodes.</p>
<p>But this only takes us so far in inscribing our causal beliefs about the world. In particular, we have not said anything here about how <em>likely</em> different sets of conditions are, what values different nodes–whether endogenous or exogenous—are likely to take on, or the kinds of causal effects we expect most commonly to operate between linked nodes on the graph.</p>
<p>To incorporate these features we need two things. We need to include probability distributions over exogenous nodes. And we need to understand how distributions over exogenous nodes imply distributions of the values—actual or counterfactual—of endogenous nodes.</p>
<section id="probability-distributions-over-exogenous-nodes" class="level4" data-number="2.2.3.1"><h4 data-number="2.2.3.1" class="anchored" data-anchor-id="probability-distributions-over-exogenous-nodes">
<span class="header-section-number">2.2.3.1</span> Probability Distributions over Exogenous Nodes</h4>
<p>When we add information on the distribution of exogenous nodes, we move from having a structural causal model to having a <em>probabilistic</em> causal model, or simply a causal model, as we have defined it above. These probability distributions may represent our “priors”—our beliefs before seeing any data—or they may represent beliefs having seen data, our “posteriors.”</p>
<p> </p>
<p>Intuitively, it can be helpful to think of the structural model as providing a collection of rules or mechanisms that can produce different outcomes depending on the context, and to think of the collection of nodal types for a unit—that unit’s causal type—as capturing the context itself. Indeed, a set of realized values on all exogenous nodes is sometimes referred to simply as the context. To understand anything about actual outcomes we first need to understand the context.</p>
<p>Thus, for instance, a structural causal model consistent with <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> stipulates that democratization may be affected by mobilization, that mobilization may be affected by ethnic homogeneity and redistributive demands, and that redistributive demands may be affected by the level of inequality. But it says nothing about the context: the values that we think the exogenous nodes tend to take on in the world. And it says nothing about how likely (or how common) we think different contexts are. We have not said anything, that is, about how common high inequality is across the relevant domain of cases or how common ethnic homogeneity is. Put differently, we have said nothing about the <em>distribution</em> of <span class="math inline">\(\theta^I\)</span> or of <span class="math inline">\(\theta^E\)</span>. Similarly, we have said nothing yet about the nature of the causal effects in the model: for instance, about how commonly mobilization has positive, negative, or null effects of democratization; about how commonly redistributive demands (<span class="math inline">\(R\)</span>) and ethnic homogeneity (<span class="math inline">\(E\)</span>) have different possible joint causal effects on <span class="math inline">\(M\)</span>; or about how commonly inequality (<span class="math inline">\(I\)</span>) has different possible effects on redistributive demands (<span class="math inline">\(R\)</span>). That is, we have said nothing about the distribution of <span class="math inline">\(\theta^D\)</span>, <span class="math inline">\(\theta^M\)</span>, or <span class="math inline">\(\theta^R\)</span> values in the world.</p>
<p>We make progress by specifying probability distributions over the model’s nodal types—its <span class="math inline">\(\theta^J\)</span> terms, specifying <span class="math inline">\(\Pr(\theta^J = \theta^J_k)\)</span>, for each node <span class="math inline">\(J\)</span> and each nodal type potentially operating at <span class="math inline">\(J\)</span> (i.e., each possible value of <span class="math inline">\(\theta^J\)</span>). At the case level, we can think of this probability distribution as a statement about our beliefs about the unit’s type or about the context. If we think in terms of populations we might think in terms of the <em>proportion</em> of units in the population of interest that have different values for <span class="math inline">\(\theta^J\)</span>—which we will call <span class="math inline">\(\lambda^J\)</span>—and then think of the unit’s type as a draw from this population. (We may also need to specify beliefs about how cases are drawn from the population.)</p>
<p>For instance, our structural causal model might tell us that <span class="math inline">\(E\)</span> and <span class="math inline">\(R\)</span> can jointly affect <span class="math inline">\(M\)</span>. We might, then, add to this a belief about what kinds of effects among these variables are most common. For instance, we might believe that redistribution rarely has a positive effect on mobilization when ethnic homogeneity is low. Well, there are four specific nodal types in which <span class="math inline">\(R\)</span> has a positive effect on <span class="math inline">\(M\)</span>, when <span class="math inline">\(E=0\)</span>: <span class="math inline">\(\theta^M_{0010}, \theta^M_{0110}, \theta^M_{0111}\)</span>, and <span class="math inline">\(\theta^M_{0011}\)</span>. (Look back at <a href="#tbl-HJ-T-2-3" class="quarto-xref">Table&nbsp;<span>2.3</span></a> to confirm this for yourself, substituting <span class="math inline">\(E\)</span> for <span class="math inline">\(X_1\)</span> and <span class="math inline">\(R\)</span> for <span class="math inline">\(X_2\)</span>.) Thus, we can express our belief as a probability distribution over the possible nodal types for <span class="math inline">\(M\)</span>, <span class="math inline">\(\theta^M\)</span>, in which we place a relatively low probability on <span class="math inline">\(\theta^M_{0010}, \theta^M_{0110}, \theta^M_{0111}\)</span>, and <span class="math inline">\(\theta^M_{0011}\)</span>, as compared to <span class="math inline">\(\theta^M\)</span>’s other possible values. This is akin to saying that we think that these four nodal types occur in a relatively small <em>share</em> of units in the population of interest.</p>
<p>Of course, when we are thinking about populations we will usually be uncertain about these kinds of beliefs. We can then build uncertainty into our beliefs about the “shares” of different nodal types in the population. We do this by thinking of the shares as nodes in their own right and specifying a probability distribution over these shares (see e.g., <span class="citation" data-cites="chickering1996clinician">Chickering and Pearl (<a href="20-references.html#ref-chickering1996clinician" role="doc-biblioref">1996</a>)</span>). For instance, rather than stipulating that <span class="math inline">\(\lambda^E_1\)</span> (the share of cases that have <span class="math inline">\(\theta^E_1\)</span>) is exactly <span class="math inline">\(0.1\)</span>, we can specify a distribution over shares, centered on a low value but with our degree of uncertainty captured by that distribution’s variance.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> Similarly, we can specify a distribution over the shares of <span class="math inline">\(\theta^M\)</span> types, <span class="math inline">\(\lambda^M\)</span>. In consequence, our uncertainty about a unit’s type might reflect uncertainty about the features of the unit given the population, or uncertainty about the population itself.</p>
<p>In the default setup, we assume that each <span class="math inline">\(\theta\)</span> term (<span class="math inline">\(\theta^I, \theta^E, \theta^R\)</span>, etc.) is generated independently of the others. So, for instance, the probability that <span class="math inline">\(I\)</span> has a positive effect on <span class="math inline">\(R\)</span> in a case bears no relationship to the probability that <span class="math inline">\(M\)</span> has a positive effect on <span class="math inline">\(D\)</span>. Or, put differently, those cases with a positive <span class="math inline">\(I \rightarrow R\)</span> effect are no more or less likely to have a positive <span class="math inline">\(M \rightarrow D\)</span> effect than are those cases without a positive <span class="math inline">\(I \rightarrow R\)</span> effect. This independence feature is critical for allowing a causal graph to reveal relationships among nodes in a model (see, in particular, our discussion of conditional independence below). See <a href="#rem-markov" class="quarto-xref">Remark&nbsp;<span>2.2</span></a> on the “Markov condition” that relates the structure of the graph to the types of independence statements implied by the graph <span class="citation" data-cites="spirtes2000causation">(<a href="20-references.html#ref-spirtes2000causation" role="doc-biblioref">Spirtes et al. 2000</a>)</span>.</p>
<p>One subtlety is that violations of independence can arise even if we are certain that <span class="math inline">\(\theta^X\)</span> and <span class="math inline">\(\theta^Y\)</span> are drawn independently from different distributions. Specifically, it is possible for our <em>beliefs</em> about the distributions from which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are drawn not to be independent even if we believe that the draws <em>are</em> independent. Consider an example. We might have every reason to believe that <span class="math inline">\(X\)</span> is randomized and so think that <span class="math inline">\(\theta^X\)</span> is independent of <span class="math inline">\(\theta^Y\)</span>—so there is no confounding between the two. However, we might be uncertain about the assignment probability (a belief about <span class="math inline">\(\lambda^X\)</span>). Moreover, we might believe that a world in which the probability of assignment to <span class="math inline">\(X=1\)</span> is high is also a world in which treatment effects are strong (a belief about <span class="math inline">\(\lambda^Y\)</span>), and that a world with low assignment probabilities is also likely a world of weak treatment effects. In this situation, even though we are sure there is randomization of the treatment—and, indeed, conditional on the true values of <span class="math inline">\((\lambda^X, \lambda^Y)\)</span> we know that <span class="math inline">\(\theta^X\)</span> and <span class="math inline">\(\lambda^Y\)</span> are independent—the value of <span class="math inline">\(\theta^X\)</span> is related to the value of <span class="math inline">\(\theta^Y\)</span> <em>in our beliefs</em>. Specifically, when we learn <span class="math inline">\(X=1\)</span> for a random case we think it is more likely we are in the high assignment-large effects world. Thus, independence is violated.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>If the assumption of independence cannot be maintained, then the model might have to be enriched to ensure independence between exogenous nodes. Otherwise, nonindependence has to be taken into account when doing analysis.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> Graphically we represent such failures of independence by using curved two headed arrows. More on this in <a href="#sec-graphing" class="quarto-xref"><span>Section 2.3.1</span></a>.</p>
</section><section id="sec-CI" class="level4" data-number="2.2.3.2"><h4 data-number="2.2.3.2" class="anchored" data-anchor-id="sec-CI">
<span class="header-section-number">2.2.3.2</span> Induced Distributions over Endogenous Nodes</h4>
<p></p>
<p>When we provide a distribution over exogenous nodes we have all we need to calculate a distribution over endogenous nodes since these nodes are all ultimately functions of exogenous nodes.</p>
<p>Figuring out the induced probability distribution of endogenous nodes is conceptually not so hard. We can imagine calculating these distributions by first looking at root nodes. For a root note <span class="math inline">\(V^1\)</span>, say, the distribution of <span class="math inline">\(V^1\)</span>, depends only on <span class="math inline">\(\theta^1\)</span>. If we figure out what values of <span class="math inline">\(\theta^1\)</span> give rise to a particular value of <span class="math inline">\(V^1\)</span>, say <span class="math inline">\(V^1 = v^1\)</span> when <span class="math inline">\(\theta^1 = \theta^1_1\)</span>, then the probability that <span class="math inline">\(V^1 = v^1\)</span> is just the probability that <span class="math inline">\(\theta^1 = \theta^1_1\)</span>. For non-root nodes, we proceed similarly except that we first calculate the probability of different possible values for their parents. For <span class="math inline">\(V^2\)</span>, for instance, we assess what values of <span class="math inline">\(\theta^2\)</span> and <span class="math inline">\(V^2\)</span>’s parent, <span class="math inline">\(V^1\)</span> say, give rise to particular values of <span class="math inline">\(V^2\)</span>, and then deduce from the causal function for what set of values of <span class="math inline">\(\theta^1\)</span> <em>and</em> <span class="math inline">\(\theta^2\)</span> we would observe <span class="math inline">\(V^2 = v^2\)</span>, say. Then we have enough to figure out the probability that <span class="math inline">\(V^2 = v^2\)</span> from the joint probability of <span class="math inline">\(\theta^1\)</span> and <span class="math inline">\(\theta^2\)</span>. And so on for subsequent nodes in the ordering.</p>
<p>Taking this one step further, it’s not hard to see that from the distribution of the exogenous nodes, we have enough to determine not just what outcomes arise in a given context but also what would arise if we <em>intervened</em> in that context. In that case we proceed as before, but now the probability of a node on which we have intervened is <em>known</em>, not inferred from <span class="math inline">\(\Pr(\theta)\)</span>.</p>
</section></section><section id="sec-cond_indep_2" class="level3" data-number="2.2.4"><h3 data-number="2.2.4" class="anchored" data-anchor-id="sec-cond_indep_2">
<span class="header-section-number">2.2.4</span> 2.2.4 Conditional Independence</h3>
<p>Importantly, even if we assume that the exogenous nodes in a model are independently distributed, we are not likely to think that the endogenous ones are. In fact, insofar as one node depends on another, it is obvious that they are not. As a result, the induced probability distribution over endogenous variables might be quite complicated.</p>
<p>Fortunately, however, the structure provided by a causal model makes it possible to use statements about “conditional independence” (see <a href="#def-ci" class="quarto-xref">Definition&nbsp;<span>2.2</span></a>) to generate relatively simple statements about the joint probability of all nodes.</p>
<div id="def-ci" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 2.2</strong></span> <strong>Conditional Independence</strong></p>
<p></p>
<p>Nodes <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are “<strong>conditionally independent</strong>” given <span class="math inline">\(C\)</span> if <span class="math inline">\(\Pr(a|b,c) = \Pr(a|c)\)</span> for all values of <span class="math inline">\(a, b\)</span>, and <span class="math inline">\(c\)</span>.</p>
</div>
<p>So let’s unpack the idea of conditional independence. The key idea is that two variables are <em>independent</em> when knowing something about one is not helpful for making inferences about the other (we get to the “conditional” part in a moment). Conversely, when there is a <em>dependence</em> between two nodes, then knowing something about one of them is informative about the other.</p>
<p>These relations of dependence and independence between nodes can result from the structure of causal relations. Intuitively, we can usefully think of dependencies as arising from the ways information flows along causal pathways. For instance, in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, the arrow running from <span class="math inline">\(I\)</span> to <span class="math inline">\(R\)</span> means that <span class="math inline">\(R\)</span> is causally dependent on <span class="math inline">\(I\)</span>. This dependence, moreover, implies that if we know something about <span class="math inline">\(I\)</span>, then we expect to know something about <span class="math inline">\(R\)</span>. Concretely, we might expect <span class="math inline">\(I\)</span>’s and <span class="math inline">\(R\)</span>’s values to be correlated with each other.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>The graph in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> thus implies that, if we measured redistributive preferences, we would also be in a better position to infer the level of inequality, and vice versa. Similarly, <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> are linked in a relationship of dependence, one that is mediated by <span class="math inline">\(R\)</span>. Since inequality can affect mobilization (through <span class="math inline">\(R\)</span>), knowing the level of inequality would allow us to improve our estimate of the level of mobilization—and vice versa.</p>
<p>In contrast, consider <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>, which in this model are <em>independent</em> of one another. In this model these two nodes have no common ancestor, which means that the forces that set a case’s level of inequality are (assumed to be) independent of the forces that determine its level of ethnic homogeneity. So learning the level of inequality in a case, according to this model, would give us no information whatsoever about the case’s degree of ethnic homogeneity and vice-versa.</p>
<p>So dependencies between nodes can arise from those nodes lying along a causal chain. Yet they can also arise from nodes having common causes (or ancestors). Consider <a href="#fig-HJ-F-2-2" class="quarto-xref">Figure&nbsp;<span>2.2</span></a>. Here, we are indicating that war (<span class="math inline">\(W\)</span>) can cause both excess deaths (<span class="math inline">\(D\)</span>) and price inflation (<span class="math inline">\(P\)</span>). Casualties and inflation may then be correlated with one another because of their shared cause. If we learn that there have been military casualties, this information will lead us to think it more likely that there is also war and, in turn, that there is price inflation (and vice versa). When two outcomes have a common (proximate or distant) cause, observing one outcome might lead us to believe it more likely that the other outcome has also occurred.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-2-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-causal-models_files/figure-html/fig-HJ-F-2-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-2-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: A simple causal model in which war (<span class="math inline">\(W\)</span>) affects both excess deaths (<span class="math inline">\(D\)</span>) and price inflation (<span class="math inline">\(P\)</span>).
</figcaption></figure>
</div>
</div>
</div>
<p>Now let’s turn to the “conditional” part. The key idea here is that sometimes what we learn from an observation depends on <em>what we already know.</em> An everyday example can help us wrap our minds around this intuition. Suppose that, on a winter’s day, I want to know whether the boiler in my basement, which provides steam to the heating system, is working properly. I usually figure out if the boiler is working by reading the temperature on the thermometer on my living room wall: This is because I believe that the boiler’s operation <em>causes</em> the room temperature to rise (implying <span class="math inline">\(B \rightarrow T\)</span>). Under this causal dependency, the temperature in the living room is generally <em>informative</em> about the boiler’s operation. If the room is warm, this makes me believe that the boiler is probably operating; if the room is cold, then I come to think it’s less likely that the boiler is running. (Similarly, if I go down to the basement and can see whether the boiler is fired up, this will shape my expectations about how warm the living room is.)</p>
<p>However, I also believe that the boiler affects the room’s temperature <em>through</em> a change in the temperature of the radiator (<span class="math inline">\(B \rightarrow R \rightarrow T\)</span>), and that this is the only way in which the boiler can affect the room temperature. So suppose that, before reading the thermometer on the wall, I touch the radiator and feel that it is hot. The radiator’s temperature has, of course, given me information about the boiler’s operation—since I believe that the boiler’s operation has an effect on the radiator’s temperature (<span class="math inline">\(B \rightarrow R\)</span>). If the radiator is hot, I judge that the boiler is probably running. But now, having already observed the radiator’s temperature, can I learn anything <em>further</em> about whether the boiler is operating by taking a reading from the thermometer on the wall? No, I cannot. Everything I could possibly learn about the boiler’s status from gauging the room’s temperature I have <em>already</em> learned from touching the radiator—since the boiler’s effect on the room’s temperature runs entirely <em>through</em> the radiator. One way to think about this is that, by observing the radiator’s temperature, we have fully intercepted, or “blocked”, the flow of information from the boiler to the wall thermometer.</p>
<p>In sum, the room’s temperature <em>can</em> be informative about the boiler, but whether it is informative hinges on whether we already know if the radiator is hot. If we know <span class="math inline">\(R\)</span>, then <span class="math inline">\(B\)</span> and <span class="math inline">\(T\)</span> are uninformative about one another. Formally, we say that <span class="math inline">\(B\)</span> and <span class="math inline">\(T\)</span> are <em>conditionally independent given</em> <span class="math inline">\(R\)</span>.</p>
<p>Turning back to <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, imagine that we already knew the level of redistributive preferences. Would we then be in a position to learn about the level of inequality by observing the level of mobilization? According to this DAG, we would not. This is because <span class="math inline">\(R\)</span>, which we already know, <em>blocks</em> the flow of information between <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span>. Since the causal link—and, hence, the flow of information—between <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> runs through <span class="math inline">\(R\)</span>, and we already know <span class="math inline">\(R\)</span>, there is nothing left to be learned about <span class="math inline">\(I\)</span> by also observing <span class="math inline">\(M\)</span>. Anything we could have learned about inequality by observing mobilization is already captured by the level of redistributive preferences, which we have already seen. We can express this idea by saying that <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> are <em>conditionally independent given</em> <span class="math inline">\(R\)</span>. That is, observing <span class="math inline">\(R\)</span> makes <span class="math inline">\(I\)</span> and <span class="math inline">\(M\)</span> independent of one another.</p>
<div id="rem-markov" class="proof remark">
<p><span class="proof-title"><em>Remark 2.2</em>. </span><strong>The Markov Condition</strong></p>
<p>The assumptions that no node is its own descendant and that the <span class="math inline">\(\theta\)</span> terms are generated independently make the model “<em>Markovian</em>,” and the parents of a given node are “Markovian parents.”</p>
<p>Knowing the set of Markovian parents allows us to write relatively simple factorizations of a joint probability distribution, exploiting the fact (“the Markov condition”) that all nodes are <em>conditionally independent</em> of their nondescendants, conditional on their parents.</p>
<p>Consider how this property allows for simple factorization of <span class="math inline">\(P\)</span> for an <span class="math inline">\(X \rightarrow M \rightarrow Y\)</span> DAG. Note that <span class="math inline">\(P(X, M, Y)\)</span> can always be written as: <span class="math display">\[P(X, M, Y) = P(X)P(M|X)P(Y|M, X)\]</span> If we believe, as implied by this DAG, that <span class="math inline">\(Y\)</span> is independent of <span class="math inline">\(X\)</span> given <span class="math inline">\(M\)</span>, then we have the simpler factorization: <span class="math display">\[P(X, M, Y) = P(X)P(M|X)P(Y|M)\]</span></p>
<p>More generally, using <span class="math inline">\(pa_i\)</span> to denote the parents of <span class="math inline">\(i\)</span>, we have:</p>
<p><span id="eq-markov"><span class="math display">\[
P(v_1,v_2,\dots, v_n) = \prod P(v_i|pa_i)
\tag{2.2}\]</span></span></p>
</div>
<p>More generally, knowing if two nodes are or are not conditionally independent of each other tells us if we can learn about one from values of the other.</p>
</section></section><section id="graphing-models-and-using-graphs" class="level2" data-number="2.3"><h2 data-number="2.3" class="anchored" data-anchor-id="graphing-models-and-using-graphs">
<span class="header-section-number">2.3</span> Graphing Models and Using Graphs</h2>
<p> While we have already been speaking about causal graphs throughout this chapter, we want to take some time to unpack their core features and uses. A key benefit of causal models is that they lend themselves to graphical representations. In turn, graphs constructed according to particular rules can aid causal analysis. In the next subsection, we discuss a set of rules for representing a model in graphical form. The following subsection then demonstrates how access to a graph facilitates causal inference.</p>
<section id="sec-graphing" class="level3" data-number="2.3.1"><h3 data-number="2.3.1" class="anchored" data-anchor-id="sec-graphing">
<span class="header-section-number">2.3.1</span> Rules for Graphing Causal Models</h3>
<p> The diagram in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> is a causal DAG <span class="citation" data-cites="hernan2006instruments">(<a href="20-references.html#ref-hernan2006instruments" role="doc-biblioref">Hernán and Robins 2006</a>)</span>. We endow it with the interpretation that an arrow from a parent to a child means that a change in the parent can, under some circumstances, induce a change in the child. Though we have already been using this causal graph to help us visualize elements of a causal model, we now explicitly point out a number of general features of causal graphs as we will be using them throughout this book. Causal graphs have their own distinctive “grammar,” a set of rules that give them useful analytic features.</p>
<p><strong>Directed, acyclic.</strong> A causal graph represents elements of a causal model as a set of nodes (or vertices), representing variables, connected by a collection of single-headed arrows (or directed edges). We draw an arrow from node <span class="math inline">\(A\)</span> to node <span class="math inline">\(B\)</span> if and only if we believe that <span class="math inline">\(A\)</span> can have a direct effect on <span class="math inline">\(B\)</span>. Thus, in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, the arrow from <span class="math inline">\(I\)</span> to <span class="math inline">\(R\)</span> means that inequality can directly affect redistributive demands.</p>
<p>The resulting diagram is a DAG if there are no paths along directed edges that lead from any node back to itself—that is, if the graph contains no causal cycles. The absence of cycles (or “feedback loops”) is less constraining than it might appear at first. In particular, if one thinks that <span class="math inline">\(A\)</span> today causes <span class="math inline">\(B\)</span> tomorrow which in turn causes <span class="math inline">\(A\)</span> the next day, we can represent this as <span class="math inline">\(A_1 \rightarrow B \rightarrow A_2\)</span> (rather than <span class="math inline">\(A \leftrightarrow B\)</span>). We timestamp the nodes, turning what might informally appear as feedback into a noncyclical chain.</p>
<p><strong>Meaning of missing arrows.</strong> The <em>absence</em> of an arrow between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> means that <span class="math inline">\(A\)</span> is not a direct cause of <span class="math inline">\(B\)</span>.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> Here lies an important asymmetry: drawing an <span class="math inline">\(A \rightarrow B\)</span> arrow does not mean that we know that <span class="math inline">\(A\)</span> <em>does</em> directly cause <span class="math inline">\(B\)</span>; but omitting such an arrow implies that we know that <span class="math inline">\(A\)</span> does <em>not</em> directly cause <span class="math inline">\(B\)</span>. We say more with the arrows that we omit than with the arrows that we include.</p>
<p>Returning to <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, we have here expressed the belief that redistributive preferences exert no direct effect on democratization; we have done so by <em>not</em> drawing an arrow directly from <span class="math inline">\(R\)</span> to <span class="math inline">\(D\)</span>. In the context of this model, saying that redistributive preferences have no direct effect on democratization is to say that any effect of redistributive preferences on democratization <em>must</em> run through mobilization; there is no other pathway through which such an effect can operate. As social scientists, we often have beliefs that take this form. For instance, the omission of an arrow from <span class="math inline">\(R\)</span> to <span class="math inline">\(D\)</span> might be a way of encoding the belief that mass preferences for redistribution cannot induce autocratic elites to liberalize the regime absent collective action in pursuit of those preferences.</p>
<p>The same goes for the effects of <span class="math inline">\(I\)</span> on <span class="math inline">\(M\)</span>, <span class="math inline">\(I\)</span> on <span class="math inline">\(D\)</span>, and <span class="math inline">\(E\)</span> on <span class="math inline">\(D\)</span>: The graph in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> implies that we believe that these effects also do not operate directly, but only along the indicated, mediated paths.</p>
<p>Moreover, when we say that <span class="math inline">\(A\)</span> does not have a direct effect on <span class="math inline">\(B\)</span>—justifying an excluded arrow—we do not mean merely that <span class="math inline">\(A\)</span> doesn’t affect <span class="math inline">\(B\)</span> <em>on average.</em> We mean that there is no chance that <span class="math inline">\(A\)</span> affects <span class="math inline">\(B\)</span>.</p>
<p><strong>Possible-causes.</strong> The existence of an arrow from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> does not imply that <span class="math inline">\(A\)</span> always has (or certainly has) a direct effect on <span class="math inline">\(B\)</span>. Consider, for instance, the arrows running from <span class="math inline">\(E\)</span> and from <span class="math inline">\(R\)</span> to <span class="math inline">\(M\)</span>. Since <span class="math inline">\(M\)</span> has two parents, assuming all variables are binary, we define a range of 16 nodal types for <span class="math inline">\(\theta^M\)</span>, capturing all possible joint effects of <span class="math inline">\(E\)</span> and <span class="math inline">\(R\)</span>. However, for some of these nodal types, <span class="math inline">\(E\)</span> or <span class="math inline">\(R\)</span> or both will have no effect on <span class="math inline">\(M\)</span>. For instance, in the nodal type <span class="math inline">\(\theta^M_{0011}\)</span>,<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> <span class="math inline">\(E\)</span> has no effect on <span class="math inline">\(M\)</span> while <span class="math inline">\(R\)</span> has a positive effect. Thus, in a case with this nodal type for <span class="math inline">\(M\)</span>, <span class="math inline">\(E\)</span> is not a cause of <span class="math inline">\(M\)</span>; whereas in a case with, say, <span class="math inline">\(\theta^M_{0101}\)</span>, <span class="math inline">\(E\)</span> has an effect on <span class="math inline">\(M\)</span>, while <span class="math inline">\(R\)</span> has none. In this sense, the existence of the arrows pointing into <span class="math inline">\(M\)</span> reflects that <span class="math inline">\(E\)</span> and <span class="math inline">\(R\)</span> are “possible causes” of <span class="math inline">\(M\)</span>.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<p><strong>No excluded common causes.</strong> Any cause common to multiple nodes on a graph must itself be represented on the graph. If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> on a graph are both affected by some third node, <span class="math inline">\(C\)</span>, then we must represent this common cause. Thus, for instance, the graph in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> implies that <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> have no common cause. If we believed that a country’s level of inequality and its ethnic composition were both shaped by, say, its colonial heritage, then this DAG would <em>not</em> be an accurate representation of our beliefs about the world. To make it accurate, we would need to add to the graph a node capturing that colonial heritage and include arrows running from colonial heritage to both <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>.</p>
<p>This rule of “no excluded common causes” ensures that the graph captures all potential relations among nodes that are implied by our beliefs. If <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> are in fact driven by some common cause, then this means not just that these two nodes may be correlated but also that each may be correlated with any consequences of the other. For instance, a common cause of <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span> would also imply a dependence between <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>. <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span> are implied to be independent in the current graph but would be implied to be dependent if a common node pointed into both <span class="math inline">\(I\)</span> and <span class="math inline">\(E\)</span>.</p>
<p>Of particular interest is the implied independence of <span class="math inline">\(\theta\)</span> terms from one another, noted earlier. In <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, imagine, for instance, that the distribution of <span class="math inline">\(\theta^D\)</span> and <span class="math inline">\(\theta^I\)</span> was dependent: that is, if the distribution of <span class="math inline">\(\theta^D\)</span> were different when <span class="math inline">\(I=0\)</span> than when <span class="math inline">\(I=1\)</span>. This could be because some other factor, perhaps a feature of a country’s economy, affects both its level of inequality and the response of its elites to mobilization from below. Such a situation would represent a classic form of confounding: the assignment of cases to values on an explanatory node (<span class="math inline">\(I\)</span>) would depend on the case’s potential outcomes on <span class="math inline">\(D\)</span>. The omission of any such common cause is equivalent to expressing the belief that <span class="math inline">\(I\)</span> is exogenous, that is, (as if) randomly assigned. If we believe such a common cause to be operating, however, then we must include it as a node on the graph, pointing into both <span class="math inline">\(I\)</span> and <span class="math inline">\(D\)</span>.</p>
<p><strong>Representing Unobserved Confounding</strong> </p>
<p> It may be, however, that there are common causes that we simply do not understand. We might believe, for instance, that some unknown factor (partially) determines both <span class="math inline">\(I\)</span> and <span class="math inline">\(D\)</span>. We refer to this situation as one of <em>unobserved</em> confounding. Even when we do not know what factor is generating the confounding, we still have a violation of the assumption of independence and need to be sure we are capturing this relationship in the graph. We can do so in a couple of ways. If we are representing all <span class="math inline">\(\theta\)</span> terms on a graph, then we can capture the relationship between <span class="math inline">\(\theta^I\)</span> and <span class="math inline">\(\theta^D\)</span> by including a single, joint term <span class="math inline">\((\theta^I, \theta^D)\)</span> that points into both <span class="math inline">\(I\)</span> and <span class="math inline">\(D\)</span>. Where the <span class="math inline">\(\theta\)</span> terms are not explicitly included in a graph (as is often the case), we can represent unobserved confounding by adding a two-headed arrow, or a dotted line, connecting nodes whose unknown causes are not independent. Either way, we are building in the possibility of a joint distribution over the nodal types <span class="math inline">\(\theta^I\)</span> and <span class="math inline">\(\theta^D\)</span>. <a href="#fig-HJ-F-2-3" class="quarto-xref">Figure&nbsp;<span>2.3</span></a> illustrates for the <span class="math inline">\(I\)</span> and <span class="math inline">\(D\)</span> relationship.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-2-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-causal-models_files/figure-html/fig-HJ-F-2-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-2-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: A DAG with unobserved confounding
</figcaption></figure>
</div>
</div>
</div>
<p>We address unobserved confounding in more detail later in the book and show how we can seek to learn about the joint distribution of nodal types—that is, how we can learn even about confounders that we cannot observe—in such situations.</p>
<p><strong>License to exclude nodes.</strong> The flip side of the “no excluded common causes” rule is that a causal graph does not need to include everything that we know about a substantive domain of interest. We may know quite a lot about the causes of economic inequality, for example. But we can safely omit any factor from the graph as long <em>as it does not affect multiple nodes in the model.</em> Indeed, <span class="math inline">\(\theta^I\)</span> in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> already implicitly captures all factors that affect <span class="math inline">\(I\)</span>. Similarly, <span class="math inline">\(\theta^D\)</span> captures all factors <em>other than</em> mobilization that affect democratization. We may be aware of a vast range of forces shaping whether countries democratize, but we can choose to bracket them for the purposes of an examination of the role of economic inequality. This bracketing is permissible as long as none of these unspecified factors also act on other nodes that <em>are</em> included in the model. For instance, we have chosen to exclude from the model the existence of international pressure on a state to democratize, even though this is another potential cause of democratization. This exclusion is permissible as long as we believe that international pressure does not have an effect on the level of inequality, a state’s ethnic makeup, redistributive demands, or mobilization.</p>
<p>Similarly, we do not need to include all mediating steps that we believe might be operating between two causally linked variables. In <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, we could choose to exclude <span class="math inline">\(R\)</span>, for instance, and draw an arrow directly from <span class="math inline">\(I\)</span> to <span class="math inline">\(M\)</span>. We could also exclude <span class="math inline">\(M\)</span>, if we wished to. (Since <span class="math inline">\(E\)</span> points into <span class="math inline">\(M\)</span>, removing <span class="math inline">\(M\)</span> would mean that we would have <span class="math inline">\(E\)</span> point directly into <span class="math inline">\(R\)</span>—a point that we return to below.) And, of course, the model that we have drawn leaves out numerous other mediating steps that we might imagine—such as the role of elites’ perceptions of the costs of repression as a mediator between mobilization and democratization. In other words, we generally have discretion about the degree of granularity to represent in our chains of causation. As we explain in <a href="06-theory-as-causal-models.html" class="quarto-xref"><span>Chapter 6</span></a> and <a href="07-process-tracing-with-models.html" class="quarto-xref"><span>Chapter 7</span></a>, we will sometimes want to spell out more, rather than fewer, mediating steps in our models for reasons of research design—because of the empirical leverage that such mediating variables might provide. However, there is nothing about the rules of DAG-making that require a particular level of granularity.</p>
<p><strong>We can’t read causal functions from a graph.</strong> As should be clear, a DAG does not represent all features of a causal model. What it does record is which nodes enter into the causal function for every other node: what can directly cause what. But the DAG contains no other information about the form of those causal relations. Thus, for instance, the DAG in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> tells us that <span class="math inline">\(M\)</span> is a function of both <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>, but it does not tell us whether that joint effect is additive (<span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span> separately increase mobilization) or interactive (the effect of each depends on the value of the other). Nor does it tell us whether either effect is linear, concave, or something else.</p>
<p>This lack of information about functional forms is puzzling at first: Surely, it would be convenient to visually differentiate, say, additive from interactive effects. As one thinks about the variety of possible causal functions; however, it quickly becomes clear that there would be no simple visual way of capturing all possible causal relations. Moreover, causal graphs do not require a specification of causal functions in order to perform their main analytic purpose—a purpose to which we now turn.</p>
</section><section id="conditional-independence-from-dags" class="level3" data-number="2.3.2"><h3 data-number="2.3.2" class="anchored" data-anchor-id="conditional-independence-from-dags">
<span class="header-section-number">2.3.2</span> Conditional Independence from DAGs</h3>
<p></p>
<p>If we encode our prior knowledge using the grammar of a causal graph, we can put that knowledge to work for us in powerful ways. In particular, the rules of DAG construction allow for an easy reading of whether and when variables in the model are likely to be independent of each other. More formally, we say that we can use a DAG to identify the <em>conditional independencies</em> that are implied by our causal beliefs. (For a more extended treatment of the ideas in this section, see <span class="citation" data-cites="rohrer2018thinking">Rohrer (<a href="20-references.html#ref-rohrer2018thinking" role="doc-biblioref">2018</a>)</span>.)</p>
<p>In <a href="#sec-cond_indep_2" class="quarto-xref"><span>Section 2.2.4</span></a> we introduced the idea of conditional independence. A major benefit of a DAG is that, if we have followed the rules for DAG construction correctly, we can read relationships of conditional independence directly from the graph.</p>
<p>Such relations of conditional independence are central to the strategy of statistical control, or covariate adjustment, in correlation-based forms of causal inference, such as regression. In a regression framework, identifying the causal effect of an explanatory node, <span class="math inline">\(X\)</span>, on a dependent node, <span class="math inline">\(Y\)</span>, requires the assumption that <span class="math inline">\(X\)</span>’s value is conditionally independent of <span class="math inline">\(Y\)</span>’s potential outcomes (over values of <span class="math inline">\(X\)</span>) given the model’s covariates. To draw a causal inference from a regression coefficient, in other words, we have to believe that including the covariates in the model “breaks” any biasing correlation between the value of the causal node and its unit-level effect.</p>
<p>As we will explore, however, relations of conditional independence are also of more general interest in that they tell us, given a model, <em>when information about one feature of the world may be informative about another feature of the world, given what we already know</em>. By identifying the possibilities for learning, relations of conditional independence can thus guide research design more broadly. We discuss these research-design implications in <a href="07-process-tracing-with-models.html" class="quarto-xref"><span>Chapter 7</span></a>, but focus here on showing how relations of conditional independence operate on a DAG.</p>
<p>To see more systematically how a DAG can reveal conditional independencies, it is useful to spell out three elemental structures according to which information can flow across a causal graph.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-2-4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-2-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-causal-models_files/figure-html/fig-HJ-F-2-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-2-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Three elemental relations of conditional independence.
</figcaption></figure>
</div>
</div>
</div>
<p></p>
<p>For each of the three structures in <a href="#fig-HJ-F-2-4" class="quarto-xref">Figure&nbsp;<span>2.4</span></a>, we can read off whether nodes are independent both in situations when other nodes are not already observed and in situations in which they are. We discuss each of these structures in turn. For each, we first specify the unconditional relations among nodes in the structure and then the relations conditional on having already observed another node. When we talk about “unconditional” relations, we are asking: What does observing one node in the structure tell us about the other nodes? When we talk about “conditional” relations, we are asking: If we have already observed a node (so, conditional on that node), what does observing a second node tell us about a third node?</p>
<p><strong>(1) A Path of Arrows in the Same Direction</strong></p>
<p><em>Unconditional relations.</em> Information can flow unconditionally along a path of arrows pointing in the same direction. In Panel 1 of <a href="#fig-HJ-F-2-4" class="quarto-xref">Figure&nbsp;<span>2.4</span></a>, information flows across all three nodes. If we have observed nothing yet, learning about any one node can tell us something about the other two.</p>
<p><em>Conditional relations.</em> Learning the value of a node along a path of arrows pointing in the same direction <em>blocks</em> flows of information that passes through that node. Knowing the value of <span class="math inline">\(B\)</span> in Panel 1 renders <span class="math inline">\(A\)</span> no longer informative about <span class="math inline">\(C\)</span>, and vice versa. This is because anything that <span class="math inline">\(A\)</span> might tell us about <span class="math inline">\(C\)</span> is already captured by the information contained in <span class="math inline">\(B\)</span>.</p>
<p><strong>(2) A forked path</strong></p>
<p></p>
<p><em>Unconditional relations.</em> Information can flow unconditionally across the branches of any forked path. In Panel 2, if we have observed nothing already, learning about any one node can provide information about the other two nodes. For instance, observing only <span class="math inline">\(A\)</span> can provide information about <span class="math inline">\(C\)</span> and vice versa.</p>
<p><em>Conditional relations.</em> Learning the value of the node at the forking point <em>blocks</em> flows of information across the branches of a forked path. In Panel 2, learning <span class="math inline">\(A\)</span> provides no information about <span class="math inline">\(C\)</span> if we already know the value of <span class="math inline">\(B\)</span>.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<p><strong>(3) An Inverted Fork (Collision)</strong> </p>
<p><em>Unconditional relations.</em> When two or more arrowheads collide, generating an inverted fork, there is no unconditional flow of information between the incoming sequences of arrows. In Panel 3, learning only <span class="math inline">\(A\)</span> provides no information about <span class="math inline">\(C\)</span>, and vice versa, since each is independently determined.</p>
<p><em>Conditional relations.</em> Collisions can be sites of <em>conditional</em> flows of information. In the jargon of causal graphs, <span class="math inline">\(B\)</span> in Panel 3 is a “collider” for <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>.<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> Although information does not flow unconditionally across colliding sequences, it does flow across them <em>conditional</em> on knowing the value of the collider node or any of its downstream consequences. In Panel 3, learning <span class="math inline">\(A\)</span> <em>does</em> provide new information about <span class="math inline">\(C\)</span>, and vice-versa, <em>if</em> we also know the value of <span class="math inline">\(B\)</span> (or, in principle, the value of anything that <span class="math inline">\(B\)</span> causes).</p>
<p>The last point is somewhat counterintuitive and warrants further discussion. It is easy enough to see that, for two nodes that are correlated unconditionally, that correlation can be “broken” by controlling for a third node. In the case of collision, two nodes that are <em>not</em> correlated (or more generally, independent) when taken by themselves can <em>become</em> correlated when we condition on (i.e., learn the value of) a third node into which they both point, the collider. The reason is in fact quite straightforward once one sees it: If an outcome is a joint function of two inputs, then if we know the outcome, information about one of the inputs can provide information about the other input. For example, if I know that you are short, then learning that your mother is tall makes me more confident that your father is short. Crucially, it is knowing the <em>outcome</em>—that you are short—that makes the information about your mother’s height informative about your father’s.</p>
<p>Looking back at our democratization DAG in <a href="#fig-HJ-F-2-1" class="quarto-xref">Figure&nbsp;<span>2.1</span></a>, <span class="math inline">\(M\)</span> is a collider for <span class="math inline">\(R\)</span> and <span class="math inline">\(E\)</span>, its two inputs. Suppose that <span class="math inline">\(M\)</span> is determined by the parametric causal function <span class="math inline">\(M=RE\)</span>. Knowing about redistributive preferences alone provides no information whatsoever about ethnic homogeneity since the two are determined independently of one another. On the other hand, imagine that we already know that there was no mobilization. Now, if we observe that there <em>were</em> redistributive preferences, we can figure out the level of ethnic homogeneity: it must be 0. (And likewise in going from observing homogeneity to inferring redistributive preferences.)</p>
<p>Using these basic principles, conditional independencies can be read off of any DAG. If we want to know whether two nodes are conditionally independent of one another, we do so by checking every path connecting them. And we ask whether, along those paths, the flow of information is open or blocked, given any other nodes whose values are already observed. Conditional independence is established when <em>all</em> paths are blocked given what we have already observed; otherwise, conditional independence is absent.</p>
<p>Following <span class="citation" data-cites="pearl2000causality">Pearl (<a href="20-references.html#ref-pearl2000causality" role="doc-biblioref">2000</a>)</span>, we will sometimes refer to relations of conditional independence using the term <em>d-separation.</em> We say that variable set <span class="math inline">\(\mathcal C\)</span> <span class="math inline">\(d\)</span>-separates variable set <span class="math inline">\(\mathcal A\)</span> from variable set <span class="math inline">\(\mathcal B\)</span> if <span class="math inline">\(\mathcal A\)</span> and <span class="math inline">\(\mathcal B\)</span> are conditionally independent given <span class="math inline">\(\mathcal C\)</span>. For instance, in Panel 2 of <a href="#fig-HJ-F-2-4" class="quarto-xref">Figure&nbsp;<span>2.4</span></a>, <span class="math inline">\(B\)</span> <span class="math inline">\(d-\)</span>separates <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>. We say that <span class="math inline">\(\mathcal A\)</span> and <span class="math inline">\(\mathcal B\)</span> are <span class="math inline">\(d-\)</span>connected given <span class="math inline">\(\mathcal C\)</span> if <span class="math inline">\(\mathcal A\)</span> and <span class="math inline">\(\mathcal B\)</span> are <em>not</em> conditionally independent given <span class="math inline">\(\mathcal C\)</span>. For instance, in Panel 3, <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span> are <span class="math inline">\(d-\)</span>connected given <span class="math inline">\(B\)</span>.</p>
<p>Readers are invited to practice reading relations of conditional independence off of a DAG using the exercises in the Appendix, <a href="#sec-tryci" class="quarto-xref"><span>Section 2.5.3</span></a>. Analyzing a causal graph for relations of independence represents one payoff to formally encoding our beliefs about the world in a causal model. We are, in essence, drawing out implications of those beliefs: Given what we believe about a set of direct causal relations (the arrows on the graph), what must this logically imply about other dependencies and independencies on the graph, conditional on having observed some particular set of nodes? We show in a later chapter how these implications can be deployed to guide research design by indicating which parts of a causal system are potentially informative about other parts that may be of interest.</p>
</section><section id="simplifying-models" class="level3" data-number="2.3.3"><h3 data-number="2.3.3" class="anchored" data-anchor-id="simplifying-models">
<span class="header-section-number">2.3.3</span> Simplifying Models</h3>
<p></p>
<p>It is very easy to write down a model that is too complex to use effectively. In such cases we often seek simpler models that are consistent with models we have in mind but contain fewer nodes or more limited variation. As we have already suggested, we often have considerable discretion about how detailed to make our models. However, whenever we seek to simplify a more complex model, we must take care to ensure that the simplified model is logically consistent with the original model.</p>
<p>The main rule that we must follow when simplifying a model is to preserve dependencies implied by the original, more complex model. Consider a few examples drawing on our Inequality example. Suppose that we begin with a model that includes the following structure: <span class="math display">\[\text{Mobilization} \leftarrow \text{Inequality} \rightarrow \text{Mortality}\]</span></p>
<p>And suppose that we are not interested in inequality or its effects per se and so wish to eliminate it from the model. We can do so, but then we must retain the relationship between <em>Mobilization</em> and <em>Mortality</em> that is implied in the original model. We can do so by drawing a double-headed arrow between <em>Mobilization</em> and <em>Mortality</em>, implying unobserved confounding between the two. Another alternative could be to simplify the graph further and simply remove <em>Mortality</em> and its descendants from the graph, which we can safely do <em>if</em> none of these nodes point into other nodes that we are retaining (since, if they do, then another dependency would be lost by this simplification). </p>
<p>Another situation in which a dependency must be preserved is where the node we eliminate is a mediator, as when we remove <em>Mobilization</em> from <span class="math display">\[\text{Inequality} \rightarrow \text{Mobilization} \rightarrow \text{Democratization}\]</span>.</p>
<p>Since a dependency between <em>Inequality</em> and <em>Democratization</em> runs through <em>Mobilization</em> in the original model, we would preserve that dependency by linking the two, that is, with the structure: <span class="math display">\[\text{Inequality} \rightarrow \text{Democratization}\]</span>.</p>
<p>Alternatively, suppose that, beginning with the model <span class="math inline">\(\text{Inequality} \rightarrow \text{Mobilization} \rightarrow \text{Democratization}\)</span>, we wish to eliminate <em>Inequality</em>. Suppose further that <em>Inequality</em> is a root node (it has no substantive parents) with no children other than <em>Mobilization</em>. Then we can eliminate <em>Inequality</em> from the graph without taking further steps. This is because there are no dependencies among substantive nodes that operate via <em>Inequality</em>.</p>
<p>Similarly, if our model includes the structure <span class="math inline">\(\text{Mobilization} \rightarrow \text{Democratization} \leftarrow \text{Growth}\)</span>, then we can safely and simply eliminate <em>Growth</em> from the model, as long as <em>Growth</em> is a root node with no other children besides <em>Democratization</em>.</p>
<p>As we discuss further in <a href="06-theory-as-causal-models.html" class="quarto-xref"><span>Chapter 6</span></a>, eliminating nodes may change the meaning of the exogenous, <span class="math inline">\(\theta\)</span> terms in the graph. For instance, when we eliminate <em>Growth</em> from the model <span class="math inline">\(\text{Mobilization} \rightarrow \text{Democratization} \leftarrow \text{Growth}\)</span>, leaving us with the simpler <span class="math inline">\(\text{Mobilization} \rightarrow \text{Democratization}\)</span>, the term <span class="math inline">\(\theta^D\)</span> changes in its range and interpretation. With all variables binary, <span class="math inline">\(\theta^D\)</span> in the original model could take on any of 16 nodal types, representing all possible joint effects of <em>Mobilization</em> and <em>Growth</em>. In the simplified model, <span class="math inline">\(\theta^D\)</span> now ranges across only four possible nodal types. <em>Growth</em>’s effects, rather than being explicitly modeled through the nodal-type functions, become an unobserved source of variation in <em>Mobilization</em>’s effects—and are, thus, “absorbed” into the four remaining nodal types.</p>
<p>In sum, we can work with models that are simpler than our causal beliefs: we may believe a model to be true, but we can derive from it a sparser set of claims. There may be intervening causal steps or features of context that we believe matter but that are not of interest for a particular line of inquiry. While these can be left out of our model, we nonetheless have to make sure that their <em>implications</em> for the relations remaining in the model are not lost. Understanding the rules of reduction allows us to undertake an important task: checking which simpler claims are and are not consistent with our full belief set.</p>
</section></section><section id="sec-conc2" class="level2" data-number="2.4"><h2 data-number="2.4" class="anchored" data-anchor-id="sec-conc2">
<span class="header-section-number">2.4</span> Conclusion</h2>
<p>In this chapter, we have shown how we can inscribe causal beliefs, rooted in the potential outcomes framework, into a causal model. In doing so, we have now set out the foundations of the book’s analytic framework. Causal models are both the starting point for analysis in this framework and the object about which we seek to learn. Before moving on to build on this foundation, we offer in the next chapter guidance by example on the construction of causal models, illustrating how a set of substantive social scientific arguments can be represented in causal model form.</p>
<div style="page-break-after: always;"></div>
</section><section id="chapter-appendix" class="level2" data-number="2.5"><h2 data-number="2.5" class="anchored" data-anchor-id="chapter-appendix">
<span class="header-section-number">2.5</span> Chapter Appendix</h2>
<section id="steps-for-constructing-causal-models" class="level3" data-number="2.5.1"><h3 data-number="2.5.1" class="anchored" data-anchor-id="steps-for-constructing-causal-models">
<span class="header-section-number">2.5.1</span> Steps for Constructing Causal Models</h3>
<p></p>
<ol type="1">
<li>Identify a set of variables in a domain of interest. These become the nodes of the model.</li>
</ol>
<ul>
<li>Specify the range of each node: Is it continuous or discrete?</li>
<li>Each node should have an associated <span class="math inline">\(\theta\)</span> term pointing into it, representing unspecified other influences (not necessarily graphed)</li>
</ul>
<ol start="2" type="1">
<li>Draw a causal graph (DAG) representing beliefs about causal dependencies among these nodes.</li>
</ol>
<ul>
<li>Include arrows for direct effects only</li>
<li>Arrows indicate <em>possible</em> causal effects</li>
<li>The absence of an arrow between two nodes indicates a belief of <em>no</em> direct causal relationship between them</li>
<li>Ensure that the graph captures all relationships between nodes. This means that either (a) any common cause of two or more nodes is included on the graph (with implications for Step 1) or (b) nodes that are not independent of each other are connected with a double-headed arrow or dashed, undirected edge.</li>
</ul>
<ol start="3" type="1">
<li>Write down one causal function for each endogenous node.</li>
</ol>
<ul>
<li>Each node’s function must include all nodes directly pointing into it on the graph as well as the <span class="math inline">\(\theta\)</span> terms</li>
<li>Functions may express arbitrary amounts of uncertainty about causal relations</li>
<li>In this book’s nonparametric framework, the causal functions are captured entirely by the <span class="math inline">\(\theta\)</span> terms.</li>
</ul>
<ol start="4" type="1">
<li>State probabilistic beliefs about the distributions of the <span class="math inline">\(\theta\)</span>s.</li>
</ol>
<ul>
<li>How common or likely to do we think different nodal types are for each node?</li>
<li>Are the nodal types independently distributed? If in Step 2 we drew an undirected edge between nodes, then we believe that the connected nodes’ types are not independently distributed.</li>
</ul></section><section id="model-construction-in-code" class="level3" data-number="2.5.2"><h3 data-number="2.5.2" class="anchored" data-anchor-id="model-construction-in-code">
<span class="header-section-number">2.5.2</span> Model Construction in Code</h3>
<p></p>
<p>Our <code>CausalQueries</code> package provides a set of functions to implement all of these steps concisely for <em>binary</em> models—models in which all nodes are dichotomous. </p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Steps 1 and 2 </span></span>
<span><span class="co"># We define a model with three binary nodes and </span></span>
<span><span class="co"># specified edges between them:</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">make_model</span><span class="op">(</span><span class="st">"X -&gt; M -&gt; Y"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Functional forms are unrestricted. Restrictions can </span></span>
<span><span class="co"># be added. Here we impose monotonicity at each step </span></span>
<span><span class="co"># by removing one type for M and one for Y</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">set_restrictions</span><span class="op">(</span><span class="va">model</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>M <span class="op">=</span> <span class="st">"10"</span>, Y<span class="op">=</span><span class="st">"10"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 4</span></span>
<span><span class="co"># Set priors over the distribution of (remaining) causal types.</span></span>
<span><span class="co"># Here we set "jeffreys priors" </span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">set_priors</span><span class="op">(</span><span class="va">model</span>, distribution <span class="op">=</span> <span class="st">"jeffreys"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We now have a model defined as an R object. </span></span>
<span><span class="co"># Later we will update  and query this model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<p>These steps are enough to fully describe a binary causal model. Later in this book, we will see how we can ask questions of a model like this but also how to use data to train it.</p>
</section><section id="sec-tryci" class="level3" data-number="2.5.3"><h3 data-number="2.5.3" class="anchored" data-anchor-id="sec-tryci">
<span class="header-section-number">2.5.3</span> Exercise: Reading Conditional Independence from a Graph</h3>
<p></p>
<p>We encourage readers to get some practice identifying the relations of conditional independence by analyzing the relationship between <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> in <a href="#fig-HJ-F-2-5" class="quarto-xref">Figure&nbsp;<span>2.5</span></a>. Try answering the following questions yourself, and then consult the answers provided below.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-HJ-F-2-5" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-HJ-F-2-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="02-causal-models_files/figure-html/fig-HJ-F-2-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-HJ-F-2-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: An exercise: <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> are conditionally independent given which other node(s)?
</figcaption></figure>
</div>
</div>
</div>
<p>Are A and D independent:</p>
<ol type="1">
<li>unconditionally?</li>
<li>if you condition on <span class="math inline">\(B\)</span>?</li>
<li>if you condition on <span class="math inline">\(C\)</span>?</li>
<li>if you condition on <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>?</li>
</ol>
<p><em>Answers</em></p>
<ol type="1">
<li>unconditionally?</li>
</ol>
<p>Yes. <span class="math inline">\(B\)</span> is a collider, and information does not flow across a collider if the value of the collider node or its consequences is not known. Since no information can flow between <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>, no information can flow between <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> simply because any such flow would have to run through <span class="math inline">\(C\)</span>.</p>
<ol start="2" type="1">
<li>if you condition on <span class="math inline">\(B\)</span>?</li>
</ol>
<p>No.&nbsp;Conditioning on a collider opens the flow of information across the incoming paths. Now, information flows between <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>. And since information flows between <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> are now also connected by an unbroken path. While <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> were independent when we conditioned on nothing, they cease to be independent when we condition on <span class="math inline">\(B\)</span>.</p>
<ol start="3" type="1">
<li>if you condition on <span class="math inline">\(C\)</span>?</li>
</ol>
<p>Yes. Conditioning on <span class="math inline">\(C\)</span>, in fact, has no effect on the situation. Doing so cuts off <span class="math inline">\(B\)</span> from <span class="math inline">\(D\)</span>, but this is irrelevant to the <span class="math inline">\(A\)</span>-<span class="math inline">\(D\)</span> relationship since the flow between <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> was already blocked at <span class="math inline">\(B\)</span>, an unobserved collider.</p>
<ol start="4" type="1">
<li>if you condition on <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>?</li>
</ol>
<p>Yes. Now we are doing two, countervailing things at once. While conditioning on <span class="math inline">\(B\)</span> opens the path connecting <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span>, conditioning on <span class="math inline">\(C\)</span> closes it again, leaving <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span> conditionally independent.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-boix2003democracy" class="csl-entry" role="listitem">
Boix, Carles. 2003. <em>Democracy and Redistribution</em>. New York: Cambridge University Press.
</div>
<div id="ref-cartwright1994nature" class="csl-entry" role="listitem">
Cartwright, Nancy. 1989. <span>“Nature’s Capacities and Their Measurement.”</span>
</div>
<div id="ref-chickering1996clinician" class="csl-entry" role="listitem">
Chickering, David M, and Judea Pearl. 1996. <span>“A Clinician’s Tool for Analyzing Non-Compliance.”</span> In <em>Proceedings of the National Conference on Artificial Intelligence</em>, 1269–76.
</div>
<div id="ref-copas1973randomization" class="csl-entry" role="listitem">
Copas, JB. 1973. <span>“Randomization Models for the Matched and Unmatched 2<span class="math inline">\(\times\)</span> 2 Tables.”</span> <em>Biometrika</em> 60 (3): 467–76.
</div>
<div id="ref-frangakis2002principal" class="csl-entry" role="listitem">
Frangakis, Constantine E, and Donald B Rubin. 2002. <span>“Principal Stratification in Causal Inference.”</span> <em>Biometrics</em> 58 (1): 21–29.
</div>
<div id="ref-galles1998axiomatic" class="csl-entry" role="listitem">
Galles, David, and Judea Pearl. 1998. <span>“An Axiomatic Characterization of Causal Counterfactuals.”</span> <em>Foundations of Science</em> 3 (1): 151–82.
</div>
<div id="ref-halpern2005causesa" class="csl-entry" role="listitem">
Halpern, Joseph Y, and Judea Pearl. 2005. <span>“Causes and Explanations: A Structural-Model Approach. Part i: Causes.”</span> <em>The British Journal for the Philosophy of Science</em> 56 (4): 843–87.
</div>
<div id="ref-hernan2006instruments" class="csl-entry" role="listitem">
Hernán, Miguel A, and James M Robins. 2006. <span>“Instruments for Causal Inference: An Epidemiologist’s Dream?”</span> <em>Epidemiology</em> 17 (4): 360–72.
</div>
<div id="ref-holland1986statistics" class="csl-entry" role="listitem">
Holland, Paul W. 1986. <span>“Statistics and Causal Inference.”</span> <em>Journal of the American Statistical Association</em> 81 (396): 945–60.
</div>
<div id="ref-hume2000enquiry" class="csl-entry" role="listitem">
Hume, David, and Tom L Beauchamp. 2000. <em>An Enquiry Concerning Human Understanding: A Critical Edition</em>. Vol. 3. Oxford University Press.
</div>
<div id="ref-laplace1901philosophical" class="csl-entry" role="listitem">
Laplace, Pierre-Simon. 1901. <em>A Philosophical Essay on Probabilities</em>. Translated by F.W. Truscott and F.L. Emory. Vol. 166. New York: Cosimo.
</div>
<div id="ref-lewis1973counterfactuals" class="csl-entry" role="listitem">
Lewis, David. 1973. <span>“Counterfactuals and Comparative Possibility.”</span> In <em>Ifs</em>, 57–85. Springer.
</div>
<div id="ref-lewis1986causation" class="csl-entry" role="listitem">
———. 1986. <span>“Causation.”</span> <em>Philosophical Papers</em> 2: 159–213.
</div>
<div id="ref-mahoney2008toward" class="csl-entry" role="listitem">
Mahoney, James. 2008. <span>“Toward a Unified Theory of Causality.”</span> <em>Comparative Political Studies</em> 41 (4-5): 412–36.
</div>
<div id="ref-pearl2000causality" class="csl-entry" role="listitem">
Pearl, Judea. 2000. <em>Causality: Models, Reasoning and Inference</em>. Vol. 29. Cambridge Univ Press.
</div>
<div id="ref-pearl2009causality" class="csl-entry" role="listitem">
———. 2009. <em>Causality</em>. Cambridge university press.
</div>
<div id="ref-rohrer2018thinking" class="csl-entry" role="listitem">
Rohrer, Julia M. 2018. <span>“Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 1 (1): 27–42.
</div>
<div id="ref-Rubin1974" class="csl-entry" role="listitem">
Rubin, Donald B. 1974. <span>“Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.”</span> <em>Journal of Educational Psychology</em> 66: 688–701.
</div>
<div id="ref-spirtes2000causation" class="csl-entry" role="listitem">
Spirtes, Peter, Clark N Glymour, Richard Scheines, and David Heckerman. 2000. <em>Causation, Prediction, and Search</em>. MIT press.
</div>
<div id="ref-splawa1990application" class="csl-entry" role="listitem">
Splawa-Neyman, Jerzy, DM Dabrowska, TP Speed, et al. 1990. <span>“On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9.”</span> <em>Statistical Science</em> 5 (4): 465–72.
</div>
</div>
</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>As nicely put by Nancy Cartwright: no causes in, no causes out <span class="citation" data-cites="cartwright1994nature">(<a href="20-references.html#ref-cartwright1994nature" role="doc-biblioref">Cartwright 1989</a>)</span>. We return to the point more formally later.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The approach is sometimes attributed to David Hume, whose writing contains ideas both about causality as regularity and causality as counterfactual. On the latter, Hume’s key formulation is, “if the first object had not been, the second never had existed” <span class="citation" data-cites="hume2000enquiry">(<a href="20-references.html#ref-hume2000enquiry" role="doc-biblioref">Hume and Beauchamp 2000, vol. 3, sec. VIII</a>)</span>. More recently, the counterfactual view has been set forth by <span class="citation" data-cites="splawa1990application">Splawa-Neyman et al. (<a href="20-references.html#ref-splawa1990application" role="doc-biblioref">1990</a>)</span> and <span class="citation" data-cites="lewis1973counterfactuals">Lewis (<a href="20-references.html#ref-lewis1973counterfactuals" role="doc-biblioref">1973</a>)</span>. See also <span class="citation" data-cites="lewis1986causation">Lewis (<a href="20-references.html#ref-lewis1986causation" role="doc-biblioref">1986</a>)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>In the terminology of <span class="citation" data-cites="pearl2000causality">Pearl (<a href="20-references.html#ref-pearl2000causality" role="doc-biblioref">2000</a>)</span>, we can represent this quantity using a “do” operator: <span class="math inline">\(Y(\text{do}(X=x))\)</span> is the value of <span class="math inline">\(Y\)</span> when the variable <span class="math inline">\(X\)</span> is <em>set</em> to the value <span class="math inline">\(x\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>To avoid ambiguity, we prefer <span class="math inline">\(Y_i(X=0)\)</span> and <span class="math inline">\(Y_i(X=1)\)</span>. Alternative notation, used in <span class="citation" data-cites="holland1986statistics">Holland (<a href="20-references.html#ref-holland1986statistics" role="doc-biblioref">1986</a>)</span> for instance, places the treatment condition in the subscript: <span class="math inline">\(Y_t(u), Y_c(u)\)</span>, with <span class="math inline">\(u\)</span> used to capture individual level features. Sometimes the pairs are written <span class="math inline">\(Y_{u0}, Y_{u1}\)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>We note that we are conditioning on the assignments of others. If we wanted to describe outcomes as a function of the <em>profile</em> of treatments received by others, we would have a more complex type space. For instance, in an <span class="math inline">\(X \rightarrow Y\)</span> model with 2 individuals, we would report how <span class="math inline">\((Y_1, Y_2)\)</span> respond to <span class="math inline">\((X_1,X_0)\)</span>; each vector can take on four values producing a type space with <span class="math inline">\(4^4\)</span> types rather than <span class="math inline">\(2^2\)</span>. The complex type space could be reduced back down to four types again, however, if we invoked the assumption that the treatment or non-treatment of one patient has no effect on the outcomes of other patients—an assumption known as the stable unit treatment value assumption.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>See <span class="citation" data-cites="copas1973randomization">Copas (<a href="20-references.html#ref-copas1973randomization" role="doc-biblioref">1973</a>)</span> for an early classification of this form. The literature on probabilistic models also refers to such strata as “principal strata,” “canonical partitions,” or “equivalence classes.”<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Later, we will refer to these as “nodal types.”<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>We note however that this terminology is not always used consistently in the literature and the term “structural causal model” is sometimes used coextensively with what we have defined above as a causal model.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>In many treatments, <span class="math inline">\(\mathcal{U}\)</span> is used for the exogenous nodes. We use <span class="math inline">\(\Theta\)</span> to denote these unobserved, unspecified influences in order to emphasize their particular role, as direct objects of interest in causal inquiry.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>These causal functions relate to “structural equations” in a simple way: structural equations place an endogenous variable on the left hand side and the causal function together with the parents on the right hand side. Thus for example <span class="math inline">\(Y = f^Y(\text{pa}(Y), \theta^Y)\)</span> is a structural equation, as is <span class="math inline">\(Y = X + \theta^Y\)</span> where implicitly <span class="math inline">\(f^Y(\text{pa}(Y), \theta^Y) = X + \theta^Y\)</span>.” <a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>The set of a node’s parents is required to be minimal in the sense that a node is not included among the parents if, given the other parents, the child does not depend on it in any state that arises with positive probability.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>We say more about these distributions when we turn to a discussion of Bayesianism in <a href="05-being-Bayesian.html" class="quarto-xref"><span>Chapter 5</span></a>.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>For more on violations of independence arising from correlations in beliefs about population quantities, see <a href="09-mixing-methods.html#sec-pvpopdag" class="quarto-xref"><span>Section 9.5.3</span></a>.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>In the <code>CausalQueries</code> software package, we can specify nodal types as having joint distributions.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Though we sometimes use “correlated” and “uncorrelated” to describe dependence and independence between variables, <em>independence</em> is in fact a stronger idea than <em>uncorrelated</em>. Two variables might be uncorrelated but still not be independent of each other. For instance, imagine <span class="math inline">\(X\)</span> is evenly distributed over <span class="math inline">\(\{0,1,2\}\)</span> and <span class="math inline">\(Y = 1\)</span> if and only if <span class="math inline">\(X=1\)</span>. Then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> will be uncorrelated but you can nevertheless learn a lot (everything!) about <span class="math inline">\(Y\)</span> from learning about <span class="math inline">\(X\)</span>.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>By “direct” we mean that the <span class="math inline">\(A\)</span> is a parent of <span class="math inline">\(B\)</span>: that is, the effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(B\)</span> is not fully mediated by one or more other nodes in the model.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>We are applying the subscript scheme from <a href="#tbl-HJ-T-2-3" class="quarto-xref">Table&nbsp;<span>2.3</span></a>, where <span class="math inline">\(E\)</span> plays the role of <span class="math inline">\(X_1\)</span> and R plays the role of <span class="math inline">\(X_2\)</span>.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>Put in more general terms, a node’s causal function must include all nodes pointing directly into it. We can imagine this same idea in a parametric setting. Imagine that <span class="math inline">\(M\)</span>’s causal function was specified as: <span class="math inline">\(M = RE\)</span>. This function would allow for the possibility that <span class="math inline">\(R\)</span> affects <span class="math inline">\(M\)</span>, as it will whenever <span class="math inline">\(E=1\)</span>. However, it would also allow that <span class="math inline">\(R\)</span> will have no effect, as it will when <span class="math inline">\(E=0\)</span>.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>Readers may recognize this statement as the logic of adjusting for a confound that is a cause of both an explanatory node and a dependent node in order to achieve conditional independence.<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>In the familial language of causal models, a collider is a child of two or more parents.<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./01-intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-illustrating-models.html" class="pagination-link" aria-label="Illustrating Causal Models">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Illustrating Causal Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>